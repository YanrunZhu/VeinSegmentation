
############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-05-29 13:34:21.997133: Initializing CustomDiceTrainer, inheriting from nnUNetTrainer, with WeightedSoftDiceLoss!
WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
2025-05-29 13:34:24.159471: Using torch.compile...
2025-05-29 13:34:25.290861: CustomDiceTrainer: Building custom weighted loss function.
2025-05-29 13:34:25.304600: Dice class weights (for WeightedSoftDiceLoss, do_bg=False): [1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:34:25.308167: CE class weights: [1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:34:25.308249: Standard (non-region) segmentation training. Applying WeightedSoftDiceLoss.
2025-05-29 13:34:25.313087: do_dummy_2d_data_aug: False
2025-05-29 13:34:25.314927: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 13:34:25.315396: The split file contains 5 splits.
2025-05-29 13:34:25.315439: Desired fold for training: 1
2025-05-29 13:34:25.315477: This split has 506 training and 127 validation cases.
using pin_memory on device 0

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-05-29 13:36:11.010151: Initializing CustomDiceTrainer, inheriting from nnUNetTrainer, with WeightedSoftDiceLoss!
WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
2025-05-29 13:36:12.742108: Using torch.compile...
2025-05-29 13:36:13.815114: CustomDiceTrainer: Building custom weighted loss function.
2025-05-29 13:36:13.823321: Dice class weights (for WeightedSoftDiceLoss, do_bg=False): [1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:36:13.823589: CE class weights: [1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:36:13.823659: Standard (non-region) segmentation training. Applying WeightedSoftDiceLoss.
2025-05-29 13:36:13.828239: do_dummy_2d_data_aug: False
2025-05-29 13:36:13.830050: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 13:36:13.830535: The split file contains 5 splits.
2025-05-29 13:36:13.830583: Desired fold for training: 2
2025-05-29 13:36:13.830614: This split has 506 training and 127 validation cases.
using pin_memory on device 0

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-05-29 13:36:50.836758: Initializing CustomDiceTrainer, inheriting from nnUNetTrainer, with WeightedSoftDiceLoss!
WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
2025-05-29 13:36:52.495403: Using torch.compile...
2025-05-29 13:36:53.369747: CustomDiceTrainer: Building custom weighted loss function.
2025-05-29 13:36:53.379255: Dice class weights (for WeightedSoftDiceLoss, do_bg=False): [1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:36:53.379511: CE class weights: [1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:36:53.379581: Standard (non-region) segmentation training. Applying WeightedSoftDiceLoss.
2025-05-29 13:36:53.384102: do_dummy_2d_data_aug: False
2025-05-29 13:36:53.385850: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 13:36:53.386323: The split file contains 5 splits.
2025-05-29 13:36:53.386365: Desired fold for training: 3
2025-05-29 13:36:53.386392: This split has 507 training and 126 validation cases.
using pin_memory on device 0
/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-05-29 13:37:11.991616: Initializing CustomDiceTrainer, inheriting from nnUNetTrainer, with WeightedSoftDiceLoss!
WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
Traceback (most recent call last):
  File "/home/zyr/anaconda3/envs/nnUNet/bin/nnUNetv2_train", line 8, in <module>
    sys.exit(run_training_entry())
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/zyr/nnUNet/nnunetv2/run/run_training.py", line 267, in run_training_entry
    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,
  File "/home/zyr/nnUNet/nnunetv2/run/run_training.py", line 207, in run_training
    nnunet_trainer.run_training()
  File "/home/zyr/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 1363, in run_training
    self.on_train_start()
  File "/home/zyr/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 896, in on_train_start
    self.initialize()
  File "/home/zyr/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py", line 216, in initialize
    ).to(self.device)
      ^^^^^^^^^^^^^^^
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  [Previous line repeated 4 more times]
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zyr/anaconda3/envs/nnUNet/lib/python3.11/site-packages/torch/cuda/__init__.py", line 302, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-05-29 13:38:59.580742: Initializing CustomDiceTrainer, inheriting from nnUNetTrainer, with WeightedSoftDiceLoss!
WARNING: Cannot continue training because there seems to be no checkpoint available to continue from. Starting a new training...
2025-05-29 13:39:01.946595: Using torch.compile...
2025-05-29 13:39:03.272017: CustomDiceTrainer: Building custom weighted loss function.
2025-05-29 13:39:03.285273: Dice class weights (for WeightedSoftDiceLoss, do_bg=False): [1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:39:03.287169: CE class weights: [1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
2025-05-29 13:39:03.287283: Standard (non-region) segmentation training. Applying WeightedSoftDiceLoss.
2025-05-29 13:39:03.293041: do_dummy_2d_data_aug: False
2025-05-29 13:39:03.295146: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 13:39:03.295770: The split file contains 5 splits.
2025-05-29 13:39:03.295832: Desired fold for training: 4
2025-05-29 13:39:03.295862: This split has 507 training and 126 validation cases.
using pin_memory on device 0
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [464.0, 449.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset228_adomi', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 464, 449], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 30.38488375492876, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.48317688397075}, '1': {'max': 255.0, 'mean': 30.448724995229867, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.54321923522895}, '2': {'max': 255.0, 'mean': 30.492282963433194, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.58594251904467}}} 

2025-05-29 13:36:15.813958: Unable to plot network architecture: nnUNet_compile is enabled!
2025-05-29 13:36:15.822831: 
2025-05-29 13:36:15.823118: Epoch 0
2025-05-29 13:36:15.823294: Current learning rate: 0.01
2025-05-29 13:37:46.457544: train_loss 0.4888
2025-05-29 13:37:46.457773: val_loss 0.3273
2025-05-29 13:37:46.457891: Pseudo dice [0.1597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:37:46.457964: Epoch time: 90.64 s
2025-05-29 13:37:46.458025: Yayy! New best EMA pseudo Dice: 0.02
2025-05-29 13:37:48.045604: 
2025-05-29 13:37:48.045928: Epoch 1
2025-05-29 13:37:48.046075: Current learning rate: 0.00997
2025-05-29 13:38:16.872823: train_loss 0.2491
2025-05-29 13:38:16.873025: val_loss 0.1494
2025-05-29 13:38:16.873143: Pseudo dice [0.5732, 0.0, 0.0, 0.2632, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:38:16.873219: Epoch time: 28.83 s
2025-05-29 13:38:16.873273: Yayy! New best EMA pseudo Dice: 0.0284
2025-05-29 13:38:19.278329: 
2025-05-29 13:38:19.278612: Epoch 2
2025-05-29 13:38:19.278721: Current learning rate: 0.00994
2025-05-29 13:38:48.362362: train_loss 0.1556
2025-05-29 13:38:48.362558: val_loss 0.1283
2025-05-29 13:38:48.362714: Pseudo dice [0.5931, 0.0, 0.0, 0.3378, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:38:48.362812: Epoch time: 29.09 s
2025-05-29 13:38:48.362864: Yayy! New best EMA pseudo Dice: 0.0372
2025-05-29 13:38:50.864200: 
2025-05-29 13:38:50.864439: Epoch 3
2025-05-29 13:38:50.864635: Current learning rate: 0.00991
2025-05-29 13:39:20.504703: train_loss 0.119
2025-05-29 13:39:20.504888: val_loss 0.161
2025-05-29 13:39:20.505000: Pseudo dice [0.5106, 0.0005, 0.0, 0.2449, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:39:20.505073: Epoch time: 29.64 s
2025-05-29 13:39:20.505126: Yayy! New best EMA pseudo Dice: 0.0429
2025-05-29 13:39:22.913714: 
2025-05-29 13:39:22.913857: Epoch 4
2025-05-29 13:39:22.914032: Current learning rate: 0.00988
2025-05-29 13:39:52.497375: train_loss 0.0838
2025-05-29 13:39:52.497692: val_loss -0.0026
2025-05-29 13:39:52.497816: Pseudo dice [0.5538, 0.0, 0.0, 0.4514, 0.0, 0.3576, 0.0, 0.0]
2025-05-29 13:39:52.497912: Epoch time: 29.58 s
2025-05-29 13:39:52.497960: Yayy! New best EMA pseudo Dice: 0.0557
2025-05-29 13:39:55.016892: 
2025-05-29 13:39:55.017202: Epoch 5
2025-05-29 13:39:55.017348: Current learning rate: 0.00985
2025-05-29 13:40:25.803305: train_loss -0.0065
2025-05-29 13:40:25.803567: val_loss 0.0005
2025-05-29 13:40:25.803744: Pseudo dice [0.56, 0.0, 0.0, 0.3783, 0.0, 0.6447, 0.0, 0.0309]
2025-05-29 13:40:25.803827: Epoch time: 30.79 s
2025-05-29 13:40:25.803891: Yayy! New best EMA pseudo Dice: 0.0703
2025-05-29 13:40:28.298506: 
2025-05-29 13:40:28.298864: Epoch 6
2025-05-29 13:40:28.298967: Current learning rate: 0.00982
2025-05-29 13:40:59.567750: train_loss -0.0353
2025-05-29 13:40:59.568079: val_loss -0.0972
2025-05-29 13:40:59.568351: Pseudo dice [0.5934, 0.0, 0.0, 0.4434, 0.0, 0.7302, 0.0, 0.2949]
2025-05-29 13:40:59.568525: Epoch time: 31.27 s
2025-05-29 13:40:59.568589: Yayy! New best EMA pseudo Dice: 0.089
2025-05-29 13:41:02.951165: 
2025-05-29 13:41:02.951564: Epoch 7
2025-05-29 13:41:02.951745: Current learning rate: 0.00979
2025-05-29 13:41:37.357543: train_loss -0.0779
2025-05-29 13:41:37.357854: val_loss -0.0908
2025-05-29 13:41:37.357975: Pseudo dice [0.6291, 0.0, 0.0944, 0.4879, 0.0, 0.7778, 0.0, 0.3309]
2025-05-29 13:41:37.358062: Epoch time: 34.41 s
2025-05-29 13:41:37.358125: Yayy! New best EMA pseudo Dice: 0.1091
2025-05-29 13:41:40.324308: 
2025-05-29 13:41:40.324634: Epoch 8
2025-05-29 13:41:40.324832: Current learning rate: 0.00976
2025-05-29 13:42:11.458720: train_loss -0.1444
2025-05-29 13:42:11.458917: val_loss -0.1592
2025-05-29 13:42:11.459071: Pseudo dice [0.7731, 0.0, 0.1666, 0.4171, 0.0, 0.7433, 0.0, 0.422]
2025-05-29 13:42:11.459156: Epoch time: 31.14 s
2025-05-29 13:42:11.459212: Yayy! New best EMA pseudo Dice: 0.1297
2025-05-29 13:42:14.075996: 
2025-05-29 13:42:14.076324: Epoch 9
2025-05-29 13:42:14.076481: Current learning rate: 0.00973
2025-05-29 13:42:44.999022: train_loss -0.1757
2025-05-29 13:42:44.999207: val_loss -0.2115
2025-05-29 13:42:44.999325: Pseudo dice [0.7406, 0.0, 0.2136, 0.5456, 0.0, 0.7353, 0.0, 0.2936]
2025-05-29 13:42:44.999402: Epoch time: 30.92 s
2025-05-29 13:42:44.999458: Yayy! New best EMA pseudo Dice: 0.1484
2025-05-29 13:42:47.766894: 
2025-05-29 13:42:47.767282: Epoch 10
2025-05-29 13:42:47.767388: Current learning rate: 0.0097
2025-05-29 13:43:27.560501: train_loss -0.1734
2025-05-29 13:43:27.560767: val_loss -0.2009
2025-05-29 13:43:27.560905: Pseudo dice [0.7738, 0.0, 0.1835, 0.4499, 0.0, 0.7668, 0.0, 0.3454]
2025-05-29 13:43:27.561006: Epoch time: 39.79 s
2025-05-29 13:43:27.561074: Yayy! New best EMA pseudo Dice: 0.165
2025-05-29 13:43:30.191003: 
2025-05-29 13:43:30.191410: Epoch 11
2025-05-29 13:43:30.191594: Current learning rate: 0.00967
2025-05-29 13:44:21.786870: train_loss -0.2605
2025-05-29 13:44:21.787122: val_loss -0.1834
2025-05-29 13:44:21.787250: Pseudo dice [0.7794, 0.0023, 0.1999, 0.4516, 0.0, 0.7655, 0.0, 0.4235]
2025-05-29 13:44:21.787335: Epoch time: 51.6 s
2025-05-29 13:44:21.787398: Yayy! New best EMA pseudo Dice: 0.1813
2025-05-29 13:44:24.524182: 
2025-05-29 13:44:24.524558: Epoch 12
2025-05-29 13:44:24.524676: Current learning rate: 0.00964
2025-05-29 13:44:55.684811: train_loss -0.2508
2025-05-29 13:44:55.685085: val_loss -0.155
2025-05-29 13:44:55.685204: Pseudo dice [0.7684, 0.2501, 0.0955, 0.3947, 0.0, 0.7522, 0.0, 0.4023]
2025-05-29 13:44:55.685299: Epoch time: 31.16 s
2025-05-29 13:44:55.685355:using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [464.0, 449.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset228_adomi', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 464, 449], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 30.38488375492876, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.48317688397075}, '1': {'max': 255.0, 'mean': 30.448724995229867, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.54321923522895}, '2': {'max': 255.0, 'mean': 30.492282963433194, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.58594251904467}}} 

2025-05-29 13:36:56.119653: Unable to plot network architecture: nnUNet_compile is enabled!
2025-05-29 13:36:56.128596: 
2025-05-29 13:36:56.128862: Epoch 0
2025-05-29 13:36:56.129317: Current learning rate: 0.01
2025-05-29 13:38:26.139048: train_loss 0.5265
2025-05-29 13:38:26.139326: val_loss 0.3428
2025-05-29 13:38:26.139476: Pseudo dice [0.1474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:38:26.139566: Epoch time: 90.01 s
2025-05-29 13:38:26.139614: Yayy! New best EMA pseudo Dice: 0.0184
2025-05-29 13:38:27.831739: 
2025-05-29 13:38:27.832124: Epoch 1
2025-05-29 13:38:27.832226: Current learning rate: 0.00997
2025-05-29 13:38:56.410800: train_loss 0.3024
2025-05-29 13:38:56.410997: val_loss 0.2215
2025-05-29 13:38:56.411118: Pseudo dice [0.5577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:38:56.411190: Epoch time: 28.58 s
2025-05-29 13:38:56.411242: Yayy! New best EMA pseudo Dice: 0.0235
2025-05-29 13:38:58.958480: 
2025-05-29 13:38:58.958686: Epoch 2
2025-05-29 13:38:58.958836: Current learning rate: 0.00994
2025-05-29 13:39:28.396079: train_loss 0.1792
2025-05-29 13:39:28.396238: val_loss 0.1422
2025-05-29 13:39:28.396347: Pseudo dice [0.689, 0.0, 0.0, 0.2271, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:39:28.396423: Epoch time: 29.44 s
2025-05-29 13:39:28.396491: Yayy! New best EMA pseudo Dice: 0.0326
2025-05-29 13:39:31.387115: 
2025-05-29 13:39:31.387476: Epoch 3
2025-05-29 13:39:31.387608: Current learning rate: 0.00991
2025-05-29 13:40:17.639162: train_loss 0.0646
2025-05-29 13:40:17.639346: val_loss 0.0571
2025-05-29 13:40:17.639472: Pseudo dice [0.7284, 0.0, 0.0, 0.2859, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:40:17.639547: Epoch time: 46.25 s
2025-05-29 13:40:17.639599: Yayy! New best EMA pseudo Dice: 0.0421
2025-05-29 13:40:20.216815: 
2025-05-29 13:40:20.217138: Epoch 4
2025-05-29 13:40:20.217243: Current learning rate: 0.00988
2025-05-29 13:41:16.296835: train_loss 0.0376
2025-05-29 13:41:16.297243: val_loss 0.0054
2025-05-29 13:41:16.297385: Pseudo dice [0.7157, 0.023, 0.0, 0.2723, 0.0, 0.5373, 0.0, 0.0]
2025-05-29 13:41:16.297474: Epoch time: 56.08 s
2025-05-29 13:41:16.297531: Yayy! New best EMA pseudo Dice: 0.0572
2025-05-29 13:41:19.033989: 
2025-05-29 13:41:19.034354: Epoch 5
2025-05-29 13:41:19.034462: Current learning rate: 0.00985
2025-05-29 13:42:28.218946: train_loss -0.0901
2025-05-29 13:42:28.219202: val_loss 0.0361
2025-05-29 13:42:28.219320: Pseudo dice [0.559, 0.0, 0.0, 0.2452, 0.0, 0.7114, 0.0, 0.0033]
2025-05-29 13:42:28.219404: Epoch time: 69.19 s
2025-05-29 13:42:28.219481: Yayy! New best EMA pseudo Dice: 0.0705
2025-05-29 13:42:30.908407: 
2025-05-29 13:42:30.908893: Epoch 6
2025-05-29 13:42:30.909026: Current learning rate: 0.00982
2025-05-29 13:43:58.368371: train_loss -0.0983
2025-05-29 13:43:58.368703: val_loss -0.0735
2025-05-29 13:43:58.368829: Pseudo dice [0.7406, 0.0, 0.0, 0.3246, 0.0, 0.7819, 0.0, 0.0507]
2025-05-29 13:43:58.368923: Epoch time: 87.46 s
2025-05-29 13:43:58.368970: Yayy! New best EMA pseudo Dice: 0.0871
2025-05-29 13:44:01.000916: 
2025-05-29 13:44:01.001233: Epoch 7
2025-05-29 13:44:01.001436: Current learning rate: 0.00979
2025-05-29 13:45:13.829651: train_loss -0.0934
2025-05-29 13:45:13.829925: val_loss -0.1075
2025-05-29 13:45:13.830043: Pseudo dice [0.7486, 0.0, 0.001, 0.3293, 0.0, 0.785, 0.0, 0.1215]
2025-05-29 13:45:13.830128: Epoch time: 72.83 s
2025-05-29 13:45:13.830189: Yayy! New best EMA pseudo Dice: 0.1033
2025-05-29 13:45:17.195012: 
2025-05-29 13:45:17.195273: Epoch 8
2025-05-29 13:45:17.195423: Current learning rate: 0.00976
2025-05-29 13:46:29.613311: train_loss -0.1682
2025-05-29 13:46:29.613606: val_loss -0.1522
2025-05-29 13:46:29.613806: Pseudo dice [0.7123, 0.0, 0.2124, 0.4214, 0.0, 0.8156, 0.0, 0.1844]
2025-05-29 13:46:29.613949: Epoch time: 72.42 s
2025-05-29 13:46:29.614026: Yayy! New best EMA pseudo Dice: 0.1223
2025-05-29 13:46:32.477155: 
2025-05-29 13:46:32.477405: Epoch 9
2025-05-29 13:46:32.477511: Current learning rate: 0.00973
2025-05-29 13:47:45.515938: train_loss -0.184
2025-05-29 13:47:45.516111: val_loss -0.1794
2025-05-29 13:47:45.516234: Pseudo dice [0.7577, 0.0, 0.2166, 0.4089, 0.0, 0.728, 0.0, 0.283]
2025-05-29 13:47:45.516306: Epoch time: 73.04 s
2025-05-29 13:47:45.516355: Yayy! New best EMA pseudo Dice: 0.14
2025-05-29 13:47:47.961917: 
2025-05-29 13:47:47.962255: Epoch 10
2025-05-29 13:47:47.962351: Current learning rate: 0.0097
2025-05-29 13:49:00.908793: train_loss -0.2544
2025-05-29 13:49:00.908979: val_loss -0.0373
2025-05-29 13:49:00.909092: Pseudo dice [0.7016, 0.0334, 0.2196, 0.264, 0.0, 0.8193, 0.0, 0.2352]
2025-05-29 13:49:00.909168: Epoch time: 72.95 s
2025-05-29 13:49:00.909220: Yayy! New best EMA pseudo Dice: 0.1544
2025-05-29 13:49:03.421625: 
2025-05-29 13:49:03.421761: Epoch 11
2025-05-29 13:49:03.421860: Current learning rate: 0.00967
2025-05-29 13:50:16.828971: train_loss -0.2738
2025-05-29 13:50:16.829159: val_loss -0.2069
2025-05-29 13:50:16.829275: Pseudo dice [0.726, 0.0, 0.1946, 0.4334, 0.0, 0.8361, 0.0, 0.1913]
2025-05-29 13:50:16.829351: Epoch time: 73.41 s
2025-05-29 13:50:16.829404: Yayy! New best EMA pseudo Dice: 0.1687
2025-05-29 13:50:19.342745: 
2025-05-29 13:50:19.342993: Epoch 12
2025-05-29 13:50:19.343244: Current learning rate: 0.00964
2025-05-29 13:51:31.649352: train_loss -0.2876
2025-05-29 13:51:31.649701: val_loss -0.2473
2025-05-29 13:51:31.649832: Pseudo dice [0.8142, 0.0, 0.0824, 0.4391, 0.0, 0.8639, 0.0, 0.3182]
2025-05-29 13:51:31.649930: Epoch time: 72.31 s
2025-05-29 13:51:31.649982:using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [464.0, 449.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset228_adomi', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 464, 449], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 30.38488375492876, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.48317688397075}, '1': {'max': 255.0, 'mean': 30.448724995229867, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.54321923522895}, '2': {'max': 255.0, 'mean': 30.492282963433194, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.58594251904467}}} 

2025-05-29 13:34:27.534444: Unable to plot network architecture: nnUNet_compile is enabled!
2025-05-29 13:34:27.551573: 
2025-05-29 13:34:27.551802: Epoch 0
2025-05-29 13:34:27.552733: Current learning rate: 0.01
2025-05-29 13:36:52.358664: train_loss 0.4785
2025-05-29 13:36:52.358979: val_loss 0.3134
2025-05-29 13:36:52.359124: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:36:52.359199: Epoch time: 144.81 s
2025-05-29 13:36:52.359247: Yayy! New best EMA pseudo Dice: 0.0
2025-05-29 13:36:54.334772: 
2025-05-29 13:36:54.334975: Epoch 1
2025-05-29 13:36:54.335166: Current learning rate: 0.00997
2025-05-29 13:38:11.480951: train_loss 0.2533
2025-05-29 13:38:11.481247: val_loss 0.1914
2025-05-29 13:38:11.481367: Pseudo dice [0.5429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:38:11.481440: Epoch time: 77.15 s
2025-05-29 13:38:11.481519: Yayy! New best EMA pseudo Dice: 0.0068
2025-05-29 13:38:13.916079: 
2025-05-29 13:38:13.916315: Epoch 2
2025-05-29 13:38:13.916511: Current learning rate: 0.00994
2025-05-29 13:39:31.004430: train_loss 0.1482
2025-05-29 13:39:31.004694: val_loss 0.0925
2025-05-29 13:39:31.004903: Pseudo dice [0.6314, 0.0, 0.0, 0.2743, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:39:31.005019: Epoch time: 77.09 s
2025-05-29 13:39:31.005075: Yayy! New best EMA pseudo Dice: 0.0174
2025-05-29 13:39:33.516241: 
2025-05-29 13:39:33.516657: Epoch 3
2025-05-29 13:39:33.516774: Current learning rate: 0.00991
2025-05-29 13:40:59.228736: train_loss 0.1257
2025-05-29 13:40:59.229053: val_loss 0.1264
2025-05-29 13:40:59.229172: Pseudo dice [0.671, 0.0, 0.0, 0.2016, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:40:59.229255: Epoch time: 85.71 s
2025-05-29 13:40:59.229303: Yayy! New best EMA pseudo Dice: 0.0266
2025-05-29 13:41:02.897065: 
2025-05-29 13:41:02.897499: Epoch 4
2025-05-29 13:41:02.897626: Current learning rate: 0.00988
2025-05-29 13:42:25.463626: train_loss 0.0683
2025-05-29 13:42:25.463889: val_loss 0.0441
2025-05-29 13:42:25.464006: Pseudo dice [0.631, 0.0, 0.0, 0.3657, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:42:25.464097: Epoch time: 82.57 s
2025-05-29 13:42:25.464180: Yayy! New best EMA pseudo Dice: 0.0364
2025-05-29 13:42:28.168083: 
2025-05-29 13:42:28.168393: Epoch 5
2025-05-29 13:42:28.168526: Current learning rate: 0.00985
2025-05-29 13:44:07.407129: train_loss 0.0079
2025-05-29 13:44:07.407359: val_loss -0.0089
2025-05-29 13:44:07.407491: Pseudo dice [0.6702, 0.0, 0.0, 0.3532, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:44:07.407571: Epoch time: 99.24 s
2025-05-29 13:44:07.407637: Yayy! New best EMA pseudo Dice: 0.0455
2025-05-29 13:44:09.967187: 
2025-05-29 13:44:09.967441: Epoch 6
2025-05-29 13:44:09.967560: Current learning rate: 0.00982
2025-05-29 13:45:33.418871: train_loss -0.0549
2025-05-29 13:45:33.419218: val_loss -0.0843
2025-05-29 13:45:33.419436: Pseudo dice [0.7197, 0.0, 0.0, 0.419, 0.0, 0.4479, 0.0, 0.0]
2025-05-29 13:45:33.419544: Epoch time: 83.45 s
2025-05-29 13:45:33.419614: Yayy! New best EMA pseudo Dice: 0.0608
2025-05-29 13:45:36.228834: 
2025-05-29 13:45:36.229353: Epoch 7
2025-05-29 13:45:36.229535: Current learning rate: 0.00979
2025-05-29 13:47:04.774509: train_loss -0.0996
2025-05-29 13:47:04.774758: val_loss -0.1484
2025-05-29 13:47:04.774884: Pseudo dice [0.7668, 0.113, 0.1185, 0.4251, 0.0, 0.6916, 0.0, 0.054]
2025-05-29 13:47:04.774992: Epoch time: 88.55 s
2025-05-29 13:47:04.775050: Yayy! New best EMA pseudo Dice: 0.0819
2025-05-29 13:47:07.953421: 
2025-05-29 13:47:07.953812: Epoch 8
2025-05-29 13:47:07.954121: Current learning rate: 0.00976
2025-05-29 13:48:37.167307: train_loss -0.1807
2025-05-29 13:48:37.167583: val_loss -0.1752
2025-05-29 13:48:37.167709: Pseudo dice [0.7264, 0.0133, 0.1716, 0.5159, 0.0, 0.6973, 0.0, 0.1264]
2025-05-29 13:48:37.167852: Epoch time: 89.22 s
2025-05-29 13:48:37.167933: Yayy! New best EMA pseudo Dice: 0.1018
2025-05-29 13:48:39.855564: 
2025-05-29 13:48:39.855818: Epoch 9
2025-05-29 13:48:39.855915: Current learning rate: 0.00973
2025-05-29 13:50:08.872973: train_loss -0.2085
2025-05-29 13:50:08.873273: val_loss -0.2305
2025-05-29 13:50:08.873404: Pseudo dice [0.7567, 0.0508, 0.1137, 0.5255, 0.0, 0.715, 0.0, 0.2564]
2025-05-29 13:50:08.873518: Epoch time: 89.02 s
2025-05-29 13:50:08.873565: Yayy! New best EMA pseudo Dice: 0.1219
2025-05-29 13:50:11.374597: 
2025-05-29 13:50:11.374825: Epoch 10
2025-05-29 13:50:11.374954: Current learning rate: 0.0097
2025-05-29 13:51:40.339977: train_loss -0.2247
2025-05-29 13:51:40.340328: val_loss -0.2169
2025-05-29 13:51:40.340477: Pseudo dice [0.7565, 0.0538, 0.2123, 0.5081, 0.0, 0.6992, 0.0, 0.3906]
2025-05-29 13:51:40.340574: Epoch time: 88.97 s
2025-05-29 13:51:40.340622: Yayy! New best EMA pseudo Dice: 0.1424
2025-05-29 13:51:42.894340: 
2025-05-29 13:51:42.894572: Epoch 11
2025-05-29 13:51:42.894672: Current learning rate: 0.00967
2025-05-29 13:53:11.241737: train_loss -0.2389
2025-05-29 13:53:11.242031: val_loss -0.269
2025-05-29 13:53:11.242213: Pseudo dice [0.7548, 0.069, 0.1998, 0.5391, 0.0, 0.7021, 0.0, 0.4624]
2025-05-29 13:53:11.242333: Epoch time: 88.35 s
2025-05-29 13:53:11.242404: Yayy! New best EMA pseudo Dice: 0.1623
2025-05-29 13:53:13.936753: 
2025-05-29 13:53:13.937115: Epoch 12
2025-05-29 13:53:13.937216: Current learning rate: 0.00964
2025-05-29 13:54:42.218502: train_loss -0.2875
2025-05-29 13:54:42.218729: val_loss -0.2253
2025-05-29 13:54:42.218841: Pseudo dice [0.7513, 0.2808, 0.1981, 0.4406, 0.0, 0.747, 0.0, 0.4042]
2025-05-29 13:54:42.218921: Epoch time: 88.28 s
2025-05-29 13:54:42.219067: Yayy! New best EMA pseudo Dice: 0.1965
2025-05-29 13:44:58.853347: 
2025-05-29 13:44:58.853680: Epoch 13
2025-05-29 13:44:58.853815: Current learning rate: 0.00961
2025-05-29 13:45:29.803887: train_loss -0.2787
2025-05-29 13:45:29.804100: val_loss -0.2219
2025-05-29 13:45:29.804220: Pseudo dice [0.7637, 0.0025, 0.1991, 0.4954, 0.0, 0.7311, 0.0, 0.4067]
2025-05-29 13:45:29.804312: Epoch time: 30.95 s
2025-05-29 13:45:29.804459: Yayy! New best EMA pseudo Dice: 0.2093
2025-05-29 13:45:32.565314: 
2025-05-29 13:45:32.565437: Epoch 14
2025-05-29 13:45:32.565539: Current learning rate: 0.00958
2025-05-29 13:46:03.383724: train_loss -0.2062
2025-05-29 13:46:03.383915: val_loss -0.1595
2025-05-29 13:46:03.384029: Pseudo dice [0.7438, 0.0686, 0.1948, 0.4088, 0.0, 0.7803, 0.0, 0.3036]
2025-05-29 13:46:03.384106: Epoch time: 30.82 s
2025-05-29 13:46:03.384158: Yayy! New best EMA pseudo Dice: 0.2196
2025-05-29 13:46:05.931764: 
2025-05-29 13:46:05.932022: Epoch 15
2025-05-29 13:46:05.932147: Current learning rate: 0.00955
2025-05-29 13:46:36.919071: train_loss -0.306
2025-05-29 13:46:36.919382: val_loss -0.2595
2025-05-29 13:46:36.919537: Pseudo dice [0.7361, 0.3178, 0.2268, 0.6007, 0.0, 0.7843, 0.0, 0.3346]
2025-05-29 13:46:36.919619: Epoch time: 30.99 s
2025-05-29 13:46:36.919678: Yayy! New best EMA pseudo Dice: 0.2352
2025-05-29 13:46:39.610864: 
2025-05-29 13:46:39.611132: Epoch 16
2025-05-29 13:46:39.611257: Current learning rate: 0.00952
2025-05-29 13:47:10.480912: train_loss -0.3237
2025-05-29 13:47:10.481087: val_loss -0.2681
2025-05-29 13:47:10.481200: Pseudo dice [0.7892, 0.266, 0.2247, 0.5884, 0.0, 0.8205, 0.0, 0.3696]
2025-05-29 13:47:10.481275: Epoch time: 30.87 s
2025-05-29 13:47:10.481327: Yayy! New best EMA pseudo Dice: 0.2499
2025-05-29 13:47:13.125919: 
2025-05-29 13:47:13.126224: Epoch 17
2025-05-29 13:47:13.126317: Current learning rate: 0.00949
2025-05-29 13:47:44.136901: train_loss -0.3258
2025-05-29 13:47:44.137095: val_loss -0.2345
2025-05-29 13:47:44.137197: Pseudo dice [0.7908, 0.3047, 0.2626, 0.4974, 0.0, 0.8043, 0.0, 0.3967]
2025-05-29 13:47:44.137269: Epoch time: 31.01 s
2025-05-29 13:47:44.137367: Yayy! New best EMA pseudo Dice: 0.2631
2025-05-29 13:47:46.715835: 
2025-05-29 13:47:46.716200: Epoch 18
2025-05-29 13:47:46.716414: Current learning rate: 0.00946
2025-05-29 13:48:17.499744: train_loss -0.3624
2025-05-29 13:48:17.499961: val_loss -0.2518
2025-05-29 13:48:17.500073: Pseudo dice [0.7685, 0.3441, 0.1866, 0.5072, 0.0, 0.8119, 0.0, 0.4745]
2025-05-29 13:48:17.500155: Epoch time: 30.79 s
2025-05-29 13:48:17.500218: Yayy! New best EMA pseudo Dice: 0.2754
2025-05-29 13:48:21.041167: 
2025-05-29 13:48:21.041533: Epoch 19
2025-05-29 13:48:21.041677: Current learning rate: 0.00943
2025-05-29 13:48:52.126025: train_loss -0.3214
2025-05-29 13:48:52.126230: val_loss -0.3297
2025-05-29 13:48:52.126343: Pseudo dice [0.8169, 0.3825, 0.2919, 0.6143, 0.0, 0.8333, 0.0, 0.4267]
2025-05-29 13:48:52.126420: Epoch time: 31.09 s
2025-05-29 13:48:52.126483: Yayy! New best EMA pseudo Dice: 0.29
2025-05-29 13:48:54.515852: 
2025-05-29 13:48:54.516124: Epoch 20
2025-05-29 13:48:54.516217: Current learning rate: 0.0094
2025-05-29 13:49:25.364648: train_loss -0.3952
2025-05-29 13:49:25.364970: val_loss -0.2954
2025-05-29 13:49:25.365091: Pseudo dice [0.7926, 0.4034, 0.2491, 0.5597, 0.0, 0.824, 0.0, 0.3605]
2025-05-29 13:49:25.365164: Epoch time: 30.85 s
2025-05-29 13:49:25.365224: Yayy! New best EMA pseudo Dice: 0.3008
2025-05-29 13:49:27.800416: 
2025-05-29 13:49:27.800717: Epoch 21
2025-05-29 13:49:27.800931: Current learning rate: 0.00937
2025-05-29 13:49:58.775275: train_loss -0.4049
2025-05-29 13:49:58.775553: val_loss -0.3839
2025-05-29 13:49:58.775674: Pseudo dice [0.8137, 0.3583, 0.1549, 0.5954, 0.0, 0.803, 0.0, 0.4828]
2025-05-29 13:49:58.775753: Epoch time: 30.98 s
2025-05-29 13:49:58.775803: Yayy! New best EMA pseudo Dice: 0.3109
2025-05-29 13:50:01.060791: 
2025-05-29 13:50:01.060968: Epoch 22
2025-05-29 13:50:01.061097: Current learning rate: 0.00934
2025-05-29 13:50:32.027237: train_loss -0.3865
2025-05-29 13:50:32.027538: val_loss -0.3323
2025-05-29 13:50:32.027657: Pseudo dice [0.8185, 0.3744, 0.2709, 0.5831, 0.0, 0.7464, 0.155, 0.5318]
2025-05-29 13:50:32.027732: Epoch time: 30.97 s
2025-05-29 13:50:32.027782: Yayy! New best EMA pseudo Dice: 0.3233
2025-05-29 13:50:34.502947: 
2025-05-29 13:50:34.503231: Epoch 23
2025-05-29 13:50:34.503325: Current learning rate: 0.00931
2025-05-29 13:51:05.299315: train_loss -0.4138
2025-05-29 13:51:05.299526: val_loss -0.3759
2025-05-29 13:51:05.299635: Pseudo dice [0.8065, 0.3803, 0.2226, 0.6017, 0.0, 0.836, 0.1998, 0.4328]
2025-05-29 13:51:05.299704: Epoch time: 30.8 s
2025-05-29 13:51:05.299783: Yayy! New best EMA pseudo Dice: 0.3344
2025-05-29 13:51:08.118752: 
2025-05-29 13:51:08.119110: Epoch 24
2025-05-29 13:51:08.119236: Current learning rate: 0.00928
2025-05-29 13:51:39.882534: train_loss -0.4144
2025-05-29 13:51:39.882725: val_loss -0.23
2025-05-29 13:51:39.882836: Pseudo dice [0.7978, 0.3988, 0.2032, 0.3538, 0.0, 0.7812, 0.2632, 0.3356]
2025-05-29 13:51:39.882912: Epoch time: 31.77 s
2025-05-29 13:51:39.883008: Yayy! New best EMA pseudo Dice: 0.3402
2025-05-29 13:51:42.410969: 
2025-05-29 13:51:42.411197: Epoch 25
2025-05-29 13:51:42.411319: Current learning rate: 0.00925
2025-05-29 13:52:13.229824: train_loss -0.487
2025-05-29 13:52:13.230025: val_loss -0.2565
2025-05-29 13:52:13.230137: Pseudo dice [0.822, 0.4263, 0.2682, 0.4093, 0.0, 0.8315, 0.3277, 0.4912]
2025-05-29 13:52:13.230210: Epoch time: 30.82 s
2025-05-29 13:52:13.230434: Yayy! New best EMA pseudo Dice: 0.3509
2025-05-29 13:52:15.749880: 
2025-05-29 13:52:15.750081: Epoch 26
2025-05-29 13:52:15.750176: Current learning rate: 0.00922
2025-05-29 13:52:46.743666: train_loss -0.5078
2025-05-29 13:52:46.743933: val_loss -0.3801
2025-05-29 13:52:46.744111: Pseudo dice [0.8142, 0.472, 0.2434, 0.5658, 0.0, 0.8699, 0.3897, 0.5284]
2025-05-29 13:52:46.744216: Epoch time: 31.0 s
2025-05-29 13:52:46.744289: Yayy! New best EMA pseudo Dice: 0.3643
2025-05-29 13:52:49.875711: 
2025-05-29 13:52:49.876041: Epoch 27
2025-05-29 13:52:49.876185: Current learning rate: 0.00919
2025-05-29 13:53:20.569735: train_loss -0.5158
2025-05-29 13:53:20.569934: val_loss -0.3875
2025-05-29 13:53:20.570045: Pseudo dice [0.8126, 0.4261, 0.2425, 0.5285, 0.0, 0.8332, 0.4149, 0.5153]
2025-05-29 13:53:20.570119: Epoch time: 30.7 s
2025-05-29 13:53:20.570168: Yayy! New best EMA pseudo Dice: 0.375
2025-05-29 13:53:23.173003: 
2025-05-29 13:53:23.173373: Epoch 28
2025-05-29 13:53:23.173490: Current learning rate: 0.00916
2025-05-29 13:53:54.314245: train_loss -0.5271
2025-05-29 13:53:54.314595: val_loss -0.3519
2025-05-29 13:53:54.314713: Pseudo dice [0.8508, 0.5087, 0.2626, 0.4882, 0.0, 0.8363, 0.4041, 0.5778]
2025-05-29 13:53:54.314794: Epoch time: 31.14 s
2025-05-29 13:53:54.314853: Yayy! New best EMA pseudo Dice: 0.3866
2025-05-29 13:53:57.578997: 
2025-05-29 13:53:57.579279: Epoch 29
2025-05-29 13:53:57.579416: Current learning rate: 0.00913
2025-05-29 13:54:28.401665: train_loss -0.5425
2025-05-29 13:54:28.401915: val_loss -0.408
2025-05-29 13:54:28.402036: Pseudo dice [0.8498, 0.4722, 0.2763, 0.4814, 0.0, 0.8391, 0.4013, 0.5046]
2025-05-29 13:54:28.402120: Epoch time: 30.82 s
2025-05-29 13:54:28.402177: Yayy! New best EMA pseudo Dice: 0.3958
2025-05-29 13:54:31.130961: 
2025-05-29 13:54:31.131074: Epoch 30
2025-05-29 13:54:31.131162: Current learning rate: 0.0091
2025-05-29 13:55:02.113898: train_loss -0.5272
2025-05-29 13:55:02.114130: val_loss -0.3204
2025-05-29 13:55:02.114247: Pseudo dice [0.8153, 0.4855, 0.2633, 0.4434, 0.0, 0.8096, 0.3553, 0.4957]
2025-05-29 13:55:02.114416: Epoch time: 30.98 s
2025-05-29 13:55:02.114495: Yayy! New best EMA pseudo Dice: 0.4021
2025-05-29 13:55:04.733187: 
2025-05-29 13:55:04.733561: Epoch 31
2025-05-29 13:55:04.733695: Current learning rate: 0.00907
2025-05-29 13:55:35.647486: train_loss -0.5141
2025-05-29 13:55:35.647698: val_loss -0.4054
2025-05-29 13:55:35.647813: Pseudo dice [0.8145, 0.4398, 0.2992, 0.5409, 0.0, 0.8154, 0.4553, 0.437]
2025-05-29 13:55:35.647897: Epoch time: 30.92 s
2025-05-29 13:55:35.647948:using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [464.0, 449.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset228_adomi', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 464, 449], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 30.38488375492876, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.48317688397075}, '1': {'max': 255.0, 'mean': 30.448724995229867, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.54321923522895}, '2': {'max': 255.0, 'mean': 30.492282963433194, 'median': 11.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 173.0, 'std': 38.58594251904467}}} 

2025-05-29 13:39:05.277831: Unable to plot network architecture: nnUNet_compile is enabled!
2025-05-29 13:39:05.294132: 
2025-05-29 13:39:05.294474: Epoch 0
2025-05-29 13:39:05.294817: Current learning rate: 0.01
2025-05-29 13:41:30.240919: train_loss 0.5125
2025-05-29 13:41:30.241390: val_loss 0.3285
2025-05-29 13:41:30.241523: Pseudo dice [0.0346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:41:30.241604: Epoch time: 144.95 s
2025-05-29 13:41:30.241657: Yayy! New best EMA pseudo Dice: 0.0043
2025-05-29 13:41:31.904492: 
2025-05-29 13:41:31.904788: Epoch 1
2025-05-29 13:41:31.904921: Current learning rate: 0.00997
2025-05-29 13:42:46.118631: train_loss 0.2818
2025-05-29 13:42:46.118981: val_loss 0.2169
2025-05-29 13:42:46.119107: Pseudo dice [0.4961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:42:46.119199: Epoch time: 74.22 s
2025-05-29 13:42:46.119286: Yayy! New best EMA pseudo Dice: 0.0101
2025-05-29 13:42:48.575545: 
2025-05-29 13:42:48.575778: Epoch 2
2025-05-29 13:42:48.575899: Current learning rate: 0.00994
2025-05-29 13:44:16.610590: train_loss 0.1695
2025-05-29 13:44:16.610827: val_loss 0.1053
2025-05-29 13:44:16.610943: Pseudo dice [0.6044, 0.0, 0.0, 0.3209, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:44:16.611017: Epoch time: 88.04 s
2025-05-29 13:44:16.611073: Yayy! New best EMA pseudo Dice: 0.0206
2025-05-29 13:44:19.425844: 
2025-05-29 13:44:19.426208: Epoch 3
2025-05-29 13:44:19.426346: Current learning rate: 0.00991
2025-05-29 13:45:32.447678: train_loss 0.1089
2025-05-29 13:45:32.448018: val_loss 0.0633
2025-05-29 13:45:32.448297: Pseudo dice [0.6021, 0.0, 0.0, 0.3324, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:45:32.448369: Epoch time: 73.02 s
2025-05-29 13:45:32.448416: Yayy! New best EMA pseudo Dice: 0.0303
2025-05-29 13:45:35.134413: 
2025-05-29 13:45:35.134842: Epoch 4
2025-05-29 13:45:35.134950: Current learning rate: 0.00988
2025-05-29 13:46:49.114843: train_loss 0.0959
2025-05-29 13:46:49.115131: val_loss -0.0076
2025-05-29 13:46:49.115245: Pseudo dice [0.6509, 0.0, 0.0, 0.3982, 0.0, 0.0, 0.0, 0.0]
2025-05-29 13:46:49.115318: Epoch time: 73.98 s
2025-05-29 13:46:49.115367: Yayy! New best EMA pseudo Dice: 0.0404
2025-05-29 13:46:51.790313: 
2025-05-29 13:46:51.790821: Epoch 5
2025-05-29 13:46:51.790930: Current learning rate: 0.00985
2025-05-29 13:48:06.849682: train_loss -0.0383
2025-05-29 13:48:06.849950: val_loss -0.0713
2025-05-29 13:48:06.850070: Pseudo dice [0.7501, 0.0455, 0.0, 0.3621, 0.0, 0.7017, 0.0, 0.0]
2025-05-29 13:48:06.850147: Epoch time: 75.06 s
2025-05-29 13:48:06.850288: Yayy! New best EMA pseudo Dice: 0.0596
2025-05-29 13:48:09.658667: 
2025-05-29 13:48:09.658964: Epoch 6
2025-05-29 13:48:09.659064: Current learning rate: 0.00982
2025-05-29 13:49:24.616676: train_loss -0.0651
2025-05-29 13:49:24.616912: val_loss -0.1478
2025-05-29 13:49:24.617072: Pseudo dice [0.7501, 0.0072, 0.0009, 0.5182, 0.0, 0.8115, 0.0, 0.0313]
2025-05-29 13:49:24.617165: Epoch time: 74.96 s
2025-05-29 13:49:24.617220: Yayy! New best EMA pseudo Dice: 0.0801
2025-05-29 13:49:27.056562: 
2025-05-29 13:49:27.056766: Epoch 7
2025-05-29 13:49:27.056891: Current learning rate: 0.00979
2025-05-29 13:50:41.179045: train_loss -0.1638
2025-05-29 13:50:41.179356: val_loss -0.2172
2025-05-29 13:50:41.179670: Pseudo dice [0.7656, 0.0759, 0.0, 0.551, 0.0, 0.7302, 0.0, 0.1214]
2025-05-29 13:50:41.179760: Epoch time: 74.12 s
2025-05-29 13:50:41.179811: Yayy! New best EMA pseudo Dice: 0.1001
2025-05-29 13:50:44.415696: 
2025-05-29 13:50:44.416089: Epoch 8
2025-05-29 13:50:44.416201: Current learning rate: 0.00976
2025-05-29 13:51:58.403081: train_loss -0.1715
2025-05-29 13:51:58.403370: val_loss -0.1612
2025-05-29 13:51:58.403501: Pseudo dice [0.7275, 0.005, 0.0008, 0.4458, 0.0, 0.7528, 0.0, 0.2572]
2025-05-29 13:51:58.403590: Epoch time: 73.99 s
2025-05-29 13:51:58.403651: Yayy! New best EMA pseudo Dice: 0.1175
2025-05-29 13:52:00.855127: 
2025-05-29 13:52:00.855444: Epoch 9
2025-05-29 13:52:00.855634: Current learning rate: 0.00973
2025-05-29 13:53:14.058984: train_loss -0.1888
2025-05-29 13:53:14.059206: val_loss -0.1509
2025-05-29 13:53:14.059384: Pseudo dice [0.7552, 0.0001, 0.0044, 0.4089, 0.0, 0.8499, 0.0, 0.129]
2025-05-29 13:53:14.059483: Epoch time: 73.21 s
2025-05-29 13:53:14.059547: Yayy! New best EMA pseudo Dice: 0.1326
2025-05-29 13:53:16.613455: 
2025-05-29 13:53:16.613728: Epoch 10
2025-05-29 13:53:16.613829: Current learning rate: 0.0097
2025-05-29 13:54:31.096562: train_loss -0.161
2025-05-29 13:54:31.096801: val_loss -0.254
2025-05-29 13:54:31.096915: Pseudo dice [0.7925, 0.1726, 0.2083, 0.5005, 0.0, 0.8038, 0.0, 0.3129]
2025-05-29 13:54:31.097002: Epoch time: 74.48 s
2025-05-29 13:54:31.097055: Yayy! New best EMA pseudo Dice: 0.1542
2025-05-29 13:54:33.676517: 
2025-05-29 13:54:33.676789: Epoch 11
2025-05-29 13:54:33.676915: Current learning rate: 0.00967
2025-05-29 13:55:47.941747: train_loss -0.2687
2025-05-29 13:55:47.942032: val_loss -0.183
2025-05-29 13:55:47.942156: Pseudo dice [0.7951, 0.1262, 0.1525, 0.3736, 0.0, 0.847, 0.0, 0.3116]
2025-05-29 13:55:47.942263: Epoch time: 74.27 s
2025-05-29 13:55:47.942312: Yayy! New best EMA pseudo Dice: 0.1714
2025-05-29 13:55:50.629311: 
2025-05-29 13:55:50.629670: Epoch 12
2025-05-29 13:55:50.629836: Current learning rate: 0.00964
2025-05-29 13:57:04.798558: train_loss -0.2858
2025-05-29 13:57:04.798783: val_loss -0.2401
2025-05-29 13:57:04.798894: Pseudo dice [0.8286, 0.3093, 0.2145, 0.3867, 0.0, 0.8232, 0.0, 0.3878]
2025-05-29 13:57:04.798976: Epoch time: 74.17 s Yayy! New best EMA pseudo Dice: 0.4094
2025-05-29 13:55:38.162233: 
2025-05-29 13:55:38.162536: Epoch 32
2025-05-29 13:55:38.162655: Current learning rate: 0.00903
2025-05-29 13:56:09.111722: train_loss -0.5762
2025-05-29 13:56:09.111919: val_loss -0.4497
2025-05-29 13:56:09.112029: Pseudo dice [0.85, 0.4342, 0.2826, 0.5369, 0.0, 0.8893, 0.3757, 0.5803]
2025-05-29 13:56:09.112103: Epoch time: 30.95 s
2025-05-29 13:56:09.112149: Yayy! New best EMA pseudo Dice: 0.4178
2025-05-29 13:56:11.703966: 
2025-05-29 13:56:11.704256: Epoch 33
2025-05-29 13:56:11.704368: Current learning rate: 0.009
2025-05-29 13:56:42.503691: train_loss -0.5775
2025-05-29 13:56:42.503931: val_loss -0.3933
2025-05-29 13:56:42.504064: Pseudo dice [0.8301, 0.464, 0.2753, 0.5273, 0.0, 0.8152, 0.4238, 0.471]
2025-05-29 13:56:42.504142: Epoch time: 30.8 s
2025-05-29 13:56:42.504193: Yayy! New best EMA pseudo Dice: 0.4236
2025-05-29 13:56:45.228495: 
2025-05-29 13:56:45.228613: Epoch 34
2025-05-29 13:56:45.228709: Current learning rate: 0.00897
2025-05-29 13:57:16.223608: train_loss -0.5414
2025-05-29 13:57:16.223834: val_loss -0.4132
2025-05-29 13:57:16.223954: Pseudo dice [0.8413, 0.4596, 0.283, 0.5669, 0.0, 0.8389, 0.4607, 0.5064]
2025-05-29 13:57:16.224035: Epoch time: 31.0 s
2025-05-29 13:57:16.224087: Yayy! New best EMA pseudo Dice: 0.4307
2025-05-29 13:57:18.902705: 
2025-05-29 13:57:18.902955: Epoch 35
2025-05-29 13:57:18.903069: Current learning rate: 0.00894
2025-05-29 13:57:50.009768: train_loss -0.5934
2025-05-29 13:57:50.009959: val_loss -0.4279
2025-05-29 13:57:50.010074: Pseudo dice [0.8512, 0.4912, 0.2635, 0.529, 0.0, 0.8469, 0.4689, 0.5517]
2025-05-29 13:57:50.010155: Epoch time: 31.11 s
2025-05-29 13:57:50.010211: Yayy! New best EMA pseudo Dice: 0.4377
2025-05-29 13:57:53.088592: 
2025-05-29 13:57:53.088987: Epoch 36
2025-05-29 13:57:53.089081: Current learning rate: 0.00891
2025-05-29 13:58:23.971418: train_loss -0.6079
2025-05-29 13:58:23.971649: val_loss -0.4656
2025-05-29 13:58:23.971771: Pseudo dice [0.8435, 0.4723, 0.2771, 0.6658, 0.0, 0.8414, 0.4161, 0.48]
2025-05-29 13:58:23.971852: Epoch time: 30.88 s
2025-05-29 13:58:23.971904: Yayy! New best EMA pseudo Dice: 0.4439
2025-05-29 13:58:26.387168: 
2025-05-29 13:58:26.387588: Epoch 37
2025-05-29 13:58:26.387684: Current learning rate: 0.00888
2025-05-29 13:58:57.474931: train_loss -0.6493
2025-05-29 13:58:57.475384: val_loss -0.4647
2025-05-29 13:58:57.475783: Pseudo dice [0.8508, 0.4594, 0.2522, 0.606, 0.0, 0.8578, 0.4308, 0.5397]
2025-05-29 13:58:57.475998: Epoch time: 31.09 s
2025-05-29 13:58:57.476327: Yayy! New best EMA pseudo Dice: 0.4494
2025-05-29 13:59:00.831723: 
2025-05-29 13:59:00.832006: Epoch 38
2025-05-29 13:59:00.832126: Current learning rate: 0.00885
2025-05-29 14:00:02.827022: train_loss -0.59
2025-05-29 14:00:02.827195: val_loss -0.4143
2025-05-29 14:00:02.827307: Pseudo dice [0.8237, 0.4961, 0.243, 0.5213, 0.0, 0.8331, 0.42, 0.5739]
2025-05-29 14:00:02.827380: Epoch time: 62.0 s
2025-05-29 14:00:02.827430: Yayy! New best EMA pseudo Dice: 0.4534
2025-05-29 14:00:05.468926: 
2025-05-29 14:00:05.469237: Epoch 39
2025-05-29 14:00:05.469399: Current learning rate: 0.00882
2025-05-29 14:01:07.831385: train_loss -0.5622
2025-05-29 14:01:07.831630: val_loss -0.3728
2025-05-29 14:01:07.831755: Pseudo dice [0.8181, 0.4048, 0.2884, 0.528, 0.0, 0.7919, 0.4716, 0.5817]
2025-05-29 14:01:07.831834: Epoch time: 62.36 s
2025-05-29 14:01:07.831886: Yayy! New best EMA pseudo Dice: 0.4566
2025-05-29 14:01:10.991749: 
2025-05-29 14:01:10.992027: Epoch 40
2025-05-29 14:01:10.992240: Current learning rate: 0.00879
2025-05-29 14:01:42.667922: train_loss -0.6383
2025-05-29 14:01:42.668261: val_loss -0.4166
2025-05-29 14:01:42.668473: Pseudo dice [0.855, 0.4891, 0.3007, 0.5318, 0.0, 0.8746, 0.4826, 0.5117]
2025-05-29 14:01:42.668590: Epoch time: 31.68 s
2025-05-29 14:01:42.668666: Yayy! New best EMA pseudo Dice: 0.4615
2025-05-29 14:01:45.410180: 
2025-05-29 14:01:45.410493: Epoch 41
2025-05-29 14:01:45.410680: Current learning rate: 0.00876
2025-05-29 14:02:16.406269: train_loss -0.6556
2025-05-29 14:02:16.406622: val_loss -0.4869
2025-05-29 14:02:16.406731: Pseudo dice [0.835, 0.4625, 0.305, 0.6336, 0.0, 0.865, 0.4814, 0.5813]
2025-05-29 14:02:16.406803: Epoch time: 31.0 s
2025-05-29 14:02:16.406850: Yayy! New best EMA pseudo Dice: 0.4674
2025-05-29 14:02:19.095428: 
2025-05-29 14:02:19.095720: Epoch 42
2025-05-29 14:02:19.095827: Current learning rate: 0.00873
2025-05-29 14:02:50.052640: train_loss -0.6355
2025-05-29 14:02:50.052872: val_loss -0.379
2025-05-29 14:02:50.053096: Pseudo dice [0.8591, 0.5205, 0.3348, 0.5004, 0.0, 0.8306, 0.4669, 0.5587]
2025-05-29 14:02:50.053198: Epoch time: 30.96 s
2025-05-29 14:02:50.053296: Yayy! New best EMA pseudo Dice: 0.4716
2025-05-29 14:02:52.922292: 
2025-05-29 14:02:52.922619: Epoch 43
2025-05-29 14:02:52.922716: Current learning rate: 0.0087
2025-05-29 14:03:24.067718: train_loss -0.6303
2025-05-29 14:03:24.068005: val_loss -0.4978
2025-05-29 14:03:24.068179: Pseudo dice [0.8636, 0.4938, 0.3304, 0.5534, 0.0, 0.9072, 0.4679, 0.558]
2025-05-29 14:03:24.068302: Epoch time: 31.15 s
2025-05-29 14:03:24.068357: Yayy! New best EMA pseudo Dice: 0.4766
2025-05-29 14:03:26.755923: 
2025-05-29 14:03:26.756195: Epoch 44
2025-05-29 14:03:26.756377: Current learning rate: 0.00867
2025-05-29 14:03:57.563651: train_loss -0.6695
2025-05-29 14:03:57.563844: val_loss -0.4589
2025-05-29 14:03:57.563959: Pseudo dice [0.8462, 0.5265, 0.3573, 0.57, 0.0, 0.8577, 0.4925, 0.5364]
2025-05-29 14:03:57.564036: Epoch time: 30.81 s
2025-05-29 14:03:57.564088: Yayy! New best EMA pseudo Dice: 0.4813
2025-05-29 14:04:00.507159: 
2025-05-29 14:04:00.507499: Epoch 45
2025-05-29 14:04:00.507593: Current learning rate: 0.00864
2025-05-29 14:04:31.134756: train_loss -0.6949
2025-05-29 14:04:31.134979: val_loss -0.4558
2025-05-29 14:04:31.135096: Pseudo dice [0.8555, 0.5605, 0.3174, 0.5619, 0.0, 0.8788, 0.4719, 0.5335]
2025-05-29 14:04:31.135179: Epoch time: 30.63 s
2025-05-29 14:04:31.135231: Yayy! New best EMA pseudo Dice: 0.4854
2025-05-29 14:04:34.001571: 
2025-05-29 14:04:34.001764: Epoch 46
2025-05-29 14:04:34.001865: Current learning rate: 0.00861
2025-05-29 14:05:04.896340: train_loss -0.6987
2025-05-29 14:05:04.896635: val_loss -0.4897
2025-05-29 14:05:04.896771: Pseudo dice [0.8539, 0.5541, 0.2877, 0.5769, 0.0, 0.8914, 0.479, 0.599]
2025-05-29 14:05:04.896859: Epoch time: 30.9 s
2025-05-29 14:05:04.896933: Yayy! New best EMA pseudo Dice: 0.4899
2025-05-29 14:05:07.927820: 
2025-05-29 14:05:07.928005: Epoch 47
2025-05-29 14:05:07.928124: Current learning rate: 0.00858
2025-05-29 14:06:00.097877: train_loss -0.681
2025-05-29 14:06:00.098050: val_loss -0.4641
2025-05-29 14:06:00.098154: Pseudo dice [0.8287, 0.5217, 0.3356, 0.5905, 0.0, 0.8605, 0.4627, 0.4784]
2025-05-29 14:06:00.098220: Epoch time: 52.17 s
2025-05-29 14:06:00.098266: Yayy! New best EMA pseudo Dice: 0.4918
2025-05-29 14:06:02.818759: 
2025-05-29 14:06:02.819068: Epoch 48
2025-05-29 14:06:02.819211: Current learning rate: 0.00855
2025-05-29 14:06:50.604978: train_loss -0.6697
2025-05-29 14:06:50.605162: val_loss -0.5011
2025-05-29 14:06:50.605309: Pseudo dice [0.8586, 0.554, 0.2282, 0.6215, 0.0, 0.8623, 0.4245, 0.5209]
2025-05-29 14:06:50.605428: Epoch time: 47.79 s
2025-05-29 14:06:50.605511: Yayy! New best EMA pseudo Dice: 0.4935
2025-05-29 14:06:53.453069: 
2025-05-29 14:06:53.453391: Epoch 49
2025-05-29 14:06:53.453523: Current learning rate: 0.00852
2025-05-29 14:07:24.437020: train_loss -0.6145
2025-05-29 14:07:24.437263: val_loss -0.381
2025-05-29 14:07:24.437394: Pseudo dice [0.8346, 0.4636, 0.3079, 0.5371, 0.0, 0.8636, 0.5164, 0.4605]
2025-05-29 14:07:24.437487: Epoch time: 30.99 s
2025-05-29 14:07:24.989176: Yayy! New best EMA pseudo Dice: 0.494
2025-05-29 14:07:27.884730: 
2025-05-29 14:07:27.884907: Epoch 50
2025-05-29 14:07:27.884996: Current learning rate: 0.00849
2025-05-29 14:07:58.791427: train_loss -0.6607
2025-05-29 14:07:58.791654: val_loss -0.5207
2025-05-29 14:07:58.791815: Pseudo dice [0.8755, 0.5573, 0.282, 0.5931, 0.0, 0.8895, 0.5272, 0.6148]
2025-05-29 14:07:58.791899: Epoch time: 30.91 s
2025-05-29 14:07:58.791971: Yayy! New best EMA pseudo Dice: 0.1833
2025-05-29 13:51:34.312026: 
2025-05-29 13:51:34.312358: Epoch 13
2025-05-29 13:51:34.312476: Current learning rate: 0.00961
2025-05-29 13:52:47.320752: train_loss -0.3244
2025-05-29 13:52:47.321236: val_loss -0.2273
2025-05-29 13:52:47.321480: Pseudo dice [0.8105, 0.3177, 0.2612, 0.3879, 0.0, 0.8412, 0.0, 0.3574]
2025-05-29 13:52:47.321616: Epoch time: 73.01 s
2025-05-29 13:52:47.321701: Yayy! New best EMA pseudo Dice: 0.2022
2025-05-29 13:52:50.282901: 
2025-05-29 13:52:50.283180: Epoch 14
2025-05-29 13:52:50.283305: Current learning rate: 0.00958
2025-05-29 13:54:03.294923: train_loss -0.3346
2025-05-29 13:54:03.295208: val_loss -0.2309
2025-05-29 13:54:03.295325: Pseudo dice [0.8218, 0.3563, 0.2246, 0.3271, 0.0, 0.8636, 0.0, 0.3383]
2025-05-29 13:54:03.295415: Epoch time: 73.01 s
2025-05-29 13:54:03.295492: Yayy! New best EMA pseudo Dice: 0.2186
2025-05-29 13:54:05.904505: 
2025-05-29 13:54:05.904820: Epoch 15
2025-05-29 13:54:05.904936: Current learning rate: 0.00955
2025-05-29 13:55:18.816413: train_loss -0.3963
2025-05-29 13:55:18.816696: val_loss -0.3052
2025-05-29 13:55:18.816824: Pseudo dice [0.8332, 0.4474, 0.2275, 0.5118, 0.0, 0.824, 0.0, 0.2607]
2025-05-29 13:55:18.816913: Epoch time: 72.91 s
2025-05-29 13:55:18.816975: Yayy! New best EMA pseudo Dice: 0.2355
2025-05-29 13:55:21.534347: 
2025-05-29 13:55:21.534744: Epoch 16
2025-05-29 13:55:21.534842: Current learning rate: 0.00952
2025-05-29 13:56:34.224378: train_loss -0.3821
2025-05-29 13:56:34.224662: val_loss -0.2208
2025-05-29 13:56:34.224784: Pseudo dice [0.7993, 0.3987, 0.2555, 0.3105, 0.0, 0.8504, 0.0, 0.3248]
2025-05-29 13:56:34.224864: Epoch time: 72.69 s
2025-05-29 13:56:34.224962: Yayy! New best EMA pseudo Dice: 0.2487
2025-05-29 13:56:37.076910: 
2025-05-29 13:56:37.077145: Epoch 17
2025-05-29 13:56:37.077245: Current learning rate: 0.00949
2025-05-29 13:57:50.415933: train_loss -0.3673
2025-05-29 13:57:50.416160: val_loss -0.1277
2025-05-29 13:57:50.416272: Pseudo dice [0.823, 0.3312, 0.2516, 0.2171, 0.0, 0.8366, 0.0, 0.3413]
2025-05-29 13:57:50.416358: Epoch time: 73.34 s
2025-05-29 13:57:50.416523: Yayy! New best EMA pseudo Dice: 0.2589
2025-05-29 13:57:53.469878: 
2025-05-29 13:57:53.470295: Epoch 18
2025-05-29 13:57:53.470406: Current learning rate: 0.00946
2025-05-29 13:59:06.816624: train_loss -0.3793
2025-05-29 13:59:06.816901: val_loss -0.3037
2025-05-29 13:59:06.817018: Pseudo dice [0.8134, 0.3788, 0.2885, 0.4727, 0.0, 0.8539, 0.0, 0.3526]
2025-05-29 13:59:06.817100: Epoch time: 73.35 s
2025-05-29 13:59:06.817177: Yayy! New best EMA pseudo Dice: 0.2725
2025-05-29 13:59:10.260434: 
2025-05-29 13:59:10.260867: Epoch 19
2025-05-29 13:59:10.261043: Current learning rate: 0.00943
2025-05-29 14:00:57.079578: train_loss -0.4152
2025-05-29 14:00:57.079942: val_loss -0.2562
2025-05-29 14:00:57.080070: Pseudo dice [0.8365, 0.4579, 0.245, 0.3906, 0.0, 0.8348, 0.0, 0.3899]
2025-05-29 14:00:57.080169: Epoch time: 106.82 s
2025-05-29 14:00:57.080218: Yayy! New best EMA pseudo Dice: 0.2847
2025-05-29 14:00:59.887175: 
2025-05-29 14:00:59.887503: Epoch 20
2025-05-29 14:00:59.887606: Current learning rate: 0.0094
2025-05-29 14:02:13.330137: train_loss -0.4146
2025-05-29 14:02:13.330483: val_loss -0.3573
2025-05-29 14:02:13.330607: Pseudo dice [0.8373, 0.4561, 0.2333, 0.4565, 0.0, 0.8622, 0.0, 0.5003]
2025-05-29 14:02:13.330706: Epoch time: 73.44 s
2025-05-29 14:02:13.330757: Yayy! New best EMA pseudo Dice: 0.298
2025-05-29 14:02:16.163278: 
2025-05-29 14:02:16.163593: Epoch 21
2025-05-29 14:02:16.163704: Current learning rate: 0.00937
2025-05-29 14:03:30.079401: train_loss -0.4286
2025-05-29 14:03:30.079632: val_loss -0.32
2025-05-29 14:03:30.079750: Pseudo dice [0.8368, 0.4076, 0.2254, 0.4695, 0.0, 0.8655, 0.0622, 0.3888]
2025-05-29 14:03:30.079843: Epoch time: 73.92 s
2025-05-29 14:03:30.079980: Yayy! New best EMA pseudo Dice: 0.3089
2025-05-29 14:03:32.827002: 
2025-05-29 14:03:32.827214: Epoch 22
2025-05-29 14:03:32.827466: Current learning rate: 0.00934
2025-05-29 14:04:43.302118: train_loss -0.4234
2025-05-29 14:04:43.302321: val_loss -0.3293
2025-05-29 14:04:43.302434: Pseudo dice [0.8404, 0.4647, 0.2947, 0.4244, 0.0, 0.84, 0.0228, 0.3839]
2025-05-29 14:04:43.302533: Epoch time: 70.48 s
2025-05-29 14:04:43.302588: Yayy! New best EMA pseudo Dice: 0.3189
2025-05-29 14:04:45.971381: 
2025-05-29 14:04:45.971794: Epoch 23
2025-05-29 14:04:45.971913: Current learning rate: 0.00931
2025-05-29 14:06:12.621594: train_loss -0.4774
2025-05-29 14:06:12.621769: val_loss -0.3595
2025-05-29 14:06:12.621881: Pseudo dice [0.8385, 0.5357, 0.3228, 0.4431, 0.0, 0.9192, 0.0521, 0.4446]
2025-05-29 14:06:12.621967: Epoch time: 86.65 s
2025-05-29 14:06:12.622021: Yayy! New best EMA pseudo Dice: 0.3315
2025-05-29 14:06:15.560834: 
2025-05-29 14:06:15.561083: Epoch 24
2025-05-29 14:06:15.561179: Current learning rate: 0.00928
2025-05-29 14:07:31.577776: train_loss -0.5324
2025-05-29 14:07:31.577988: val_loss -0.46
2025-05-29 14:07:31.578103: Pseudo dice [0.8631, 0.4892, 0.2614, 0.6197, 0.0, 0.9248, 0.1046, 0.5542]
2025-05-29 14:07:31.578176: Epoch time: 76.02 s
2025-05-29 14:07:31.578226: Yayy! New best EMA pseudo Dice: 0.346
2025-05-29 14:07:34.261495: 
2025-05-29 14:07:34.261812: Epoch 25
2025-05-29 14:07:34.261946: Current learning rate: 0.00925
2025-05-29 14:08:46.123352: train_loss -0.5436
2025-05-29 14:08:46.123546: val_loss -0.3804
2025-05-29 14:08:46.123658: Pseudo dice [0.8357, 0.5811, 0.3566, 0.4572, 0.0, 0.8858, 0.2149, 0.4395]
2025-05-29 14:08:46.123881: Epoch time: 71.86 s
2025-05-29 14:08:46.123964: Yayy! New best EMA pseudo Dice: 0.3586
2025-05-29 14:08:48.796642: 
2025-05-29 14:08:48.796770: Epoch 26
2025-05-29 14:08:48.796912: Current learning rate: 0.00922
2025-05-29 14:10:01.703037: train_loss -0.5201
2025-05-29 14:10:01.703334: val_loss -0.2662
2025-05-29 14:10:01.703466: Pseudo dice [0.8439, 0.475, 0.2169, 0.3001, 0.0, 0.8956, 0.2692, 0.397]
2025-05-29 14:10:01.703568: Epoch time: 72.91 s
2025-05-29 14:10:01.703618: Yayy! New best EMA pseudo Dice: 0.3652
2025-05-29 14:10:05.578966: 
2025-05-29 14:10:05.579295: Epoch 27
2025-05-29 14:10:05.579458: Current learning rate: 0.00919
2025-05-29 14:11:18.729669: train_loss -0.5499
2025-05-29 14:11:18.729901: val_loss -0.4514
2025-05-29 14:11:18.730015: Pseudo dice [0.8542, 0.5136, 0.3527, 0.4831, 0.0, 0.8598, 0.3558, 0.5393]
2025-05-29 14:11:18.730107: Epoch time: 73.15 s
2025-05-29 14:11:18.730160: Yayy! New best EMA pseudo Dice: 0.3781
2025-05-29 14:11:21.271023: 
2025-05-29 14:11:21.271359: Epoch 28
2025-05-29 14:11:21.271608: Current learning rate: 0.00916
2025-05-29 14:12:33.763328: train_loss -0.5479
2025-05-29 14:12:33.763609: val_loss -0.3437
2025-05-29 14:12:33.763730: Pseudo dice [0.8101, 0.4193, 0.2421, 0.4319, 0.0, 0.8561, 0.3964, 0.4647]
2025-05-29 14:12:33.763821: Epoch time: 72.49 s
2025-05-29 14:12:33.763948: Yayy! New best EMA pseudo Dice: 0.3856
2025-05-29 14:12:36.576181: 
2025-05-29 14:12:36.576511: Epoch 29
2025-05-29 14:12:36.576652: Current learning rate: 0.00913
2025-05-29 14:13:50.129094: train_loss -0.5395
2025-05-29 14:13:50.129327: val_loss -0.3721
2025-05-29 14:13:50.129439: Pseudo dice [0.8423, 0.4625, 0.2787, 0.4852, 0.0, 0.9102, 0.4056, 0.3995]
2025-05-29 14:13:50.129560: Epoch time: 73.55 s
2025-05-29 14:13:50.129616: Yayy! New best EMA pseudo Dice: 0.3943
2025-05-29 14:13:53.487294: 
2025-05-29 14:13:53.487724: Epoch 30
2025-05-29 14:13:53.487866: Current learning rate: 0.0091
2025-05-29 14:15:06.173658: train_loss -0.5739
2025-05-29 14:15:06.174089: val_loss -0.3392
2025-05-29 14:15:06.174261: Pseudo dice [0.7781, 0.4665, 0.2966, 0.4912, 0.0, 0.8604, 0.4364, 0.3692]
2025-05-29 14:15:06.174353: Epoch time: 72.69 s
2025-05-29 14:15:06.174411: Yayy! New best EMA pseudo Dice: 0.4011
2025-05-29 14:15:08.704046: 
2025-05-29 14:15:08.704340: Epoch 31
2025-05-29 14:15:08.704439: Current learning rate: 0.00907
2025-05-29 14:16:22.089115: train_loss -0.5434
2025-05-29 14:16:22.089314: val_loss -0.39
2025-05-29 14:16:22.089514: Pseudo dice [0.8273, 0.5434, 0.3194, 0.4276, 0.0, 0.8479, 0.4034, 0.4994]
2025-05-29 14:16:22.089606: Epoch time: 73.39 s
2025-05-29 14:16:22.089767: Yayy! New best EMA pseudo Dice: 0.4988
2025-05-29 14:08:01.469504: 
2025-05-29 14:08:01.469876: Epoch 51
2025-05-29 14:08:01.469969: Current learning rate: 0.00846
2025-05-29 14:08:33.063644: train_loss -0.7422
2025-05-29 14:08:33.063837: val_loss -0.4331
2025-05-29 14:08:33.063975: Pseudo dice [0.86, 0.5482, 0.3424, 0.4898, 0.0, 0.8835, 0.4882, 0.5736]
2025-05-29 14:08:33.064053: Epoch time: 31.6 s
2025-05-29 14:08:33.064137: Yayy! New best EMA pseudo Dice: 0.5013
2025-05-29 14:08:35.707616: 
2025-05-29 14:08:35.707983: Epoch 52
2025-05-29 14:08:35.708083: Current learning rate: 0.00843
2025-05-29 14:09:06.708495: train_loss -0.7628
2025-05-29 14:09:06.708660: val_loss -0.4615
2025-05-29 14:09:06.708771: Pseudo dice [0.8493, 0.5446, 0.2815, 0.6497, 0.0, 0.8861, 0.4169, 0.482]
2025-05-29 14:09:06.708849: Epoch time: 31.0 s
2025-05-29 14:09:06.708902: Yayy! New best EMA pseudo Dice: 0.5025
2025-05-29 14:09:10.665941: 
2025-05-29 14:09:10.666235: Epoch 53
2025-05-29 14:09:10.666352: Current learning rate: 0.00839
2025-05-29 14:09:41.729852: train_loss -0.7602
2025-05-29 14:09:41.730051: val_loss -0.3705
2025-05-29 14:09:41.730166: Pseudo dice [0.8035, 0.4923, 0.2637, 0.5414, 0.0, 0.9202, 0.4955, 0.4354]
2025-05-29 14:09:41.730285: Epoch time: 31.07 s
2025-05-29 14:09:43.039213: 
2025-05-29 14:09:43.039442: Epoch 54
2025-05-29 14:09:43.039558: Current learning rate: 0.00836
2025-05-29 14:10:13.751640: train_loss -0.7223
2025-05-29 14:10:13.751973: val_loss -0.5507
2025-05-29 14:10:13.752089: Pseudo dice [0.8521, 0.6089, 0.3061, 0.6587, 0.0, 0.8817, 0.5502, 0.5842]
2025-05-29 14:10:13.752166: Epoch time: 30.71 s
2025-05-29 14:10:13.752226: Yayy! New best EMA pseudo Dice: 0.507
2025-05-29 14:10:16.519431: 
2025-05-29 14:10:16.519771: Epoch 55
2025-05-29 14:10:16.519957: Current learning rate: 0.00833
2025-05-29 14:10:47.462141: train_loss -0.7704
2025-05-29 14:10:47.462317: val_loss -0.475
2025-05-29 14:10:47.462432: Pseudo dice [0.8462, 0.5252, 0.2575, 0.657, 0.0, 0.8686, 0.4935, 0.5883]
2025-05-29 14:10:47.462570: Epoch time: 30.94 s
2025-05-29 14:10:47.462632: Yayy! New best EMA pseudo Dice: 0.5093
2025-05-29 14:10:50.023597: 
2025-05-29 14:10:50.023812: Epoch 56
2025-05-29 14:10:50.023929: Current learning rate: 0.0083
2025-05-29 14:11:20.966227: train_loss -0.7859
2025-05-29 14:11:20.966508: val_loss -0.5202
2025-05-29 14:11:20.966663: Pseudo dice [0.8474, 0.6367, 0.3083, 0.5795, 0.0, 0.8935, 0.5356, 0.5878]
2025-05-29 14:11:20.966763: Epoch time: 30.94 s
2025-05-29 14:11:20.966815: Yayy! New best EMA pseudo Dice: 0.5132
2025-05-29 14:11:23.430327: 
2025-05-29 14:11:23.430590: Epoch 57
2025-05-29 14:11:23.430822: Current learning rate: 0.00827
2025-05-29 14:11:54.337169: train_loss -0.7556
2025-05-29 14:11:54.337371: val_loss -0.4596
2025-05-29 14:11:54.337492: Pseudo dice [0.8673, 0.5873, 0.3277, 0.5596, 0.0, 0.8866, 0.4835, 0.5505]
2025-05-29 14:11:54.337576: Epoch time: 30.91 s
2025-05-29 14:11:54.337626: Yayy! New best EMA pseudo Dice: 0.5152
2025-05-29 14:11:56.631177: 
2025-05-29 14:11:56.631379: Epoch 58
2025-05-29 14:11:56.631489: Current learning rate: 0.00824
2025-05-29 14:12:27.538246: train_loss -0.8116
2025-05-29 14:12:27.538438: val_loss -0.5035
2025-05-29 14:12:27.538571: Pseudo dice [0.8553, 0.5774, 0.3045, 0.6104, 0.0, 0.8795, 0.5319, 0.5213]
2025-05-29 14:12:27.538648: Epoch time: 30.91 s
2025-05-29 14:12:27.538701: Yayy! New best EMA pseudo Dice: 0.5172
2025-05-29 14:12:30.363125: 
2025-05-29 14:12:30.363499: Epoch 59
2025-05-29 14:12:30.363623: Current learning rate: 0.00821
2025-05-29 14:13:01.434923: train_loss -0.7985
2025-05-29 14:13:01.435095: val_loss -0.4826
2025-05-29 14:13:01.435209: Pseudo dice [0.8591, 0.5865, 0.3407, 0.6233, 0.0, 0.8763, 0.4864, 0.5675]
2025-05-29 14:13:01.435285: Epoch time: 31.07 s
2025-05-29 14:13:01.435335: Yayy! New best EMA pseudo Dice: 0.5197
2025-05-29 14:13:04.415435: 
2025-05-29 14:13:04.415631: Epoch 60
2025-05-29 14:13:04.415752: Current learning rate: 0.00818
2025-05-29 14:13:35.380780: train_loss -0.7617
2025-05-29 14:13:35.380986: val_loss -0.4701
2025-05-29 14:13:35.381116: Pseudo dice [0.8527, 0.6005, 0.3306, 0.5104, 0.0, 0.8482, 0.5424, 0.5895]
2025-05-29 14:13:35.381205: Epoch time: 30.97 s
2025-05-29 14:13:35.381260: Yayy! New best EMA pseudo Dice: 0.5211
2025-05-29 14:13:37.947801: 
2025-05-29 14:13:37.948035: Epoch 61
2025-05-29 14:13:37.948188: Current learning rate: 0.00815
2025-05-29 14:14:08.912374: train_loss -0.7586
2025-05-29 14:14:08.912625: val_loss -0.5035
2025-05-29 14:14:08.912778: Pseudo dice [0.8598, 0.5675, 0.3522, 0.5969, 0.0, 0.8743, 0.4905, 0.5157]
2025-05-29 14:14:08.912871: Epoch time: 30.97 s
2025-05-29 14:14:08.912931: Yayy! New best EMA pseudo Dice: 0.5222
2025-05-29 14:14:11.923323: 
2025-05-29 14:14:11.923500: Epoch 62
2025-05-29 14:14:11.923597: Current learning rate: 0.00812
2025-05-29 14:14:42.893038: train_loss -0.8144
2025-05-29 14:14:42.893269: val_loss -0.4983
2025-05-29 14:14:42.893388: Pseudo dice [0.8851, 0.6137, 0.3755, 0.5984, 0.0, 0.8691, 0.5057, 0.5975]
2025-05-29 14:14:42.893480: Epoch time: 30.97 s
2025-05-29 14:14:42.893611: Yayy! New best EMA pseudo Dice: 0.5256
2025-05-29 14:14:45.639933: 
2025-05-29 14:14:45.640284: Epoch 63
2025-05-29 14:14:45.640383: Current learning rate: 0.00809
2025-05-29 14:15:16.595413: train_loss -0.7281
2025-05-29 14:15:16.595766: val_loss -0.5459
2025-05-29 14:15:16.595884: Pseudo dice [0.8657, 0.5564, 0.3173, 0.6551, 0.0, 0.8607, 0.4938, 0.5585]
2025-05-29 14:15:16.595974: Epoch time: 30.96 s
2025-05-29 14:15:16.596023: Yayy! New best EMA pseudo Dice: 0.5269
2025-05-29 14:15:19.188901: 
2025-05-29 14:15:19.189303: Epoch 64
2025-05-29 14:15:19.189442: Current learning rate: 0.00806
2025-05-29 14:15:50.192975: train_loss -0.7658
2025-05-29 14:15:50.193216: val_loss -0.5064
2025-05-29 14:15:50.193360: Pseudo dice [0.8424, 0.5544, 0.3514, 0.6443, 0.0494, 0.8486, 0.4669, 0.5385]
2025-05-29 14:15:50.193493: Epoch time: 31.01 s
2025-05-29 14:15:50.193560: Yayy! New best EMA pseudo Dice: 0.5279
2025-05-29 14:15:52.469142: 
2025-05-29 14:15:52.469308: Epoch 65
2025-05-29 14:15:52.469416: Current learning rate: 0.00803
2025-05-29 14:16:23.404518: train_loss -0.7804
2025-05-29 14:16:23.404727: val_loss -0.5389
2025-05-29 14:16:23.404843: Pseudo dice [0.8581, 0.5784, 0.375, 0.62, 0.0529, 0.8783, 0.5522, 0.5502]
2025-05-29 14:16:23.404911: Epoch time: 30.94 s
2025-05-29 14:16:23.404957: Yayy! New best EMA pseudo Dice: 0.5309
2025-05-29 14:16:25.801826: 
2025-05-29 14:16:25.801999: Epoch 66
2025-05-29 14:16:25.802115: Current learning rate: 0.008
2025-05-29 14:16:56.888813: train_loss -0.8235
2025-05-29 14:16:56.889028: val_loss -0.4789
2025-05-29 14:16:56.889150: Pseudo dice [0.8718, 0.6215, 0.2934, 0.6079, 0.0, 0.885, 0.532, 0.6138]
2025-05-29 14:16:56.889230: Epoch time: 31.09 s
2025-05-29 14:16:56.889281: Yayy! New best EMA pseudo Dice: 0.5331
2025-05-29 14:16:59.496472: 
2025-05-29 14:16:59.496659: Epoch 67
2025-05-29 14:16:59.496753: Current learning rate: 0.00797
2025-05-29 14:17:30.359181: train_loss -0.8282
2025-05-29 14:17:30.359371: val_loss -0.5032
2025-05-29 14:17:30.359493: Pseudo dice [0.8602, 0.6389, 0.3903, 0.5751, 0.1543, 0.8289, 0.5631, 0.5989]
2025-05-29 14:17:30.359576: Epoch time: 30.86 s
2025-05-29 14:17:30.359629: Yayy! New best EMA pseudo Dice: 0.5374
2025-05-29 14:17:32.831622: 
2025-05-29 14:17:32.831985: Epoch 68
2025-05-29 14:17:32.832080: Current learning rate: 0.00793
2025-05-29 14:18:03.684680: train_loss -0.8283
2025-05-29 14:18:03.684914: val_loss -0.5441
2025-05-29 14:18:03.685033: Pseudo dice [0.8679, 0.6424, 0.4029, 0.6089, 0.0226, 0.8945, 0.5732, 0.6422]
2025-05-29 14:18:03.685171: Epoch time: 30.85 s
2025-05-29 14:18:03.685271: Yayy! New best EMA pseudo Dice: 0.5419
2025-05-29 14:18:06.309986: 
2025-05-29 14:18:06.310174: Epoch 69
2025-05-29 14:18:06.310300: Current learning rate: 0.0079
2025-05-29 14:18:37.245095: train_loss -0.7917
2025-05-29 14:18:37.245278: val_loss -0.5571
2025-05-29 14:18:37.245388: Pseudo dice [0.8469, 0.6589, 0.3448, 0.6639, 0.0193, 0.8847, 0.4821, 0.5168]
2025-05-29 14:18:37.245476: Epoch time: 30.94 s
2025-05-29 14:18:37.245531: Yayy! New best EMA pseudo Dice: 0.5429
2025-05-29 13:57:04.799267: Yayy! New best EMA pseudo Dice: 0.1911
2025-05-29 13:57:07.549445: 
2025-05-29 13:57:07.549795: Epoch 13
2025-05-29 13:57:07.549893: Current learning rate: 0.00961
2025-05-29 13:58:21.565934: train_loss -0.2216
2025-05-29 13:58:21.566181: val_loss -0.1451
2025-05-29 13:58:21.566368: Pseudo dice [0.7651, 0.2054, 0.1948, 0.3326, 0.0, 0.6795, 0.0, 0.2525]
2025-05-29 13:58:21.566553: Epoch time: 74.02 s
2025-05-29 13:58:21.566711: Yayy! New best EMA pseudo Dice: 0.2024
2025-05-29 13:58:24.181470: 
2025-05-29 13:58:24.181603: Epoch 14
2025-05-29 13:58:24.181698: Current learning rate: 0.00958
2025-05-29 13:59:51.275353: train_loss -0.2324
2025-05-29 13:59:51.275699: val_loss -0.2091
2025-05-29 13:59:51.275840: Pseudo dice [0.8025, 0.2527, 0.3089, 0.4259, 0.0, 0.8169, 0.0, 0.3843]
2025-05-29 13:59:51.275996: Epoch time: 87.1 s
2025-05-29 13:59:51.276055: Yayy! New best EMA pseudo Dice: 0.2195
2025-05-29 13:59:53.759187: 
2025-05-29 13:59:53.759566: Epoch 15
2025-05-29 13:59:53.759678: Current learning rate: 0.00955
2025-05-29 14:01:27.150600: train_loss -0.3265
2025-05-29 14:01:27.151076: val_loss -0.3183
2025-05-29 14:01:27.151205: Pseudo dice [0.8168, 0.273, 0.2921, 0.5161, 0.0, 0.8785, 0.0, 0.3433]
2025-05-29 14:01:27.151285: Epoch time: 93.39 s
2025-05-29 14:01:27.151335: Yayy! New best EMA pseudo Dice: 0.2366
2025-05-29 14:01:29.856671: 
2025-05-29 14:01:29.857016: Epoch 16
2025-05-29 14:01:29.857127: Current learning rate: 0.00952
2025-05-29 14:02:44.094803: train_loss -0.3354
2025-05-29 14:02:44.095029: val_loss -0.2741
2025-05-29 14:02:44.095144: Pseudo dice [0.8427, 0.2229, 0.2927, 0.4593, 0.0, 0.838, 0.0, 0.3805]
2025-05-29 14:02:44.095224: Epoch time: 74.24 s
2025-05-29 14:02:44.095398: Yayy! New best EMA pseudo Dice: 0.2509
2025-05-29 14:02:46.529314: 
2025-05-29 14:02:46.529765: Epoch 17
2025-05-29 14:02:46.529870: Current learning rate: 0.00949
2025-05-29 14:04:00.808475: train_loss -0.3485
2025-05-29 14:04:00.808759: val_loss -0.3175
2025-05-29 14:04:00.808875: Pseudo dice [0.8592, 0.3264, 0.3152, 0.4797, 0.0, 0.8767, 0.0, 0.3497]
2025-05-29 14:04:00.808952: Epoch time: 74.28 s
2025-05-29 14:04:00.809003: Yayy! New best EMA pseudo Dice: 0.2659
2025-05-29 14:04:04.106967: 
2025-05-29 14:04:04.107228: Epoch 18
2025-05-29 14:04:04.107473: Current learning rate: 0.00946
2025-05-29 14:05:18.143033: train_loss -0.3629
2025-05-29 14:05:18.143219: val_loss -0.3762
2025-05-29 14:05:18.143334: Pseudo dice [0.8366, 0.3786, 0.3334, 0.6249, 0.0, 0.8529, 0.0, 0.4453]
2025-05-29 14:05:18.143407: Epoch time: 74.04 s
2025-05-29 14:05:18.143493: Yayy! New best EMA pseudo Dice: 0.2827
2025-05-29 14:05:20.942141: 
2025-05-29 14:05:20.942313: Epoch 19
2025-05-29 14:05:20.942476: Current learning rate: 0.00943
2025-05-29 14:06:52.097630: train_loss -0.3737
2025-05-29 14:06:52.097884: val_loss -0.3132
2025-05-29 14:06:52.098029: Pseudo dice [0.7508, 0.3291, 0.1684, 0.4922, 0.0, 0.8503, 0.0, 0.3863]
2025-05-29 14:06:52.098110: Epoch time: 91.16 s
2025-05-29 14:06:52.098173: Yayy! New best EMA pseudo Dice: 0.2916
2025-05-29 14:06:54.852583: 
2025-05-29 14:06:54.852932: Epoch 20
2025-05-29 14:06:54.853036: Current learning rate: 0.0094
2025-05-29 14:08:08.948610: train_loss -0.3862
2025-05-29 14:08:08.948990: val_loss -0.3574
2025-05-29 14:08:08.949167: Pseudo dice [0.7885, 0.3028, 0.2861, 0.552, 0.0, 0.8837, 0.0535, 0.3795]
2025-05-29 14:08:08.949248: Epoch time: 74.1 s
2025-05-29 14:08:08.949296: Yayy! New best EMA pseudo Dice: 0.303
2025-05-29 14:08:11.997756: 
2025-05-29 14:08:11.998071: Epoch 21
2025-05-29 14:08:11.998171: Current learning rate: 0.00937
2025-05-29 14:09:26.728374: train_loss -0.4491
2025-05-29 14:09:26.728637: val_loss -0.3935
2025-05-29 14:09:26.728752: Pseudo dice [0.8458, 0.3786, 0.2962, 0.5874, 0.0, 0.855, 0.3142, 0.5865]
2025-05-29 14:09:26.729004: Epoch time: 74.73 s
2025-05-29 14:09:26.729054: Yayy! New best EMA pseudo Dice: 0.321
2025-05-29 14:09:29.707352: 
2025-05-29 14:09:29.707597: Epoch 22
2025-05-29 14:09:29.707704: Current learning rate: 0.00934
2025-05-29 14:10:41.608959: train_loss -0.487
2025-05-29 14:10:41.609226: val_loss -0.3781
2025-05-29 14:10:41.609344: Pseudo dice [0.8551, 0.3477, 0.2976, 0.4975, 0.0, 0.802, 0.3217, 0.5732]
2025-05-29 14:10:41.609423: Epoch time: 71.9 s
2025-05-29 14:10:41.609516: Yayy! New best EMA pseudo Dice: 0.3351
2025-05-29 14:10:44.066595: 
2025-05-29 14:10:44.067009: Epoch 23
2025-05-29 14:10:44.067117: Current learning rate: 0.00931
2025-05-29 14:11:58.237804: train_loss -0.4361
2025-05-29 14:11:58.238033: val_loss -0.3915
2025-05-29 14:11:58.238154: Pseudo dice [0.8526, 0.3787, 0.3045, 0.5523, 0.0, 0.8421, 0.3787, 0.557]
2025-05-29 14:11:58.238232: Epoch time: 74.17 s
2025-05-29 14:11:58.238284: Yayy! New best EMA pseudo Dice: 0.3499
2025-05-29 14:12:00.817844: 
2025-05-29 14:12:00.818186: Epoch 24
2025-05-29 14:12:00.818304: Current learning rate: 0.00928
2025-05-29 14:13:15.343836: train_loss -0.5073
2025-05-29 14:13:15.344067: val_loss -0.3611
2025-05-29 14:13:15.344198: Pseudo dice [0.8154, 0.3572, 0.282, 0.5785, 0.0, 0.8735, 0.4084, 0.5083]
2025-05-29 14:13:15.344278: Epoch time: 74.53 s
2025-05-29 14:13:15.344334: Yayy! New best EMA pseudo Dice: 0.3627
2025-05-29 14:13:18.284669: 
2025-05-29 14:13:18.284981: Epoch 25
2025-05-29 14:13:18.285087: Current learning rate: 0.00925
2025-05-29 14:14:31.647718: train_loss -0.515
2025-05-29 14:14:31.647935: val_loss -0.4698
2025-05-29 14:14:31.648061: Pseudo dice [0.8631, 0.4675, 0.3182, 0.5588, 0.0, 0.8612, 0.4099, 0.6144]
2025-05-29 14:14:31.648147: Epoch time: 73.36 s
2025-05-29 14:14:31.648290: Yayy! New best EMA pseudo Dice: 0.3776
2025-05-29 14:14:34.219524: 
2025-05-29 14:14:34.219823: Epoch 26
2025-05-29 14:14:34.219966: Current learning rate: 0.00922
2025-05-29 14:15:49.147036: train_loss -0.5187
2025-05-29 14:15:49.147246: val_loss -0.3667
2025-05-29 14:15:49.147366: Pseudo dice [0.8316, 0.4404, 0.2549, 0.4848, 0.0, 0.8534, 0.3831, 0.5459]
2025-05-29 14:15:49.147444: Epoch time: 74.93 s
2025-05-29 14:15:49.147670: Yayy! New best EMA pseudo Dice: 0.3873
2025-05-29 14:15:51.843896: 
2025-05-29 14:15:51.844200: Epoch 27
2025-05-29 14:15:51.844343: Current learning rate: 0.00919
2025-05-29 14:17:06.576761: train_loss -0.5424
2025-05-29 14:17:06.577068: val_loss -0.4158
2025-05-29 14:17:06.577188: Pseudo dice [0.8678, 0.4454, 0.3483, 0.4922, 0.0, 0.8853, 0.4544, 0.5824]
2025-05-29 14:17:06.577267: Epoch time: 74.73 s
2025-05-29 14:17:06.577332: Yayy! New best EMA pseudo Dice: 0.3995
2025-05-29 14:17:09.196237: 
2025-05-29 14:17:09.196721: Epoch 28
2025-05-29 14:17:09.196870: Current learning rate: 0.00916
2025-05-29 14:18:23.813754: train_loss -0.5818
2025-05-29 14:18:23.814070: val_loss -0.4323
2025-05-29 14:18:23.814239: Pseudo dice [0.8548, 0.424, 0.3346, 0.5223, 0.0, 0.8391, 0.4641, 0.6296]
2025-05-29 14:18:23.814338: Epoch time: 74.62 s
2025-05-29 14:18:23.814388: Yayy! New best EMA pseudo Dice: 0.4104
2025-05-29 14:18:26.570092: 
2025-05-29 14:18:26.570335: Epoch 29
2025-05-29 14:18:26.570524: Current learning rate: 0.00913
2025-05-29 14:19:41.591691: train_loss -0.5258
2025-05-29 14:19:41.591995: val_loss -0.432
2025-05-29 14:19:41.592116: Pseudo dice [0.8575, 0.4342, 0.2808, 0.4879, 0.0, 0.8221, 0.4521, 0.5995]
2025-05-29 14:19:41.592201: Epoch time: 75.02 s
2025-05-29 14:19:41.592313: Yayy! New best EMA pseudo Dice: 0.4185
2025-05-29 14:19:45.096036: 
2025-05-29 14:19:45.096650: Epoch 30
2025-05-29 14:19:45.096812: Current learning rate: 0.0091
2025-05-29 14:20:58.575148: train_loss -0.5479
2025-05-29 14:20:58.575445: val_loss -0.456
2025-05-29 14:20:58.575610: Pseudo dice [0.873, 0.5124, 0.3874, 0.5557, 0.0, 0.8508, 0.4505, 0.5211]
2025-05-29 14:20:58.575708: Epoch time: 73.48 s
2025-05-29 14:20:58.575755: Yayy! New best EMA pseudo Dice: 0.4286
2025-05-29 14:21:01.748782: 
2025-05-29 14:21:01.749240: Epoch 31
2025-05-29 14:21:01.749347: Current learning rate: 0.00907
2025-05-29 14:22:16.808321: train_loss -0.5761
2025-05-29 14:22:16.808598: val_loss -0.5308
2025-05-29 14:22:16.808716: Pseudo dice [0.8706, 0.5246, 0.3826, 0.6297, 0.0, 0.8624, 0.4362, 0.6233]
2025-05-29 14:22:16.808807: Epoch time: 75.06 s Yayy! New best EMA pseudo Dice: 0.1813
2025-05-29 13:54:45.073284: 
2025-05-29 13:54:45.073678: Epoch 13
2025-05-29 13:54:45.073909: Current learning rate: 0.00961
2025-05-29 13:56:13.964389: train_loss -0.3016
2025-05-29 13:56:13.964752: val_loss -0.191
2025-05-29 13:56:13.964872: Pseudo dice [0.7871, 0.2135, 0.2352, 0.4479, 0.0, 0.7099, 0.0, 0.4094]
2025-05-29 13:56:13.964974: Epoch time: 88.89 s
2025-05-29 13:56:13.965024: Yayy! New best EMA pseudo Dice: 0.1982
2025-05-29 13:56:16.737847: 
2025-05-29 13:56:16.737993: Epoch 14
2025-05-29 13:56:16.738088: Current learning rate: 0.00958
2025-05-29 13:57:42.280475: train_loss -0.3138
2025-05-29 13:57:42.280819: val_loss -0.3154
2025-05-29 13:57:42.280954: Pseudo dice [0.7563, 0.312, 0.2378, 0.6031, 0.0, 0.6818, 0.0, 0.4136]
2025-05-29 13:57:42.281052: Epoch time: 85.54 s
2025-05-29 13:57:42.281100: Yayy! New best EMA pseudo Dice: 0.216
2025-05-29 13:57:44.985978: 
2025-05-29 13:57:44.986438: Epoch 15
2025-05-29 13:57:44.986552: Current learning rate: 0.00955
2025-05-29 13:59:09.291268: train_loss -0.3245
2025-05-29 13:59:09.291515: val_loss -0.298
2025-05-29 13:59:09.291635: Pseudo dice [0.8036, 0.3307, 0.2196, 0.5228, 0.0, 0.6834, 0.0452, 0.4784]
2025-05-29 13:59:09.291716: Epoch time: 84.31 s
2025-05-29 13:59:09.291767: Yayy! New best EMA pseudo Dice: 0.2329
2025-05-29 13:59:12.028111: 
2025-05-29 13:59:12.028328: Epoch 16
2025-05-29 13:59:12.028428: Current learning rate: 0.00952
2025-05-29 14:01:10.984257: train_loss -0.3588
2025-05-29 14:01:10.984480: val_loss -0.2789
2025-05-29 14:01:10.984593: Pseudo dice [0.7756, 0.2903, 0.2341, 0.5289, 0.0, 0.6645, 0.1154, 0.4998]
2025-05-29 14:01:10.984680: Epoch time: 118.96 s
2025-05-29 14:01:10.984735: Yayy! New best EMA pseudo Dice: 0.2485
2025-05-29 14:01:13.434319: 
2025-05-29 14:01:13.434556: Epoch 17
2025-05-29 14:01:13.434791: Current learning rate: 0.00949
2025-05-29 14:02:42.344437: train_loss -0.298
2025-05-29 14:02:42.344685: val_loss -0.293
2025-05-29 14:02:42.344795: Pseudo dice [0.773, 0.2938, 0.2206, 0.5653, 0.0, 0.7289, 0.148, 0.4131]
2025-05-29 14:02:42.344882: Epoch time: 88.91 s
2025-05-29 14:02:42.345081: Yayy! New best EMA pseudo Dice: 0.2629
2025-05-29 14:02:45.141271: 
2025-05-29 14:02:45.141728: Epoch 18
2025-05-29 14:02:45.141836: Current learning rate: 0.00946
2025-05-29 14:04:13.750595: train_loss -0.3732
2025-05-29 14:04:13.750892: val_loss -0.3558
2025-05-29 14:04:13.751013: Pseudo dice [0.7706, 0.3239, 0.2557, 0.5624, 0.0, 0.7441, 0.1958, 0.4221]
2025-05-29 14:04:13.751098: Epoch time: 88.61 s
2025-05-29 14:04:13.751172: Yayy! New best EMA pseudo Dice: 0.2775
2025-05-29 14:04:17.360196: 
2025-05-29 14:04:17.360536: Epoch 19
2025-05-29 14:04:17.360638: Current learning rate: 0.00943
2025-05-29 14:05:56.846761: train_loss -0.4016
2025-05-29 14:05:56.846983: val_loss -0.3102
2025-05-29 14:05:56.847095: Pseudo dice [0.7808, 0.3264, 0.2308, 0.5124, 0.0, 0.7161, 0.1942, 0.5157]
2025-05-29 14:05:56.847177: Epoch time: 99.49 s
2025-05-29 14:05:56.847230: Yayy! New best EMA pseudo Dice: 0.2908
2025-05-29 14:05:59.634416: 
2025-05-29 14:05:59.634770: Epoch 20
2025-05-29 14:05:59.634874: Current learning rate: 0.0094
2025-05-29 14:07:34.600048: train_loss -0.4012
2025-05-29 14:07:34.600335: val_loss -0.373
2025-05-29 14:07:34.600468: Pseudo dice [0.8113, 0.2672, 0.3193, 0.5622, 0.0, 0.7558, 0.2817, 0.4533]
2025-05-29 14:07:34.600572: Epoch time: 94.97 s
2025-05-29 14:07:34.600623: Yayy! New best EMA pseudo Dice: 0.3048
2025-05-29 14:07:37.777114: 
2025-05-29 14:07:37.777393: Epoch 21
2025-05-29 14:07:37.777510: Current learning rate: 0.00937
2025-05-29 14:09:06.598633: train_loss -0.4296
2025-05-29 14:09:06.598852: val_loss -0.314
2025-05-29 14:09:06.598962: Pseudo dice [0.7693, 0.3502, 0.229, 0.4953, 0.0, 0.7624, 0.1783, 0.5403]
2025-05-29 14:09:06.599045: Epoch time: 88.82 s
2025-05-29 14:09:06.599095: Yayy! New best EMA pseudo Dice: 0.3159
2025-05-29 14:09:10.752443: 
2025-05-29 14:09:10.752676: Epoch 22
2025-05-29 14:09:10.752838: Current learning rate: 0.00934
2025-05-29 14:10:36.484580: train_loss -0.4623
2025-05-29 14:10:36.484797: val_loss -0.3785
2025-05-29 14:10:36.484897: Pseudo dice [0.8229, 0.3832, 0.2759, 0.5186, 0.0, 0.7201, 0.3446, 0.5656]
2025-05-29 14:10:36.484972: Epoch time: 85.73 s
2025-05-29 14:10:36.485019: Yayy! New best EMA pseudo Dice: 0.3297
2025-05-29 14:10:39.332653: 
2025-05-29 14:10:39.333043: Epoch 23
2025-05-29 14:10:39.333180: Current learning rate: 0.00931
2025-05-29 14:12:04.857388: train_loss -0.4596
2025-05-29 14:12:04.857700: val_loss -0.3894
2025-05-29 14:12:04.857814: Pseudo dice [0.8211, 0.3295, 0.2266, 0.5432, 0.0, 0.8248, 0.3103, 0.4665]
2025-05-29 14:12:04.857899: Epoch time: 85.53 s
2025-05-29 14:12:04.857962: Yayy! New best EMA pseudo Dice: 0.3407
2025-05-29 14:12:07.460495: 
2025-05-29 14:12:07.460719: Epoch 24
2025-05-29 14:12:07.460829: Current learning rate: 0.00928
2025-05-29 14:13:33.337846: train_loss -0.5056
2025-05-29 14:13:33.338274: val_loss -0.3875
2025-05-29 14:13:33.338390: Pseudo dice [0.8246, 0.3207, 0.2482, 0.5086, 0.0, 0.7955, 0.3826, 0.5617]
2025-05-29 14:13:33.338493: Epoch time: 85.88 s
2025-05-29 14:13:33.338542: Yayy! New best EMA pseudo Dice: 0.3522
2025-05-29 14:13:35.851507: 
2025-05-29 14:13:35.851811: Epoch 25
2025-05-29 14:13:35.851938: Current learning rate: 0.00925
2025-05-29 14:15:00.462596: train_loss -0.4906
2025-05-29 14:15:00.462855: val_loss -0.2684
2025-05-29 14:15:00.462978: Pseudo dice [0.8085, 0.2424, 0.2924, 0.3872, 0.0, 0.7945, 0.3757, 0.531]
2025-05-29 14:15:00.463065: Epoch time: 84.61 s
2025-05-29 14:15:00.463118: Yayy! New best EMA pseudo Dice: 0.3599
2025-05-29 14:15:03.071679: 
2025-05-29 14:15:03.071827: Epoch 26
2025-05-29 14:15:03.072004: Current learning rate: 0.00922
2025-05-29 14:16:23.931175: train_loss -0.4982
2025-05-29 14:16:23.931473: val_loss -0.5174
2025-05-29 14:16:23.931628: Pseudo dice [0.824, 0.4363, 0.2195, 0.6847, 0.0, 0.7645, 0.3854, 0.6022]
2025-05-29 14:16:23.931718: Epoch time: 80.86 s
2025-05-29 14:16:23.931778: Yayy! New best EMA pseudo Dice: 0.3728
2025-05-29 14:16:26.357566: 
2025-05-29 14:16:26.357840: Epoch 27
2025-05-29 14:16:26.357943: Current learning rate: 0.00919
2025-05-29 14:17:55.071142: train_loss -0.5357
2025-05-29 14:17:55.071487: val_loss -0.4123
2025-05-29 14:17:55.071667: Pseudo dice [0.834, 0.2896, 0.2387, 0.5732, 0.0, 0.7596, 0.311, 0.5953]
2025-05-29 14:17:55.071841: Epoch time: 88.71 s
2025-05-29 14:17:55.071937: Yayy! New best EMA pseudo Dice: 0.3806
2025-05-29 14:17:57.711127: 
2025-05-29 14:17:57.711459: Epoch 28
2025-05-29 14:17:57.711588: Current learning rate: 0.00916
2025-05-29 14:19:27.112137: train_loss -0.5559
2025-05-29 14:19:27.112432: val_loss -0.4144
2025-05-29 14:19:27.112565: Pseudo dice [0.808, 0.3095, 0.2639, 0.6168, 0.0, 0.761, 0.3482, 0.4875]
2025-05-29 14:19:27.112649: Epoch time: 89.4 s
2025-05-29 14:19:27.112710: Yayy! New best EMA pseudo Dice: 0.3875
2025-05-29 14:19:29.903377: 
2025-05-29 14:19:29.903713: Epoch 29
2025-05-29 14:19:29.903811: Current learning rate: 0.00913
2025-05-29 14:20:57.642824: train_loss -0.4556
2025-05-29 14:20:57.643059: val_loss -0.3476
2025-05-29 14:20:57.643171: Pseudo dice [0.8099, 0.4257, 0.2237, 0.4906, 0.0, 0.7721, 0.382, 0.4516]
2025-05-29 14:20:57.643261: Epoch time: 87.74 s
2025-05-29 14:20:57.643384: Yayy! New best EMA pseudo Dice: 0.3932
2025-05-29 14:21:01.460093: 
2025-05-29 14:21:01.460323: Epoch 30
2025-05-29 14:21:01.460473: Current learning rate: 0.0091
2025-05-29 14:22:31.623616: train_loss -0.5367
2025-05-29 14:22:31.623904: val_loss -0.4425
2025-05-29 14:22:31.624070: Pseudo dice [0.8483, 0.3892, 0.2666, 0.5489, 0.0, 0.8562, 0.4069, 0.6769]
2025-05-29 14:22:31.624209: Epoch time: 90.16 s
2025-05-29 14:22:31.624265: Yayy! New best EMA pseudo Dice: 0.4037
2025-05-29 14:22:34.345603: 
2025-05-29 14:22:34.345880: Epoch 31
2025-05-29 14:22:34.346074: Current learning rate: 0.00907
2025-05-29 14:24:02.580523: train_loss -0.5662
2025-05-29 14:24:02.591146: val_loss -0.4832
2025-05-29 14:24:02.591350: Pseudo dice [0.7689, 0.4327, 0.2836, 0.6908, 0.0, 0.6696, 0.3994, 0.5875]
2025-05-29 14:24:02.591431: Epoch time: 88.24 s
2025-05-29 14:18:39.837656: 
2025-05-29 14:18:39.837880: Epoch 70
2025-05-29 14:18:39.838039: Current learning rate: 0.00787
2025-05-29 14:19:10.653888: train_loss -0.8319
2025-05-29 14:19:10.654137: val_loss -0.4924
2025-05-29 14:19:10.654260: Pseudo dice [0.8663, 0.621, 0.3489, 0.6139, 0.0, 0.8744, 0.4663, 0.5991]
2025-05-29 14:19:10.654343: Epoch time: 30.82 s
2025-05-29 14:19:10.654396: Yayy! New best EMA pseudo Dice: 0.5435
2025-05-29 14:19:13.473956: 
2025-05-29 14:19:13.474143: Epoch 71
2025-05-29 14:19:13.474283: Current learning rate: 0.00784
2025-05-29 14:19:44.361023: train_loss -0.8233
2025-05-29 14:19:44.361204: val_loss -0.5469
2025-05-29 14:19:44.361316: Pseudo dice [0.8589, 0.6177, 0.3905, 0.6282, 0.1581, 0.8534, 0.5478, 0.5941]
2025-05-29 14:19:44.361389: Epoch time: 30.89 s
2025-05-29 14:19:44.361515: Yayy! New best EMA pseudo Dice: 0.5473
2025-05-29 14:19:46.839544: 
2025-05-29 14:19:46.839824: Epoch 72
2025-05-29 14:19:46.840022: Current learning rate: 0.00781
2025-05-29 14:20:17.747759: train_loss -0.8605
2025-05-29 14:20:17.747926: val_loss -0.5733
2025-05-29 14:20:17.748028: Pseudo dice [0.8751, 0.6219, 0.4009, 0.6663, 0.1756, 0.8835, 0.4954, 0.5516]
2025-05-29 14:20:17.748096: Epoch time: 30.91 s
2025-05-29 14:20:17.748177: Yayy! New best EMA pseudo Dice: 0.5509
2025-05-29 14:20:21.045944: 
2025-05-29 14:20:21.046295: Epoch 73
2025-05-29 14:20:21.046445: Current learning rate: 0.00778
2025-05-29 14:20:52.044671: train_loss -0.8299
2025-05-29 14:20:52.044946: val_loss -0.5578
2025-05-29 14:20:52.045066: Pseudo dice [0.8477, 0.6129, 0.324, 0.6928, 0.1241, 0.847, 0.5188, 0.5309]
2025-05-29 14:20:52.045149: Epoch time: 31.0 s
2025-05-29 14:20:52.045214: Yayy! New best EMA pseudo Dice: 0.552
2025-05-29 14:20:54.494031: 
2025-05-29 14:20:54.494373: Epoch 74
2025-05-29 14:20:54.494475: Current learning rate: 0.00775
2025-05-29 14:21:25.200732: train_loss -0.8153
2025-05-29 14:21:25.201017: val_loss -0.4615
2025-05-29 14:21:25.201164: Pseudo dice [0.8424, 0.5799, 0.3391, 0.5754, 0.1756, 0.8734, 0.5492, 0.5723]
2025-05-29 14:21:25.201276: Epoch time: 30.71 s
2025-05-29 14:21:25.201358: Yayy! New best EMA pseudo Dice: 0.5532
2025-05-29 14:21:27.657631: 
2025-05-29 14:21:27.658009: Epoch 75
2025-05-29 14:21:27.658107: Current learning rate: 0.00772
2025-05-29 14:21:59.535916: train_loss -0.866
2025-05-29 14:21:59.536131: val_loss -0.5736
2025-05-29 14:21:59.536241: Pseudo dice [0.86, 0.6466, 0.3448, 0.6535, 0.1145, 0.8508, 0.5037, 0.591]
2025-05-29 14:21:59.536322: Epoch time: 31.88 s
2025-05-29 14:21:59.536375: Yayy! New best EMA pseudo Dice: 0.5549
2025-05-29 14:22:02.079369: 
2025-05-29 14:22:02.079716: Epoch 76
2025-05-29 14:22:02.079841: Current learning rate: 0.00769
2025-05-29 14:22:32.990885: train_loss -0.8792
2025-05-29 14:22:32.991087: val_loss -0.547
2025-05-29 14:22:32.991199: Pseudo dice [0.8781, 0.6414, 0.3652, 0.596, 0.1867, 0.8761, 0.5265, 0.629]
2025-05-29 14:22:32.991282: Epoch time: 30.91 s
2025-05-29 14:22:32.991341: Yayy! New best EMA pseudo Dice: 0.5582
2025-05-29 14:22:35.504522: 
2025-05-29 14:22:35.504867: Epoch 77
2025-05-29 14:22:35.505069: Current learning rate: 0.00766
2025-05-29 14:23:06.443949: train_loss -0.9015
2025-05-29 14:23:06.444285: val_loss -0.5496
2025-05-29 14:23:06.444441: Pseudo dice [0.8698, 0.6859, 0.3102, 0.6224, 0.096, 0.8471, 0.5239, 0.6723]
2025-05-29 14:23:06.444556: Epoch time: 30.94 s
2025-05-29 14:23:06.444611: Yayy! New best EMA pseudo Dice: 0.5602
2025-05-29 14:23:08.979189: 
2025-05-29 14:23:08.979520: Epoch 78
2025-05-29 14:23:08.979670: Current learning rate: 0.00763
2025-05-29 14:23:39.923331: train_loss -0.8634
2025-05-29 14:23:39.923550: val_loss -0.6486
2025-05-29 14:23:39.923666: Pseudo dice [0.8601, 0.6782, 0.2969, 0.6968, 0.2533, 0.9063, 0.5294, 0.5546]
2025-05-29 14:23:39.923746: Epoch time: 30.95 s
2025-05-29 14:23:39.923799: Yayy! New best EMA pseudo Dice: 0.5639
2025-05-29 14:23:42.677123: 
2025-05-29 14:23:42.677337: Epoch 79
2025-05-29 14:23:42.677490: Current learning rate: 0.0076
2025-05-29 14:24:13.554875: train_loss -0.9201
2025-05-29 14:24:13.555051: val_loss -0.5871
2025-05-29 14:24:13.555164: Pseudo dice [0.8768, 0.6883, 0.3766, 0.6109, 0.1674, 0.8784, 0.5452, 0.6485]
2025-05-29 14:24:13.555238: Epoch time: 30.88 s
2025-05-29 14:24:13.555288: Yayy! New best EMA pseudo Dice: 0.5674
2025-05-29 14:24:16.174787: 
2025-05-29 14:24:16.175068: Epoch 80
2025-05-29 14:24:16.175207: Current learning rate: 0.00756
2025-05-29 14:24:47.217213: train_loss -0.9316
2025-05-29 14:24:47.217467: val_loss -0.5885
2025-05-29 14:24:47.217611: Pseudo dice [0.8909, 0.6811, 0.3958, 0.6807, 0.1079, 0.878, 0.5279, 0.5849]
2025-05-29 14:24:47.217690: Epoch time: 31.04 s
2025-05-29 14:24:47.217741: Yayy! New best EMA pseudo Dice: 0.57
2025-05-29 14:24:49.694318: 
2025-05-29 14:24:49.694550: Epoch 81
2025-05-29 14:24:49.694645: Current learning rate: 0.00753
2025-05-29 14:25:20.473931: train_loss -0.9277
2025-05-29 14:25:20.474112: val_loss -0.565
2025-05-29 14:25:20.474232: Pseudo dice [0.8577, 0.5571, 0.381, 0.6708, 0.2005, 0.9161, 0.5152, 0.6046]
2025-05-29 14:25:20.474310: Epoch time: 30.78 s
2025-05-29 14:25:20.474362: Yayy! New best EMA pseudo Dice: 0.5718
2025-05-29 14:25:23.152138: 
2025-05-29 14:25:23.152371: Epoch 82
2025-05-29 14:25:23.152514: Current learning rate: 0.0075
2025-05-29 14:25:54.092384: train_loss -0.9437
2025-05-29 14:25:54.092583: val_loss -0.6155
2025-05-29 14:25:54.092694: Pseudo dice [0.8633, 0.686, 0.3631, 0.7238, 0.1808, 0.8619, 0.5681, 0.5613]
2025-05-29 14:25:54.092768: Epoch time: 30.94 s
2025-05-29 14:25:54.092818: Yayy! New best EMA pseudo Dice: 0.5747
2025-05-29 14:25:56.827428: 
2025-05-29 14:25:56.827781: Epoch 83
2025-05-29 14:25:56.827929: Current learning rate: 0.00747
2025-05-29 14:26:27.540288: train_loss -0.8966
2025-05-29 14:26:27.540491: val_loss -0.5402
2025-05-29 14:26:27.540607: Pseudo dice [0.8642, 0.5952, 0.2729, 0.6443, 0.0151, 0.8617, 0.5037, 0.6107]
2025-05-29 14:26:27.540686: Epoch time: 30.71 s
2025-05-29 14:26:29.502158: 
2025-05-29 14:26:29.502422: Epoch 84
2025-05-29 14:26:29.502586: Current learning rate: 0.00744
2025-05-29 14:27:00.575684: train_loss -0.7986
2025-05-29 14:27:00.576013: val_loss -0.5471
2025-05-29 14:27:00.576145: Pseudo dice [0.85, 0.6166, 0.3367, 0.6745, 0.0972, 0.8727, 0.5334, 0.5184]
2025-05-29 14:27:00.576219: Epoch time: 31.07 s
2025-05-29 14:27:01.937726: 
2025-05-29 14:27:01.937984: Epoch 85
2025-05-29 14:27:01.938113: Current learning rate: 0.00741
2025-05-29 14:27:32.784334: train_loss -0.8683
2025-05-29 14:27:32.784563: val_loss -0.6033
2025-05-29 14:27:32.784677: Pseudo dice [0.8664, 0.5938, 0.2981, 0.6986, 0.0491, 0.8721, 0.5449, 0.61]
2025-05-29 14:27:32.784759: Epoch time: 30.85 s
2025-05-29 14:27:34.093097: 
2025-05-29 14:27:34.093431: Epoch 86
2025-05-29 14:27:34.093597: Current learning rate: 0.00738
2025-05-29 14:28:05.020972: train_loss -0.8914
2025-05-29 14:28:05.021188: val_loss -0.4376
2025-05-29 14:28:05.021303: Pseudo dice [0.8649, 0.5144, 0.3446, 0.578, 0.0347, 0.8553, 0.4894, 0.629]
2025-05-29 14:28:05.021379: Epoch time: 30.93 s
2025-05-29 14:28:06.401601: 
2025-05-29 14:28:06.401918: Epoch 87
2025-05-29 14:28:06.402121: Current learning rate: 0.00735
2025-05-29 14:28:37.505823: train_loss -0.8974
2025-05-29 14:28:37.506061: val_loss -0.6006
2025-05-29 14:28:37.506163: Pseudo dice [0.8523, 0.6438, 0.3876, 0.694, 0.1803, 0.88, 0.5832, 0.6315]
2025-05-29 14:28:37.506241: Epoch time: 31.11 s
2025-05-29 14:28:38.806675: 
2025-05-29 14:28:38.807090: Epoch 88
2025-05-29 14:28:38.807185: Current learning rate: 0.00732
2025-05-29 14:29:09.582985: train_loss -0.9203
2025-05-29 14:29:09.583193: val_loss -0.5909
2025-05-29 14:29:09.583303: Pseudo dice [0.9046, 0.5848, 0.3625, 0.6874, 0.0425, 0.9159, 0.5392, 0.7056]
2025-05-29 14:29:09.583383: Epoch time: 30.78 s
2025-05-29 14:29:10.910803: 
2025-05-29 14:29:10.911083: Epoch 89
2025-05-29 14:29:10.911174: Current learning rate: 0.00729
2025-05-29 14:29:41.934751: train_loss -0.9335
2025-05-29 14:29:41.934974: val_loss -0.4798
2025-05-29 14:29:41.935092: Pseudo dice [0.8565, 0.596, 0.3881, 0.58, 0.037, 0.8519, 0.5534, 0.6171]
2025-05-29 14:29:41.935174: Yayy! New best EMA pseudo Dice: 0.4094
2025-05-29 14:16:24.484754: 
2025-05-29 14:16:24.485069: Epoch 32
2025-05-29 14:16:24.485182: Current learning rate: 0.00903
2025-05-29 14:17:37.377361: train_loss -0.616
2025-05-29 14:17:37.377562: val_loss -0.3481
2025-05-29 14:17:37.377680: Pseudo dice [0.8341, 0.5352, 0.228, 0.412, 0.0, 0.852, 0.4314, 0.4667]
2025-05-29 14:17:37.377764: Epoch time: 72.89 s
2025-05-29 14:17:37.377918: Yayy! New best EMA pseudo Dice: 0.4154
2025-05-29 14:17:39.987145: 
2025-05-29 14:17:39.987508: Epoch 33
2025-05-29 14:17:39.987652: Current learning rate: 0.009
2025-05-29 14:18:53.023263: train_loss -0.5864
2025-05-29 14:18:53.023515: val_loss -0.285
2025-05-29 14:18:53.023651: Pseudo dice [0.8568, 0.5101, 0.2059, 0.2599, 0.0, 0.8906, 0.4588, 0.4672]
2025-05-29 14:18:53.023739: Epoch time: 73.04 s
2025-05-29 14:18:53.023807: Yayy! New best EMA pseudo Dice: 0.4195
2025-05-29 14:18:55.634666: 
2025-05-29 14:18:55.634864: Epoch 34
2025-05-29 14:18:55.635024: Current learning rate: 0.00897
2025-05-29 14:20:08.056710: train_loss -0.6148
2025-05-29 14:20:08.057007: val_loss -0.4882
2025-05-29 14:20:08.057127: Pseudo dice [0.8743, 0.5585, 0.3401, 0.5121, 0.0, 0.9034, 0.4524, 0.5925]
2025-05-29 14:20:08.057216: Epoch time: 72.42 s
2025-05-29 14:20:08.057279: Yayy! New best EMA pseudo Dice: 0.4305
2025-05-29 14:20:10.804085: 
2025-05-29 14:20:10.804386: Epoch 35
2025-05-29 14:20:10.804595: Current learning rate: 0.00894
2025-05-29 14:21:22.741461: train_loss -0.6471
2025-05-29 14:21:22.741657: val_loss -0.4303
2025-05-29 14:21:22.741770: Pseudo dice [0.8735, 0.516, 0.2604, 0.4845, 0.0, 0.8931, 0.3261, 0.5609]
2025-05-29 14:21:22.741865: Epoch time: 71.94 s
2025-05-29 14:21:22.742038: Yayy! New best EMA pseudo Dice: 0.4363
2025-05-29 14:21:25.365783: 
2025-05-29 14:21:25.365938: Epoch 36
2025-05-29 14:21:25.366031: Current learning rate: 0.00891
2025-05-29 14:22:38.705644: train_loss -0.6722
2025-05-29 14:22:38.705887: val_loss -0.4585
2025-05-29 14:22:38.706033: Pseudo dice [0.8466, 0.5761, 0.3274, 0.4716, 0.0, 0.8977, 0.5221, 0.4609]
2025-05-29 14:22:38.706136: Epoch time: 73.34 s
2025-05-29 14:22:38.706193: Yayy! New best EMA pseudo Dice: 0.444
2025-05-29 14:22:41.234249: 
2025-05-29 14:22:41.234463: Epoch 37
2025-05-29 14:22:41.234595: Current learning rate: 0.00888
2025-05-29 14:23:53.846530: train_loss -0.6425
2025-05-29 14:23:53.846795: val_loss -0.4545
2025-05-29 14:23:53.846925: Pseudo dice [0.8671, 0.4419, 0.292, 0.485, 0.0, 0.907, 0.4511, 0.567]
2025-05-29 14:23:53.847012: Epoch time: 72.61 s
2025-05-29 14:23:53.847071: Yayy! New best EMA pseudo Dice: 0.4497
2025-05-29 14:23:56.454042: 
2025-05-29 14:23:56.454312: Epoch 38
2025-05-29 14:23:56.454411: Current learning rate: 0.00885
2025-05-29 14:25:09.829481: train_loss -0.6029
2025-05-29 14:25:09.829778: val_loss -0.3444
2025-05-29 14:25:09.829905: Pseudo dice [0.8279, 0.5316, 0.2802, 0.3396, 0.0, 0.8518, 0.5185, 0.5862]
2025-05-29 14:25:09.830003: Epoch time: 73.38 s
2025-05-29 14:25:09.830052: Yayy! New best EMA pseudo Dice: 0.454
2025-05-29 14:25:12.559566: 
2025-05-29 14:25:12.559769: Epoch 39
2025-05-29 14:25:12.559864: Current learning rate: 0.00882
2025-05-29 14:26:25.023260: train_loss -0.6326
2025-05-29 14:26:25.023544: val_loss -0.4796
2025-05-29 14:26:25.023666: Pseudo dice [0.8703, 0.5376, 0.3349, 0.4955, 0.0, 0.9057, 0.5206, 0.5392]
2025-05-29 14:26:25.023767: Epoch time: 72.46 s
2025-05-29 14:26:25.023817: Yayy! New best EMA pseudo Dice: 0.4611
2025-05-29 14:26:27.616184: 
2025-05-29 14:26:27.617014: Epoch 40
2025-05-29 14:26:27.617353: Current learning rate: 0.00879
2025-05-29 14:27:40.098673: train_loss -0.6743
2025-05-29 14:27:40.099228: val_loss -0.4575
2025-05-29 14:27:40.099391: Pseudo dice [0.8616, 0.6049, 0.3289, 0.4229, 0.0, 0.9019, 0.5285, 0.6125]
2025-05-29 14:27:40.099523: Epoch time: 72.49 s
2025-05-29 14:27:40.099579: Yayy! New best EMA pseudo Dice: 0.4683
2025-05-29 14:27:43.404799: 
2025-05-29 14:27:43.405070: Epoch 41
2025-05-29 14:27:43.405186: Current learning rate: 0.00876
2025-05-29 14:28:56.038767: train_loss -0.7036
2025-05-29 14:28:56.039282: val_loss -0.4558
2025-05-29 14:28:56.039418: Pseudo dice [0.8287, 0.5145, 0.2916, 0.5365, 0.0, 0.919, 0.5234, 0.4959]
2025-05-29 14:28:56.039512: Epoch time: 72.64 s
2025-05-29 14:28:56.039597: Yayy! New best EMA pseudo Dice: 0.4728
2025-05-29 14:28:58.615550: 
2025-05-29 14:28:58.615828: Epoch 42
2025-05-29 14:28:58.616045: Current learning rate: 0.00873
2025-05-29 14:30:10.966913: train_loss -0.7367
2025-05-29 14:30:10.967156: val_loss -0.4809
2025-05-29 14:30:10.967271: Pseudo dice [0.8649, 0.5853, 0.3125, 0.4946, 0.0, 0.8939, 0.4535, 0.619]
2025-05-29 14:30:10.967366: Epoch time: 72.35 s
2025-05-29 14:30:10.967430: Yayy! New best EMA pseudo Dice: 0.4783
2025-05-29 14:30:13.580516: 
2025-05-29 14:30:13.580925: Epoch 43
2025-05-29 14:30:13.581052: Current learning rate: 0.0087
2025-05-29 14:31:27.009916: train_loss -0.7592
2025-05-29 14:31:27.010179: val_loss -0.472
2025-05-29 14:31:27.010299: Pseudo dice [0.877, 0.5816, 0.3593, 0.4258, 0.0, 0.9029, 0.489, 0.5915]
2025-05-29 14:31:27.010382: Epoch time: 73.43 s
2025-05-29 14:31:27.010457: Yayy! New best EMA pseudo Dice: 0.4833
2025-05-29 14:31:29.519324: 
2025-05-29 14:31:29.519540: Epoch 44
2025-05-29 14:31:29.519638: Current learning rate: 0.00867
2025-05-29 14:32:40.883201: train_loss -0.7041
2025-05-29 14:32:40.883391: val_loss -0.3701
2025-05-29 14:32:40.883519: Pseudo dice [0.8588, 0.5651, 0.2601, 0.3948, 0.0, 0.8912, 0.531, 0.5183]
2025-05-29 14:32:40.883601: Epoch time: 71.37 s
2025-05-29 14:32:40.883653: Yayy! New best EMA pseudo Dice: 0.4852
2025-05-29 14:32:43.705169: 
2025-05-29 14:32:43.705441: Epoch 45
2025-05-29 14:32:43.705621: Current learning rate: 0.00864
2025-05-29 14:33:55.525279: train_loss -0.7185
2025-05-29 14:33:55.525521: val_loss -0.53
2025-05-29 14:33:55.525725: Pseudo dice [0.8713, 0.5659, 0.3154, 0.5164, 0.0, 0.8891, 0.521, 0.6181]
2025-05-29 14:33:55.525835: Epoch time: 71.82 s
2025-05-29 14:33:55.525967: Yayy! New best EMA pseudo Dice: 0.4904
2025-05-29 14:33:58.310184: 
2025-05-29 14:33:58.310622: Epoch 46
2025-05-29 14:33:58.310718: Current learning rate: 0.00861
2025-05-29 14:35:10.987540: train_loss -0.7652
2025-05-29 14:35:10.987741: val_loss -0.5812
2025-05-29 14:35:10.987851: Pseudo dice [0.8935, 0.594, 0.3447, 0.6116, 0.0, 0.9145, 0.4243, 0.6118]
2025-05-29 14:35:10.987946: Epoch time: 72.68 s
2025-05-29 14:35:10.987996: Yayy! New best EMA pseudo Dice: 0.4963
2025-05-29 14:35:13.613921: 
2025-05-29 14:35:13.614188: Epoch 47
2025-05-29 14:35:13.614334: Current learning rate: 0.00858
2025-05-29 14:36:27.226220: train_loss -0.6762
2025-05-29 14:36:27.226423: val_loss -0.4961
2025-05-29 14:36:27.226555: Pseudo dice [0.8821, 0.5412, 0.3648, 0.4422, 0.0, 0.8312, 0.5591, 0.5484]
2025-05-29 14:36:27.226635: Epoch time: 73.61 s
2025-05-29 14:36:27.226687: Yayy! New best EMA pseudo Dice: 0.4988
2025-05-29 14:36:29.665243: 
2025-05-29 14:36:29.665523: Epoch 48
2025-05-29 14:36:29.665668: Current learning rate: 0.00855
2025-05-29 14:37:46.329543: train_loss -0.6899
2025-05-29 14:37:46.329746: val_loss -0.4799
2025-05-29 14:37:46.329860: Pseudo dice [0.8767, 0.5699, 0.3759, 0.4939, 0.0, 0.894, 0.5248, 0.5554]
2025-05-29 14:37:46.329951: Epoch time: 76.67 s
2025-05-29 14:37:46.330004: Yayy! New best EMA pseudo Dice: 0.5026
2025-05-29 14:37:48.842544: 
2025-05-29 14:37:48.842902: Epoch 49
2025-05-29 14:37:48.843037: Current learning rate: 0.00852
2025-05-29 14:39:03.308199: train_loss -0.6897
2025-05-29 14:39:03.308453: val_loss -0.4452
2025-05-29 14:39:03.308573: Pseudo dice [0.8932, 0.5524, 0.2908, 0.4832, 0.0, 0.9157, 0.4608, 0.6173]
2025-05-29 14:39:03.308657: Epoch time: 74.47 s
2025-05-29 14:39:03.821019: Yayy! New best EMA pseudo Dice: 0.505
2025-05-29 14:39:06.352390: 
2025-05-29 14:39:06.352624: Epoch 50
2025-05-29 14:39:06.352716: Current learning rate: 0.00849
2025-05-29 14:40:21.109847: train_loss -0.7214
2025-05-29 14:40:21.110108: val_loss -0.515
2025-05-29 14:40:21.110277: Pseudo dice [0.8826, 0.5728, 0.3731, 0.5176, 0.0, 0.9197, 0.5117, 0.6571]
2025-05-29 14:40:21.110363: Epoch time: 74.76 s
2025-05-29 14:40:21.110427: Epoch time: 31.03 s
2025-05-29 14:29:43.248914: 
2025-05-29 14:29:43.249228: Epoch 90
2025-05-29 14:29:43.249370: Current learning rate: 0.00725
2025-05-29 14:30:14.092733: train_loss -0.9152
2025-05-29 14:30:14.093582: val_loss -0.5607
2025-05-29 14:30:14.093784: Pseudo dice [0.8775, 0.661, 0.3766, 0.6349, 0.0456, 0.8764, 0.4859, 0.6073]
2025-05-29 14:30:14.094015: Epoch time: 30.85 s
2025-05-29 14:30:15.521933: 
2025-05-29 14:30:15.522267: Epoch 91
2025-05-29 14:30:15.522374: Current learning rate: 0.00722
2025-05-29 14:30:46.794256: train_loss -0.9132
2025-05-29 14:30:46.794794: val_loss -0.5331
2025-05-29 14:30:46.795003: Pseudo dice [0.8494, 0.6724, 0.3447, 0.6053, 0.1556, 0.86, 0.5446, 0.5634]
2025-05-29 14:30:46.795135: Epoch time: 31.27 s
2025-05-29 14:30:48.152514: 
2025-05-29 14:30:48.152986: Epoch 92
2025-05-29 14:30:48.153083: Current learning rate: 0.00719
2025-05-29 14:31:19.174083: train_loss -0.961
2025-05-29 14:31:19.174474: val_loss -0.6233
2025-05-29 14:31:19.174700: Pseudo dice [0.8852, 0.7113, 0.4273, 0.6384, 0.234, 0.9065, 0.5288, 0.5923]
2025-05-29 14:31:19.174782: Epoch time: 31.02 s
2025-05-29 14:31:19.174828: Yayy! New best EMA pseudo Dice: 0.5765
2025-05-29 14:31:21.726513: 
2025-05-29 14:31:21.726841: Epoch 93
2025-05-29 14:31:21.727044: Current learning rate: 0.00716
2025-05-29 14:31:52.787812: train_loss -0.9048
2025-05-29 14:31:52.788197: val_loss -0.4799
2025-05-29 14:31:52.788356: Pseudo dice [0.8439, 0.6416, 0.3862, 0.5726, 0.187, 0.8527, 0.5642, 0.5345]
2025-05-29 14:31:52.788440: Epoch time: 31.06 s
2025-05-29 14:31:54.102952: 
2025-05-29 14:31:54.103262: Epoch 94
2025-05-29 14:31:54.103412: Current learning rate: 0.00713
2025-05-29 14:32:25.152416: train_loss -0.9356
2025-05-29 14:32:25.152673: val_loss -0.5664
2025-05-29 14:32:25.152791: Pseudo dice [0.8785, 0.6526, 0.3736, 0.6819, 0.1329, 0.9056, 0.5426, 0.6208]
2025-05-29 14:32:25.152887: Epoch time: 31.05 s
2025-05-29 14:32:25.152947: Yayy! New best EMA pseudo Dice: 0.5784
2025-05-29 14:32:28.395845: 
2025-05-29 14:32:28.396166: Epoch 95
2025-05-29 14:32:28.396259: Current learning rate: 0.0071
2025-05-29 14:32:59.117521: train_loss -0.9752
2025-05-29 14:32:59.117880: val_loss -0.5921
2025-05-29 14:32:59.118034: Pseudo dice [0.8735, 0.6313, 0.3414, 0.6328, 0.1401, 0.8855, 0.5281, 0.6389]
2025-05-29 14:32:59.118121: Epoch time: 30.72 s
2025-05-29 14:32:59.118169: Yayy! New best EMA pseudo Dice: 0.5789
2025-05-29 14:33:01.762157: 
2025-05-29 14:33:01.762486: Epoch 96
2025-05-29 14:33:01.762590: Current learning rate: 0.00707
2025-05-29 14:33:32.859432: train_loss -0.9695
2025-05-29 14:33:32.859620: val_loss -0.5788
2025-05-29 14:33:32.859733: Pseudo dice [0.8842, 0.6098, 0.3989, 0.6558, 0.1751, 0.8963, 0.5444, 0.5719]
2025-05-29 14:33:32.859806: Epoch time: 31.1 s
2025-05-29 14:33:32.859857: Yayy! New best EMA pseudo Dice: 0.5802
2025-05-29 14:33:35.906411: 
2025-05-29 14:33:35.906657: Epoch 97
2025-05-29 14:33:35.906760: Current learning rate: 0.00704
2025-05-29 14:34:06.588351: train_loss -0.9536
2025-05-29 14:34:06.588560: val_loss -0.5873
2025-05-29 14:34:06.588678: Pseudo dice [0.8719, 0.6826, 0.4047, 0.6303, 0.2241, 0.9072, 0.5494, 0.6003]
2025-05-29 14:34:06.588762: Epoch time: 30.68 s
2025-05-29 14:34:06.588814: Yayy! New best EMA pseudo Dice: 0.5831
2025-05-29 14:34:09.276540: 
2025-05-29 14:34:09.276715: Epoch 98
2025-05-29 14:34:09.276832: Current learning rate: 0.007
2025-05-29 14:34:40.400320: train_loss -0.9897
2025-05-29 14:34:40.400669: val_loss -0.5122
2025-05-29 14:34:40.400853: Pseudo dice [0.8787, 0.6412, 0.3479, 0.6138, 0.2027, 0.8909, 0.5569, 0.5805]
2025-05-29 14:34:40.401032: Epoch time: 31.12 s
2025-05-29 14:34:40.401178: Yayy! New best EMA pseudo Dice: 0.5837
2025-05-29 14:34:42.976840: 
2025-05-29 14:34:42.977198: Epoch 99
2025-05-29 14:34:42.977340: Current learning rate: 0.00697
2025-05-29 14:35:13.662985: train_loss -0.9735
2025-05-29 14:35:13.663340: val_loss -0.5264
2025-05-29 14:35:13.663466: Pseudo dice [0.8928, 0.6716, 0.3247, 0.5855, 0.138, 0.8731, 0.5523, 0.6451]
2025-05-29 14:35:13.663564: Epoch time: 30.69 s
2025-05-29 14:35:14.905367: Yayy! New best EMA pseudo Dice: 0.5839
2025-05-29 14:35:17.305475: 
2025-05-29 14:35:17.305724: Epoch 100
2025-05-29 14:35:17.305844: Current learning rate: 0.00694
2025-05-29 14:35:48.432631: train_loss -0.9685
2025-05-29 14:35:48.433610: val_loss -0.5121
2025-05-29 14:35:48.433741: Pseudo dice [0.8774, 0.6568, 0.3757, 0.586, 0.1563, 0.8749, 0.4864, 0.5805]
2025-05-29 14:35:48.433866: Epoch time: 31.13 s
2025-05-29 14:35:49.750526: 
2025-05-29 14:35:49.750720: Epoch 101
2025-05-29 14:35:49.750822: Current learning rate: 0.00691
2025-05-29 14:36:20.824585: train_loss -0.9792
2025-05-29 14:36:20.825315: val_loss -0.5893
2025-05-29 14:36:20.825485: Pseudo dice [0.846, 0.6595, 0.3737, 0.6805, 0.2241, 0.8691, 0.5357, 0.5393]
2025-05-29 14:36:20.825611: Epoch time: 31.08 s
2025-05-29 14:36:22.222371: 
2025-05-29 14:36:22.222891: Epoch 102
2025-05-29 14:36:22.223058: Current learning rate: 0.00688
2025-05-29 14:37:01.289604: train_loss -0.9808
2025-05-29 14:37:01.290191: val_loss -0.6054
2025-05-29 14:37:01.290381: Pseudo dice [0.8914, 0.7141, 0.3705, 0.6101, 0.0601, 0.8534, 0.5563, 0.6241]
2025-05-29 14:37:01.290488: Epoch time: 39.07 s
2025-05-29 14:37:02.657721: 
2025-05-29 14:37:02.658102: Epoch 103
2025-05-29 14:37:02.658213: Current learning rate: 0.00685
2025-05-29 14:37:33.721151: train_loss -1.0336
2025-05-29 14:37:33.721635: val_loss -0.5798
2025-05-29 14:37:33.721753: Pseudo dice [0.8691, 0.6875, 0.4096, 0.6499, 0.2618, 0.8959, 0.5438, 0.5405]
2025-05-29 14:37:33.721831: Epoch time: 31.06 s
2025-05-29 14:37:33.721879: Yayy! New best EMA pseudo Dice: 0.5862
2025-05-29 14:37:36.454353: 
2025-05-29 14:37:36.454750: Epoch 104
2025-05-29 14:37:36.454891: Current learning rate: 0.00682
2025-05-29 14:38:07.280296: train_loss -1.0129
2025-05-29 14:38:07.280653: val_loss -0.6091
2025-05-29 14:38:07.280776: Pseudo dice [0.8928, 0.6629, 0.3722, 0.6486, 0.198, 0.9342, 0.5309, 0.6357]
2025-05-29 14:38:07.280907: Epoch time: 30.83 s
2025-05-29 14:38:07.280954: Yayy! New best EMA pseudo Dice: 0.5885
2025-05-29 14:38:10.814606: 
2025-05-29 14:38:10.814819: Epoch 105
2025-05-29 14:38:10.814973: Current learning rate: 0.00679
2025-05-29 14:38:41.958483: train_loss -1.0428
2025-05-29 14:38:41.958713: val_loss -0.5763
2025-05-29 14:38:41.958834: Pseudo dice [0.8958, 0.6854, 0.3863, 0.5829, 0.1835, 0.8984, 0.5278, 0.6163]
2025-05-29 14:38:41.958921: Epoch time: 31.15 s
2025-05-29 14:38:41.958974: Yayy! New best EMA pseudo Dice: 0.5894
2025-05-29 14:38:45.020516: 
2025-05-29 14:38:45.020664: Epoch 106
2025-05-29 14:38:45.020776: Current learning rate: 0.00675
2025-05-29 14:39:15.827509: train_loss -0.9999
2025-05-29 14:39:15.827757: val_loss -0.5964
2025-05-29 14:39:15.827886: Pseudo dice [0.8753, 0.6819, 0.4122, 0.6486, 0.2369, 0.8964, 0.5295, 0.6085]
2025-05-29 14:39:15.827978: Epoch time: 30.81 s
2025-05-29 14:39:15.828028: Yayy! New best EMA pseudo Dice: 0.5915
2025-05-29 14:39:18.657915: 
2025-05-29 14:39:18.658310: Epoch 107
2025-05-29 14:39:18.658445: Current learning rate: 0.00672
2025-05-29 14:39:49.748609: train_loss -1.0315
2025-05-29 14:39:49.748789: val_loss -0.6162
2025-05-29 14:39:49.748899: Pseudo dice [0.9029, 0.7051, 0.4172, 0.6528, 0.0294, 0.9047, 0.5869, 0.6945]
2025-05-29 14:39:49.748974: Epoch time: 31.09 s
2025-05-29 14:39:49.749026: Yayy! New best EMA pseudo Dice: 0.5936
2025-05-29 14:39:52.308315: 
2025-05-29 14:39:52.308611: Epoch 108
2025-05-29 14:39:52.308748: Current learning rate: 0.00669
2025-05-29 14:40:23.084945: train_loss -1.0178
2025-05-29 14:40:23.085116: val_loss -0.6238
2025-05-29 14:40:23.085226: Pseudo dice [0.859, 0.6701, 0.4277, 0.6964, 0.2059, 0.8999, 0.5788, 0.6044]
2025-05-29 14:40:23.085307: Epoch time: 30.78 s
2025-05-29 14:40:23.085421: Yayy! New best EMA pseudo Dice: 0.596
2025-05-29 14:40:25.505589: 
2025-05-29 14:40:25.505774: Epoch 109
2025-05-29 14:40:25.505878: Current learning rate: 0.00666
2025-05-29 14:40:56.594101: train_loss -1.0414
2025-05-29 14:40:56.594406: val_loss -0.5784
2025-05-29 14:40:56.594544: Pseudo dice [0.8983, 0.7121, 0.4168, 0.6061, 0.2316, 0.9282, 0.5337, 0.6206]
2025-05-29 14:22:16.809204: Yayy! New best EMA pseudo Dice: 0.4398
2025-05-29 14:22:19.452065: 
2025-05-29 14:22:19.452425: Epoch 32
2025-05-29 14:22:19.452576: Current learning rate: 0.00903
2025-05-29 14:23:33.724632: train_loss -0.5556
2025-05-29 14:23:33.724867: val_loss -0.3993
2025-05-29 14:23:33.724986: Pseudo dice [0.8645, 0.4341, 0.3008, 0.515, 0.0, 0.8579, 0.3967, 0.539]
2025-05-29 14:23:33.725095: Epoch time: 74.27 s
2025-05-29 14:23:33.725157: Yayy! New best EMA pseudo Dice: 0.4447
2025-05-29 14:23:36.418661: 
2025-05-29 14:23:36.419117: Epoch 33
2025-05-29 14:23:36.419228: Current learning rate: 0.009
2025-05-29 14:24:51.166063: train_loss -0.573
2025-05-29 14:24:51.173329: val_loss -0.3823
2025-05-29 14:24:51.173490: Pseudo dice [0.8292, 0.4634, 0.3283, 0.4954, 0.0, 0.8428, 0.5088, 0.5857]
2025-05-29 14:24:51.173584: Epoch time: 74.75 s
2025-05-29 14:24:51.173637: Yayy! New best EMA pseudo Dice: 0.4509
2025-05-29 14:24:53.710412: 
2025-05-29 14:24:53.710833: Epoch 34
2025-05-29 14:24:53.711068: Current learning rate: 0.00897
2025-05-29 14:26:07.717433: train_loss -0.506
2025-05-29 14:26:07.717776: val_loss -0.3749
2025-05-29 14:26:07.717903: Pseudo dice [0.8489, 0.4505, 0.3296, 0.5536, 0.0, 0.8871, 0.4272, 0.5124]
2025-05-29 14:26:07.718010: Epoch time: 74.01 s
2025-05-29 14:26:07.718060: Yayy! New best EMA pseudo Dice: 0.4559
2025-05-29 14:26:10.511080: 
2025-05-29 14:26:10.511363: Epoch 35
2025-05-29 14:26:10.511487: Current learning rate: 0.00894
2025-05-29 14:27:24.372051: train_loss -0.5287
2025-05-29 14:27:24.372392: val_loss -0.3443
2025-05-29 14:27:24.372553: Pseudo dice [0.8629, 0.4112, 0.3252, 0.322, 0.0, 0.8274, 0.3755, 0.5633]
2025-05-29 14:27:24.372653: Epoch time: 73.86 s
2025-05-29 14:27:24.372704: Yayy! New best EMA pseudo Dice: 0.4564
2025-05-29 14:27:27.067036: 
2025-05-29 14:27:27.067405: Epoch 36
2025-05-29 14:27:27.067553: Current learning rate: 0.00891
2025-05-29 14:28:40.354917: train_loss -0.5581
2025-05-29 14:28:40.361616: val_loss -0.3542
2025-05-29 14:28:40.361782: Pseudo dice [0.852, 0.484, 0.3107, 0.5061, 0.0, 0.8513, 0.4262, 0.486]
2025-05-29 14:28:40.361875: Epoch time: 73.29 s
2025-05-29 14:28:40.361929: Yayy! New best EMA pseudo Dice: 0.4597
2025-05-29 14:28:42.824350: 
2025-05-29 14:28:42.824785: Epoch 37
2025-05-29 14:28:42.825032: Current learning rate: 0.00888
2025-05-29 14:29:57.018223: train_loss -0.581
2025-05-29 14:29:57.018550: val_loss -0.4261
2025-05-29 14:29:57.018674: Pseudo dice [0.8544, 0.4441, 0.3384, 0.5534, 0.0, 0.8462, 0.3331, 0.591]
2025-05-29 14:29:57.018759: Epoch time: 74.2 s
2025-05-29 14:29:57.018816: Yayy! New best EMA pseudo Dice: 0.4633
2025-05-29 14:29:59.842317: 
2025-05-29 14:29:59.842797: Epoch 38
2025-05-29 14:29:59.842911: Current learning rate: 0.00885
2025-05-29 14:31:15.265928: train_loss -0.6252
2025-05-29 14:31:15.266222: val_loss -0.4613
2025-05-29 14:31:15.266391: Pseudo dice [0.8826, 0.4774, 0.3379, 0.5294, 0.0, 0.8678, 0.4934, 0.6502]
2025-05-29 14:31:15.266509: Epoch time: 75.42 s
2025-05-29 14:31:15.266581: Yayy! New best EMA pseudo Dice: 0.4699
2025-05-29 14:31:17.824703: 
2025-05-29 14:31:17.825045: Epoch 39
2025-05-29 14:31:17.825151: Current learning rate: 0.00882
2025-05-29 14:32:32.018791: train_loss -0.6073
2025-05-29 14:32:32.019180: val_loss -0.4195
2025-05-29 14:32:32.019344: Pseudo dice [0.866, 0.4588, 0.3949, 0.4685, 0.0, 0.8403, 0.485, 0.6268]
2025-05-29 14:32:32.019441: Epoch time: 74.2 s
2025-05-29 14:32:32.019502: Yayy! New best EMA pseudo Dice: 0.4747
2025-05-29 14:32:35.351924: 
2025-05-29 14:32:35.352419: Epoch 40
2025-05-29 14:32:35.352618: Current learning rate: 0.00879
2025-05-29 14:33:48.432846: train_loss -0.5877
2025-05-29 14:33:48.433082: val_loss -0.6244
2025-05-29 14:33:48.433199: Pseudo dice [0.881, 0.5334, 0.3612, 0.712, 0.0, 0.8993, 0.4932, 0.666]
2025-05-29 14:33:48.433289: Epoch time: 73.08 s
2025-05-29 14:33:48.433341: Yayy! New best EMA pseudo Dice: 0.484
2025-05-29 14:33:51.188152: 
2025-05-29 14:33:51.188520: Epoch 41
2025-05-29 14:33:51.188678: Current learning rate: 0.00876
2025-05-29 14:35:05.636879: train_loss -0.6647
2025-05-29 14:35:05.637176: val_loss -0.5446
2025-05-29 14:35:05.637290: Pseudo dice [0.8883, 0.5392, 0.3666, 0.6576, 0.0, 0.8949, 0.4628, 0.6392]
2025-05-29 14:35:05.637372: Epoch time: 74.45 s
2025-05-29 14:35:05.637433: Yayy! New best EMA pseudo Dice: 0.4912
2025-05-29 14:35:08.431627: 
2025-05-29 14:35:08.431967: Epoch 42
2025-05-29 14:35:08.432102: Current learning rate: 0.00873
2025-05-29 14:36:22.961928: train_loss -0.654
2025-05-29 14:36:22.962237: val_loss -0.4125
2025-05-29 14:36:22.962398: Pseudo dice [0.8454, 0.4832, 0.3471, 0.4624, 0.0, 0.8993, 0.5209, 0.4084]
2025-05-29 14:36:22.962517: Epoch time: 74.53 s
2025-05-29 14:36:22.962570: Yayy! New best EMA pseudo Dice: 0.4917
2025-05-29 14:36:25.575558: 
2025-05-29 14:36:25.575897: Epoch 43
2025-05-29 14:36:25.576032: Current learning rate: 0.0087
2025-05-29 14:37:43.747201: train_loss -0.6109
2025-05-29 14:37:43.747671: val_loss -0.4921
2025-05-29 14:37:43.747809: Pseudo dice [0.8941, 0.5043, 0.3796, 0.5397, 0.0, 0.8814, 0.4941, 0.6667]
2025-05-29 14:37:43.747893: Epoch time: 78.17 s
2025-05-29 14:37:43.747945: Yayy! New best EMA pseudo Dice: 0.497
2025-05-29 14:37:46.468003: 
2025-05-29 14:37:46.468374: Epoch 44
2025-05-29 14:37:46.468492: Current learning rate: 0.00867
2025-05-29 14:39:01.474593: train_loss -0.6983
2025-05-29 14:39:01.474785: val_loss -0.4615
2025-05-29 14:39:01.474899: Pseudo dice [0.8792, 0.5167, 0.256, 0.5067, 0.0, 0.874, 0.5162, 0.6693]
2025-05-29 14:39:01.474977: Epoch time: 75.01 s
2025-05-29 14:39:01.475028: Yayy! New best EMA pseudo Dice: 0.5001
2025-05-29 14:39:04.085971: 
2025-05-29 14:39:04.086169: Epoch 45
2025-05-29 14:39:04.086390: Current learning rate: 0.00864
2025-05-29 14:40:19.430830: train_loss -0.7052
2025-05-29 14:40:19.431137: val_loss -0.5906
2025-05-29 14:40:19.431270: Pseudo dice [0.8871, 0.5745, 0.364, 0.6246, 0.0, 0.9124, 0.5274, 0.6323]
2025-05-29 14:40:19.431376: Epoch time: 75.35 s
2025-05-29 14:40:19.431427: Yayy! New best EMA pseudo Dice: 0.5066
2025-05-29 14:40:22.138639: 
2025-05-29 14:40:22.138973: Epoch 46
2025-05-29 14:40:22.139100: Current learning rate: 0.00861
2025-05-29 14:41:38.750715: train_loss -0.7447
2025-05-29 14:41:38.751029: val_loss -0.5834
2025-05-29 14:41:38.751153: Pseudo dice [0.8902, 0.5, 0.3922, 0.6677, 0.0, 0.8727, 0.5802, 0.6618]
2025-05-29 14:41:38.751277: Epoch time: 76.61 s
2025-05-29 14:41:38.751325: Yayy! New best EMA pseudo Dice: 0.513
2025-05-29 14:41:41.626223: 
2025-05-29 14:41:41.626469: Epoch 47
2025-05-29 14:41:41.626573: Current learning rate: 0.00858
2025-05-29 14:42:58.624490: train_loss -0.7615
2025-05-29 14:42:58.624802: val_loss -0.6359
2025-05-29 14:42:58.624929: Pseudo dice [0.9005, 0.5614, 0.3558, 0.7048, 0.0, 0.9032, 0.5307, 0.6746]
2025-05-29 14:42:58.625028: Epoch time: 77.0 s
2025-05-29 14:42:58.625077: Yayy! New best EMA pseudo Dice: 0.5196
2025-05-29 14:43:01.309495: 
2025-05-29 14:43:01.309624: Epoch 48
2025-05-29 14:43:01.309729: Current learning rate: 0.00855
2025-05-29 14:44:20.379481: train_loss -0.7604
2025-05-29 14:44:20.379724: val_loss -0.5888
2025-05-29 14:44:20.379842: Pseudo dice [0.8904, 0.578, 0.3605, 0.6425, 0.0, 0.8936, 0.5224, 0.6848]
2025-05-29 14:44:20.379925: Epoch time: 79.07 s
2025-05-29 14:44:20.379980: Yayy! New best EMA pseudo Dice: 0.5248
2025-05-29 14:44:24.218408: 
2025-05-29 14:44:24.218673: Epoch 49
2025-05-29 14:44:24.218790: Current learning rate: 0.00852
2025-05-29 14:45:41.713121: train_loss -0.7189
2025-05-29 14:45:41.713482: val_loss -0.4056
2025-05-29 14:45:41.713620: Pseudo dice [0.8744, 0.5144, 0.3826, 0.458, 0.0, 0.84, 0.507, 0.5713]
2025-05-29 14:45:41.713717: Epoch time: 77.5 s
2025-05-29 14:45:43.561525: 
2025-05-29 14:45:43.561705: Epoch 50
2025-05-29 14:45:43.561805: Current learning rate: 0.00849
2025-05-29 14:47:01.344883: train_loss -0.6808
2025-05-29 14:47:01.345096: val_loss -0.6184
2025-05-29 14:47:01.345303: Pseudo dice [0.899, 0.5412, 0.3761, 0.6802, 0.0, 0.8957, 0.5069, 0.7226]
2025-05-29 14:47:01.345384: Epoch time: 77.78 s
2025-05-29 14:47:01.345431: Yayy! New best EMA pseudo Dice: 0.5295
2025-05-29 14:40:56.594960: Epoch time: 31.09 s
2025-05-29 14:40:56.595027: Yayy! New best EMA pseudo Dice: 0.5982
2025-05-29 14:40:59.093244: 
2025-05-29 14:40:59.093646: Epoch 110
2025-05-29 14:40:59.093738: Current learning rate: 0.00663
2025-05-29 14:41:30.168266: train_loss -1.0389
2025-05-29 14:41:30.168623: val_loss -0.6339
2025-05-29 14:41:30.168736: Pseudo dice [0.891, 0.7, 0.4112, 0.6925, 0.2129, 0.8713, 0.5075, 0.6614]
2025-05-29 14:41:30.168831: Epoch time: 31.08 s
2025-05-29 14:41:30.168880: Yayy! New best EMA pseudo Dice: 0.6002
2025-05-29 14:41:32.927516: 
2025-05-29 14:41:32.927747: Epoch 111
2025-05-29 14:41:32.927836: Current learning rate: 0.0066
2025-05-29 14:42:03.760827: train_loss -1.0457
2025-05-29 14:42:03.761046: val_loss -0.5349
2025-05-29 14:42:03.761160: Pseudo dice [0.8904, 0.7157, 0.4047, 0.6098, 0.1944, 0.8684, 0.5463, 0.5531]
2025-05-29 14:42:03.761241: Epoch time: 30.83 s
2025-05-29 14:42:05.150065: 
2025-05-29 14:42:05.150403: Epoch 112
2025-05-29 14:42:05.150645: Current learning rate: 0.00657
2025-05-29 14:42:36.098735: train_loss -1.0329
2025-05-29 14:42:36.099138: val_loss -0.5226
2025-05-29 14:42:36.099342: Pseudo dice [0.8766, 0.6816, 0.3778, 0.5876, 0.1776, 0.8811, 0.5543, 0.5609]
2025-05-29 14:42:36.099492: Epoch time: 30.95 s
2025-05-29 14:42:37.528640: 
2025-05-29 14:42:37.529095: Epoch 113
2025-05-29 14:42:37.529298: Current learning rate: 0.00654
2025-05-29 14:43:08.394359: train_loss -1.052
2025-05-29 14:43:08.394718: val_loss -0.6497
2025-05-29 14:43:08.394845: Pseudo dice [0.8973, 0.7049, 0.4274, 0.6542, 0.3074, 0.8871, 0.5863, 0.6461]
2025-05-29 14:43:08.394936: Epoch time: 30.87 s
2025-05-29 14:43:08.394988: Yayy! New best EMA pseudo Dice: 0.6027
2025-05-29 14:43:11.026556: 
2025-05-29 14:43:11.026887: Epoch 114
2025-05-29 14:43:11.027050: Current learning rate: 0.0065
2025-05-29 14:43:42.207815: train_loss -1.0624
2025-05-29 14:43:42.208032: val_loss -0.6139
2025-05-29 14:43:42.208142: Pseudo dice [0.8737, 0.6556, 0.4457, 0.6327, 0.1714, 0.8703, 0.6032, 0.6528]
2025-05-29 14:43:42.208223: Epoch time: 31.18 s
2025-05-29 14:43:42.208275: Yayy! New best EMA pseudo Dice: 0.6038
2025-05-29 14:43:45.094194: 
2025-05-29 14:43:45.094456: Epoch 115
2025-05-29 14:43:45.094552: Current learning rate: 0.00647
2025-05-29 14:44:16.318179: train_loss -1.0805
2025-05-29 14:44:16.318385: val_loss -0.6565
2025-05-29 14:44:16.318507: Pseudo dice [0.9028, 0.7009, 0.4134, 0.6919, 0.2193, 0.9097, 0.5127, 0.6639]
2025-05-29 14:44:16.318592: Epoch time: 31.23 s
2025-05-29 14:44:16.318645: Yayy! New best EMA pseudo Dice: 0.6061
2025-05-29 14:44:19.373526: 
2025-05-29 14:44:19.373911: Epoch 116
2025-05-29 14:44:19.374053: Current learning rate: 0.00644
2025-05-29 14:44:50.297418: train_loss -1.068
2025-05-29 14:44:50.297881: val_loss -0.5913
2025-05-29 14:44:50.298001: Pseudo dice [0.8937, 0.6868, 0.4354, 0.6067, 0.047, 0.8838, 0.594, 0.6172]
2025-05-29 14:44:50.298082: Epoch time: 30.93 s
2025-05-29 14:44:52.708043: 
2025-05-29 14:44:52.708630: Epoch 117
2025-05-29 14:44:52.708744: Current learning rate: 0.00641
2025-05-29 14:45:23.840361: train_loss -1.0589
2025-05-29 14:45:23.840623: val_loss -0.624
2025-05-29 14:45:23.840751: Pseudo dice [0.8936, 0.6675, 0.3639, 0.6587, 0.1475, 0.92, 0.592, 0.6457]
2025-05-29 14:45:23.840878: Epoch time: 31.13 s
2025-05-29 14:45:25.236126: 
2025-05-29 14:45:25.236548: Epoch 118
2025-05-29 14:45:25.236690: Current learning rate: 0.00638
2025-05-29 14:45:56.120845: train_loss -1.0486
2025-05-29 14:45:56.121166: val_loss -0.5664
2025-05-29 14:45:56.121284: Pseudo dice [0.8933, 0.6637, 0.3941, 0.5948, 0.1916, 0.9019, 0.5532, 0.6831]
2025-05-29 14:45:56.121362: Epoch time: 30.89 s
2025-05-29 14:45:57.512843: 
2025-05-29 14:45:57.513209: Epoch 119
2025-05-29 14:45:57.513316: Current learning rate: 0.00635
2025-05-29 14:46:28.559109: train_loss -1.0726
2025-05-29 14:46:28.559302: val_loss -0.5844
2025-05-29 14:46:28.559491: Pseudo dice [0.8843, 0.6508, 0.4005, 0.5997, 0.228, 0.8936, 0.5685, 0.6349]
2025-05-29 14:46:28.559576: Epoch time: 31.05 s
2025-05-29 14:46:28.559650: Yayy! New best EMA pseudo Dice: 0.6062
2025-05-29 14:46:31.595977: 
2025-05-29 14:46:31.596368: Epoch 120
2025-05-29 14:46:31.596558: Current learning rate: 0.00631
2025-05-29 14:47:02.370018: train_loss -1.0365
2025-05-29 14:47:02.370328: val_loss -0.519
2025-05-29 14:47:02.370459: Pseudo dice [0.8735, 0.6612, 0.3928, 0.5993, 0.1199, 0.8907, 0.5328, 0.5926]
2025-05-29 14:47:02.370583: Epoch time: 30.78 s
2025-05-29 14:47:03.702743: 
2025-05-29 14:47:03.703133: Epoch 121
2025-05-29 14:47:03.703243: Current learning rate: 0.00628
2025-05-29 14:47:34.597017: train_loss -1.0138
2025-05-29 14:47:34.597226: val_loss -0.6014
2025-05-29 14:47:34.597341: Pseudo dice [0.8922, 0.6633, 0.3877, 0.6208, 0.2218, 0.9052, 0.5388, 0.6176]
2025-05-29 14:47:34.597505: Epoch time: 30.9 s
2025-05-29 14:47:35.951707: 
2025-05-29 14:47:35.951877: Epoch 122
2025-05-29 14:47:35.951987: Current learning rate: 0.00625
2025-05-29 14:48:06.927958: train_loss -1.0353
2025-05-29 14:48:06.928481: val_loss -0.5883
2025-05-29 14:48:06.928625: Pseudo dice [0.8806, 0.6907, 0.3998, 0.621, 0.2277, 0.8779, 0.5612, 0.6271]
2025-05-29 14:48:06.928792: Epoch time: 30.98 s
2025-05-29 14:48:08.250956: 
2025-05-29 14:48:08.251166: Epoch 123
2025-05-29 14:48:08.251268: Current learning rate: 0.00622
2025-05-29 14:48:38.979093: train_loss -1.0493
2025-05-29 14:48:38.979432: val_loss -0.5606
2025-05-29 14:48:38.979642: Pseudo dice [0.8707, 0.6764, 0.4173, 0.5785, 0.2572, 0.8797, 0.5327, 0.6153]
2025-05-29 14:48:38.979730: Epoch time: 30.73 s
2025-05-29 14:48:40.287657: 
2025-05-29 14:48:40.287833: Epoch 124
2025-05-29 14:48:40.288044: Current learning rate: 0.00619
2025-05-29 14:49:11.259059: train_loss -1.0799
2025-05-29 14:49:11.259286: val_loss -0.5177
2025-05-29 14:49:11.259392: Pseudo dice [0.896, 0.645, 0.4404, 0.5369, 0.2401, 0.9201, 0.5475, 0.5856]
2025-05-29 14:49:11.259485: Epoch time: 30.97 s
2025-05-29 14:49:12.596409: 
2025-05-29 14:49:12.596630: Epoch 125
2025-05-29 14:49:12.596770: Current learning rate: 0.00616
2025-05-29 14:49:43.351352: train_loss -1.0686
2025-05-29 14:49:43.351622: val_loss -0.5202
2025-05-29 14:49:43.351737: Pseudo dice [0.8783, 0.6528, 0.3797, 0.6257, 0.0732, 0.8627, 0.5812, 0.6711]
2025-05-29 14:49:43.351820: Epoch time: 30.76 s
2025-05-29 14:49:44.795741: 
2025-05-29 14:49:44.796053: Epoch 126
2025-05-29 14:49:44.796239: Current learning rate: 0.00612
2025-05-29 14:50:16.045125: train_loss -1.0307
2025-05-29 14:50:16.045999: val_loss -0.6475
2025-05-29 14:50:16.046169: Pseudo dice [0.9081, 0.697, 0.4294, 0.6772, 0.1799, 0.8948, 0.5201, 0.6443]
2025-05-29 14:50:16.046317: Epoch time: 31.25 s
2025-05-29 14:50:17.448355: 
2025-05-29 14:50:17.448806: Epoch 127
2025-05-29 14:50:17.449015: Current learning rate: 0.00609
2025-05-29 14:50:48.516171: train_loss -1.0998
2025-05-29 14:50:48.516511: val_loss -0.6167
2025-05-29 14:50:48.516682: Pseudo dice [0.8915, 0.6792, 0.4121, 0.6621, 0.1647, 0.9056, 0.5885, 0.656]
2025-05-29 14:50:48.516786: Epoch time: 31.07 s
2025-05-29 14:50:50.764267: 
2025-05-29 14:50:50.764656: Epoch 128
2025-05-29 14:50:50.764766: Current learning rate: 0.00606
2025-05-29 14:51:21.405921: train_loss -1.0943
2025-05-29 14:51:21.406795: val_loss -0.5043
2025-05-29 14:51:21.406964: Pseudo dice [0.891, 0.6917, 0.4035, 0.5731, 0.1125, 0.8759, 0.559, 0.5737]
2025-05-29 14:51:21.407116: Epoch time: 30.64 s
2025-05-29 14:51:22.784492: 
2025-05-29 14:51:22.784676: Epoch 129
2025-05-29 14:51:22.784797: Current learning rate: 0.00603
2025-05-29 14:51:53.932984: train_loss -1.1027
2025-05-29 14:51:53.933257: val_loss -0.6235
2025-05-29 14:51:53.933377: Pseudo dice [0.893, 0.6596, 0.4419, 0.6931, 0.1612, 0.8973, 0.5346, 0.6526]
2025-05-29 14:51:53.933473: Epoch time: 31.15 s
2025-05-29 14:51:55.323853: 
2025-05-29 14:51:55.324099: Epoch 130
2025-05-29 14:51:55.324191: Current learning rate: 0.006
2025-05-29 14:52:26.162809: train_loss -1.0652
2025-05-29 14:52:26.163023: val_loss -0.5442
2025-05-29 14:52:26.163134: Pseudo dice [0.8748, 0.6806, 0.3006, 0.6506, 0.1252, 0.8556, 0.5359, 0.5558]
2025-05-29 14:52:26.163222:
2025-05-29 14:24:02.591844: Yayy! New best EMA pseudo Dice: 0.4113
2025-05-29 14:24:05.345097: 
2025-05-29 14:24:05.345461: Epoch 32
2025-05-29 14:24:05.345581: Current learning rate: 0.00903
2025-05-29 14:25:35.083026: train_loss -0.5657
2025-05-29 14:25:35.083262: val_loss -0.4533
2025-05-29 14:25:35.083382: Pseudo dice [0.8504, 0.376, 0.2666, 0.5964, 0.0, 0.826, 0.4456, 0.5443]
2025-05-29 14:25:35.083486: Epoch time: 89.74 s
2025-05-29 14:25:35.083622: Yayy! New best EMA pseudo Dice: 0.419
2025-05-29 14:25:37.886315: 
2025-05-29 14:25:37.886684: Epoch 33
2025-05-29 14:25:37.886789: Current learning rate: 0.009
2025-05-29 14:27:05.395255: train_loss -0.4949
2025-05-29 14:27:05.395540: val_loss -0.2853
2025-05-29 14:27:05.395658: Pseudo dice [0.7907, 0.3633, 0.1684, 0.4684, 0.0, 0.7206, 0.373, 0.4782]
2025-05-29 14:27:05.395804: Epoch time: 87.51 s
2025-05-29 14:27:05.395860: Yayy! New best EMA pseudo Dice: 0.4191
2025-05-29 14:27:08.044762: 
2025-05-29 14:27:08.044889: Epoch 34
2025-05-29 14:27:08.045064: Current learning rate: 0.00897
2025-05-29 14:28:36.323121: train_loss -0.5652
2025-05-29 14:28:36.323356: val_loss -0.4452
2025-05-29 14:28:36.323478: Pseudo dice [0.8374, 0.4272, 0.2603, 0.5786, 0.0, 0.8078, 0.3338, 0.5614]
2025-05-29 14:28:36.323572: Epoch time: 88.28 s
2025-05-29 14:28:36.323624: Yayy! New best EMA pseudo Dice: 0.4248
2025-05-29 14:28:38.988185: 
2025-05-29 14:28:38.988456: Epoch 35
2025-05-29 14:28:38.988552: Current learning rate: 0.00894
2025-05-29 14:30:03.389616: train_loss -0.6347
2025-05-29 14:30:03.389923: val_loss -0.4847
2025-05-29 14:30:03.390042: Pseudo dice [0.846, 0.4056, 0.3064, 0.6162, 0.0, 0.8379, 0.4002, 0.6394]
2025-05-29 14:30:03.390129: Epoch time: 84.4 s
2025-05-29 14:30:03.390188: Yayy! New best EMA pseudo Dice: 0.4329
2025-05-29 14:30:05.896540: 
2025-05-29 14:30:05.896835: Epoch 36
2025-05-29 14:30:05.896995: Current learning rate: 0.00891
2025-05-29 14:31:29.470071: train_loss -0.6292
2025-05-29 14:31:29.470331: val_loss -0.3603
2025-05-29 14:31:29.470458: Pseudo dice [0.8529, 0.4825, 0.2838, 0.3877, 0.0, 0.7855, 0.3674, 0.6827]
2025-05-29 14:31:29.470551: Epoch time: 83.57 s
2025-05-29 14:31:29.470605: Yayy! New best EMA pseudo Dice: 0.4377
2025-05-29 14:31:31.935535: 
2025-05-29 14:31:31.935790: Epoch 37
2025-05-29 14:31:31.935912: Current learning rate: 0.00888
2025-05-29 14:33:00.059349: train_loss -0.5892
2025-05-29 14:33:00.059571: val_loss -0.3938
2025-05-29 14:33:00.059704: Pseudo dice [0.826, 0.417, 0.2747, 0.4852, 0.0, 0.8203, 0.4181, 0.6268]
2025-05-29 14:33:00.059785: Epoch time: 88.13 s
2025-05-29 14:33:00.059835: Yayy! New best EMA pseudo Dice: 0.4423
2025-05-29 14:33:02.811272: 
2025-05-29 14:33:02.811653: Epoch 38
2025-05-29 14:33:02.811748: Current learning rate: 0.00885
2025-05-29 14:34:29.019496: train_loss -0.5709
2025-05-29 14:34:29.019713: val_loss -0.3433
2025-05-29 14:34:29.019825: Pseudo dice [0.8106, 0.3759, 0.2888, 0.456, 0.0, 0.6997, 0.4188, 0.5487]
2025-05-29 14:34:29.019910: Epoch time: 86.21 s
2025-05-29 14:34:29.020037: Yayy! New best EMA pseudo Dice: 0.443
2025-05-29 14:34:31.543644: 
2025-05-29 14:34:31.543887: Epoch 39
2025-05-29 14:34:31.544012: Current learning rate: 0.00882
2025-05-29 14:36:00.941848: train_loss -0.5944
2025-05-29 14:36:00.942050: val_loss -0.3827
2025-05-29 14:36:00.942172: Pseudo dice [0.8167, 0.4249, 0.3081, 0.484, 0.0, 0.7393, 0.395, 0.6591]
2025-05-29 14:36:00.942252: Epoch time: 89.4 s
2025-05-29 14:36:00.942371: Yayy! New best EMA pseudo Dice: 0.4466
2025-05-29 14:36:04.238891: 
2025-05-29 14:36:04.239107: Epoch 40
2025-05-29 14:36:04.239208: Current learning rate: 0.00879
2025-05-29 14:37:36.901894: train_loss -0.6354
2025-05-29 14:37:36.902096: val_loss -0.5796
2025-05-29 14:37:36.902203: Pseudo dice [0.8638, 0.4083, 0.3234, 0.6864, 0.0, 0.8192, 0.4331, 0.6513]
2025-05-29 14:37:36.902288: Epoch time: 92.66 s
2025-05-29 14:37:36.902340: Yayy! New best EMA pseudo Dice: 0.4542
2025-05-29 14:37:39.542963: 
2025-05-29 14:37:39.543323: Epoch 41
2025-05-29 14:37:39.543433: Current learning rate: 0.00876
2025-05-29 14:39:07.039799: train_loss -0.6205
2025-05-29 14:39:07.040012: val_loss -0.4192
2025-05-29 14:39:07.040122: Pseudo dice [0.8552, 0.4702, 0.2695, 0.4842, 0.0, 0.8065, 0.3821, 0.6465]
2025-05-29 14:39:07.040202: Epoch time: 87.5 s
2025-05-29 14:39:07.040257: Yayy! New best EMA pseudo Dice: 0.4577
2025-05-29 14:39:09.621032: 
2025-05-29 14:39:09.621231: Epoch 42
2025-05-29 14:39:09.621338: Current learning rate: 0.00873
2025-05-29 14:40:37.251403: train_loss -0.6405
2025-05-29 14:40:37.251738: val_loss -0.5391
2025-05-29 14:40:37.251859: Pseudo dice [0.8727, 0.4341, 0.3175, 0.6139, 0.0, 0.8205, 0.4258, 0.631]
2025-05-29 14:40:37.251943: Epoch time: 87.63 s
2025-05-29 14:40:37.252003: Yayy! New best EMA pseudo Dice: 0.4634
2025-05-29 14:40:40.020031: 
2025-05-29 14:40:40.020479: Epoch 43
2025-05-29 14:40:40.020601: Current learning rate: 0.0087
2025-05-29 14:42:09.026043: train_loss -0.5837
2025-05-29 14:42:09.026287: val_loss -0.4369
2025-05-29 14:42:09.026409: Pseudo dice [0.7974, 0.4654, 0.2577, 0.5742, 0.0, 0.8363, 0.4441, 0.5043]
2025-05-29 14:42:09.026516: Epoch time: 89.01 s
2025-05-29 14:42:09.026583: Yayy! New best EMA pseudo Dice: 0.4656
2025-05-29 14:42:11.764628: 
2025-05-29 14:42:11.764985: Epoch 44
2025-05-29 14:42:11.765138: Current learning rate: 0.00867
2025-05-29 14:43:39.747311: train_loss -0.6226
2025-05-29 14:43:39.747641: val_loss -0.4693
2025-05-29 14:43:39.747770: Pseudo dice [0.856, 0.495, 0.28, 0.5325, 0.0, 0.8144, 0.4229, 0.6472]
2025-05-29 14:43:39.747876: Epoch time: 87.99 s
2025-05-29 14:43:39.748029: Yayy! New best EMA pseudo Dice: 0.4696
2025-05-29 14:43:42.649361: 
2025-05-29 14:43:42.649736: Epoch 45
2025-05-29 14:43:42.649847: Current learning rate: 0.00864
2025-05-29 14:45:07.658516: train_loss -0.6702
2025-05-29 14:45:07.658751: val_loss -0.4975
2025-05-29 14:45:07.658867: Pseudo dice [0.869, 0.4457, 0.291, 0.5995, 0.0, 0.742, 0.4465, 0.6509]
2025-05-29 14:45:07.658949: Epoch time: 85.01 s
2025-05-29 14:45:07.659000: Yayy! New best EMA pseudo Dice: 0.4732
2025-05-29 14:45:10.400114: 
2025-05-29 14:45:10.400434: Epoch 46
2025-05-29 14:45:10.400568: Current learning rate: 0.00861
2025-05-29 14:46:34.584254: train_loss -0.6786
2025-05-29 14:46:34.584487: val_loss -0.5934
2025-05-29 14:46:34.584602: Pseudo dice [0.8699, 0.4851, 0.2553, 0.6723, 0.0, 0.7478, 0.4709, 0.7339]
2025-05-29 14:46:34.584696: Epoch time: 84.19 s
2025-05-29 14:46:34.584747: Yayy! New best EMA pseudo Dice: 0.4788
2025-05-29 14:46:37.385397: 
2025-05-29 14:46:37.385750: Epoch 47
2025-05-29 14:46:37.385890: Current learning rate: 0.00858
2025-05-29 14:48:07.936012: train_loss -0.6796
2025-05-29 14:48:07.936426: val_loss -0.4731
2025-05-29 14:48:07.936687: Pseudo dice [0.861, 0.4449, 0.2832, 0.6046, 0.0, 0.7911, 0.4493, 0.6277]
2025-05-29 14:48:07.936789: Epoch time: 90.55 s
2025-05-29 14:48:07.936842: Yayy! New best EMA pseudo Dice: 0.4817
2025-05-29 14:48:10.541128: 
2025-05-29 14:48:10.541320: Epoch 48
2025-05-29 14:48:10.541425: Current learning rate: 0.00855
2025-05-29 14:49:39.987599: train_loss -0.708
2025-05-29 14:49:39.987873: val_loss -0.475
2025-05-29 14:49:39.988017: Pseudo dice [0.8721, 0.4619, 0.3069, 0.5228, 0.0, 0.7866, 0.3554, 0.699]
2025-05-29 14:49:39.988095: Epoch time: 89.45 s
2025-05-29 14:49:39.988156: Yayy! New best EMA pseudo Dice: 0.4836
2025-05-29 14:49:43.587702: 
2025-05-29 14:49:43.588079: Epoch 49
2025-05-29 14:49:43.588174: Current learning rate: 0.00852
2025-05-29 14:51:13.931809: train_loss -0.7348
2025-05-29 14:51:13.932119: val_loss -0.45
2025-05-29 14:51:13.932240: Pseudo dice [0.8384, 0.4865, 0.3331, 0.5728, 0.0, 0.7502, 0.4862, 0.6406]
2025-05-29 14:51:13.932316: Epoch time: 90.35 s
2025-05-29 14:51:14.527127: Yayy! New best EMA pseudo Dice: 0.4866
2025-05-29 14:51:18.801178: 
2025-05-29 14:51:18.801496: Epoch 50
2025-05-29 14:51:18.801654: Current learning rate: 0.00849
2025-05-29 14:52:49.138142: train_loss -0.7307
2025-05-29 14:52:49.138586: val_loss -0.5765
2025-05-29 14:52:49.138807: Pseudo dice [0.8799, 0.502, 0.3615, 0.6277, 0.0, 0.7884, 0.4194, 0.7019]
2025-05-29 14:52:49.138892: Epoch time: 30.84 s
2025-05-29 14:52:27.503861: 
2025-05-29 14:52:27.504074: Epoch 131
2025-05-29 14:52:27.504172: Current learning rate: 0.00597
2025-05-29 14:52:58.698156: train_loss -1.0482
2025-05-29 14:52:58.698413: val_loss -0.5247
2025-05-29 14:52:58.698578: Pseudo dice [0.8633, 0.6613, 0.4485, 0.6168, 0.2061, 0.9082, 0.576, 0.6312]
2025-05-29 14:52:58.698682: Epoch time: 31.2 s
2025-05-29 14:53:00.047991: 
2025-05-29 14:53:00.048380: Epoch 132
2025-05-29 14:53:00.048617: Current learning rate: 0.00593
2025-05-29 14:53:31.132911: train_loss -1.0994
2025-05-29 14:53:31.133201: val_loss -0.4257
2025-05-29 14:53:31.133327: Pseudo dice [0.901, 0.7158, 0.3907, 0.43, 0.1468, 0.8574, 0.5548, 0.6337]
2025-05-29 14:53:31.133414: Epoch time: 31.09 s
2025-05-29 14:53:32.465719: 
2025-05-29 14:53:32.465947: Epoch 133
2025-05-29 14:53:32.466043: Current learning rate: 0.0059
2025-05-29 14:54:03.395388: train_loss -1.0295
2025-05-29 14:54:03.395758: val_loss -0.5318
2025-05-29 14:54:03.395905: Pseudo dice [0.8763, 0.6533, 0.4218, 0.609, 0.2104, 0.9152, 0.581, 0.5877]
2025-05-29 14:54:03.395996: Epoch time: 30.93 s
2025-05-29 14:54:04.731316: 
2025-05-29 14:54:04.731653: Epoch 134
2025-05-29 14:54:04.731751: Current learning rate: 0.00587
2025-05-29 14:54:35.742065: train_loss -1.0376
2025-05-29 14:54:35.742493: val_loss -0.5918
2025-05-29 14:54:35.742628: Pseudo dice [0.8883, 0.7322, 0.3538, 0.631, 0.2201, 0.8685, 0.5632, 0.6086]
2025-05-29 14:54:35.742715: Epoch time: 31.01 s
2025-05-29 14:54:37.120591: 
2025-05-29 14:54:37.120817: Epoch 135
2025-05-29 14:54:37.121105: Current learning rate: 0.00584
2025-05-29 14:55:08.116575: train_loss -1.0779
2025-05-29 14:55:08.117017: val_loss -0.6735
2025-05-29 14:55:08.117151: Pseudo dice [0.8978, 0.7054, 0.423, 0.7118, 0.2549, 0.9089, 0.5541, 0.606]
2025-05-29 14:55:08.117241: Epoch time: 31.0 s
2025-05-29 14:55:09.456960: 
2025-05-29 14:55:09.457422: Epoch 136
2025-05-29 14:55:09.457542: Current learning rate: 0.00581
2025-05-29 14:55:40.563554: train_loss -1.0879
2025-05-29 14:55:40.563933: val_loss -0.6539
2025-05-29 14:55:40.564122: Pseudo dice [0.9023, 0.7348, 0.4118, 0.6822, 0.3363, 0.9252, 0.561, 0.6276]
2025-05-29 14:55:40.564247: Epoch time: 31.11 s
2025-05-29 14:55:40.564330: Yayy! New best EMA pseudo Dice: 0.6093
2025-05-29 14:55:43.486946: 
2025-05-29 14:55:43.487200: Epoch 137
2025-05-29 14:55:43.487369: Current learning rate: 0.00578
2025-05-29 14:56:14.481938: train_loss -1.1068
2025-05-29 14:56:14.482231: val_loss -0.6194
2025-05-29 14:56:14.482350: Pseudo dice [0.8825, 0.6707, 0.4109, 0.7015, 0.2063, 0.8886, 0.5434, 0.5959]
2025-05-29 14:56:14.483055: Epoch time: 31.0 s
2025-05-29 14:56:14.483158: Yayy! New best EMA pseudo Dice: 0.6096
2025-05-29 14:56:17.333676: 
2025-05-29 14:56:17.334015: Epoch 138
2025-05-29 14:56:17.334121: Current learning rate: 0.00574
2025-05-29 14:56:49.290844: train_loss -1.0823
2025-05-29 14:56:49.291058: val_loss -0.5979
2025-05-29 14:56:49.291175: Pseudo dice [0.8951, 0.6488, 0.381, 0.6382, 0.3241, 0.9158, 0.5504, 0.6433]
2025-05-29 14:56:49.291255: Epoch time: 31.96 s
2025-05-29 14:56:49.291301: Yayy! New best EMA pseudo Dice: 0.6111
2025-05-29 14:56:52.254294: 
2025-05-29 14:56:52.254781: Epoch 139
2025-05-29 14:56:52.255055: Current learning rate: 0.00571
2025-05-29 14:57:23.440357: train_loss -1.0901
2025-05-29 14:57:23.440826: val_loss -0.5919
2025-05-29 14:57:23.440948: Pseudo dice [0.9021, 0.6892, 0.3305, 0.639, 0.1524, 0.8976, 0.5822, 0.6811]
2025-05-29 14:57:23.441070: Epoch time: 31.19 s
2025-05-29 14:57:24.794685: 
2025-05-29 14:57:24.795074: Epoch 140
2025-05-29 14:57:24.795179: Current learning rate: 0.00568
2025-05-29 14:57:55.729669: train_loss -1.071
2025-05-29 14:57:55.729967: val_loss -0.6176
2025-05-29 14:57:55.730163: Pseudo dice [0.8666, 0.6871, 0.4528, 0.6732, 0.2655, 0.8981, 0.5414, 0.6404]
2025-05-29 14:57:55.730285: Epoch time: 30.94 s
2025-05-29 14:57:55.730337: Yayy! New best EMA pseudo Dice: 0.6127
2025-05-29 14:57:58.662418: 
2025-05-29 14:57:58.662967: Epoch 141
2025-05-29 14:57:58.663307: Current learning rate: 0.00565
2025-05-29 14:58:29.689736: train_loss -1.0749
2025-05-29 14:58:29.690575: val_loss -0.654
2025-05-29 14:58:29.691005: Pseudo dice [0.8941, 0.664, 0.4335, 0.7281, 0.4271, 0.926, 0.5207, 0.6401]
2025-05-29 14:58:29.691413: Epoch time: 31.03 s
2025-05-29 14:58:29.691519: Yayy! New best EMA pseudo Dice: 0.6168
2025-05-29 14:58:32.612053: 
2025-05-29 14:58:32.612430: Epoch 142
2025-05-29 14:58:32.612560: Current learning rate: 0.00562
2025-05-29 14:59:03.524495: train_loss -1.1177
2025-05-29 14:59:03.524951: val_loss -0.4895
2025-05-29 14:59:03.525096: Pseudo dice [0.8855, 0.6797, 0.3775, 0.5684, 0.1875, 0.9211, 0.5631, 0.6306]
2025-05-29 14:59:03.525181: Epoch time: 30.91 s
2025-05-29 14:59:04.940353: 
2025-05-29 14:59:04.940712: Epoch 143
2025-05-29 14:59:04.940850: Current learning rate: 0.00558
2025-05-29 14:59:35.949142: train_loss -1.1408
2025-05-29 14:59:35.950023: val_loss -0.6485
2025-05-29 14:59:35.950140: Pseudo dice [0.8973, 0.7005, 0.4187, 0.71, 0.2762, 0.8968, 0.5382, 0.6011]
2025-05-29 14:59:35.950318: Epoch time: 31.01 s
2025-05-29 14:59:37.397908: 
2025-05-29 14:59:37.398178: Epoch 144
2025-05-29 14:59:37.398335: Current learning rate: 0.00555
2025-05-29 15:00:08.221915: train_loss -1.1216
2025-05-29 15:00:08.222401: val_loss -0.6506
2025-05-29 15:00:08.222615: Pseudo dice [0.8857, 0.6946, 0.3871, 0.7193, 0.2694, 0.9053, 0.4968, 0.6398]
2025-05-29 15:00:08.222820: Epoch time: 30.83 s
2025-05-29 15:00:08.222887: Yayy! New best EMA pseudo Dice: 0.6176
2025-05-29 15:00:10.959577: 
2025-05-29 15:00:10.960412: Epoch 145
2025-05-29 15:00:10.960566: Current learning rate: 0.00552
2025-05-29 15:00:41.967668: train_loss -1.1366
2025-05-29 15:00:41.968042: val_loss -0.5444
2025-05-29 15:00:41.968194: Pseudo dice [0.8955, 0.6901, 0.4116, 0.5874, 0.2616, 0.9196, 0.5334, 0.5428]
2025-05-29 15:00:41.968333: Epoch time: 31.01 s
2025-05-29 15:00:43.346465: 
2025-05-29 15:00:43.346669: Epoch 146
2025-05-29 15:00:43.346781: Current learning rate: 0.00549
2025-05-29 15:01:14.412345: train_loss -1.1129
2025-05-29 15:01:14.412702: val_loss -0.5058
2025-05-29 15:01:14.412887: Pseudo dice [0.8606, 0.6734, 0.3641, 0.6077, 0.2072, 0.893, 0.5531, 0.5699]
2025-05-29 15:01:14.412975: Epoch time: 31.07 s
2025-05-29 15:01:15.778064: 
2025-05-29 15:01:15.778239: Epoch 147
2025-05-29 15:01:15.778392: Current learning rate: 0.00546
2025-05-29 15:01:46.658921: train_loss -1.1208
2025-05-29 15:01:46.659134: val_loss -0.6213
2025-05-29 15:01:46.659257: Pseudo dice [0.8865, 0.6983, 0.4232, 0.6841, 0.1538, 0.8975, 0.5879, 0.6253]
2025-05-29 15:01:46.659344: Epoch time: 30.88 s
2025-05-29 15:01:48.122310: 
2025-05-29 15:01:48.122685: Epoch 148
2025-05-29 15:01:48.122966: Current learning rate: 0.00542
2025-05-29 15:02:19.142244: train_loss -1.153
2025-05-29 15:02:19.142501: val_loss -0.6143
2025-05-29 15:02:19.142633: Pseudo dice [0.8898, 0.7042, 0.4042, 0.6679, 0.1865, 0.9066, 0.5843, 0.6522]
2025-05-29 15:02:19.142735: Epoch time: 31.02 s
2025-05-29 15:02:21.416991: 
2025-05-29 15:02:21.417395: Epoch 149
2025-05-29 15:02:21.417518: Current learning rate: 0.00539
2025-05-29 15:02:52.523054: train_loss -1.1491
2025-05-29 15:02:52.523402: val_loss -0.6224
2025-05-29 15:02:52.523563: Pseudo dice [0.8921, 0.7403, 0.4061, 0.6747, 0.2849, 0.9152, 0.596, 0.6192]
2025-05-29 15:02:52.523668: Epoch time: 31.11 s
2025-05-29 15:02:53.775937: Yayy! New best EMA pseudo Dice: 0.618
2025-05-29 15:02:56.204617: 
2025-05-29 15:02:56.205034: Epoch 150
2025-05-29 15:02:56.205130: Current learning rate: 0.00536
2025-05-29 15:03:27.220524: train_loss -1.1434
2025-05-29 15:03:27.220824: val_loss -0.6177
2025-05-29 15:03:27.220934: Pseudo dice [0.8971, 0.7185, 0.432, 0.6636, 0.1432, 0.8849, 0.5966, 0.662]
2025-05-29 15:03:27.221097: Epoch time: 31.02 s
2025-05-29 15:03:27.221148: Yayy! New best EMA pseudo Dice: 0.6186
2025-05-29 15:03:29.824950: 
2025-05-29 15:03:29.825618: Epoch 151
2025-05-29 15:03:29.825874: Current learning rate: 0.00533
2025-05-29 15:04:00.803774: train_loss -1.1523
2025-05-29 15:04:00.804025: val_loss -0.4975
2025-05-29 15:04:00.804157: Yayy! New best EMA pseudo Dice: 0.5099
2025-05-29 14:40:23.710902: 
2025-05-29 14:40:23.711189: Epoch 51
2025-05-29 14:40:23.711282: Current learning rate: 0.00846
2025-05-29 14:41:39.765142: train_loss -0.7524
2025-05-29 14:41:39.765399: val_loss -0.5156
2025-05-29 14:41:39.765524: Pseudo dice [0.888, 0.5844, 0.3696, 0.5254, 0.0, 0.9036, 0.5581, 0.5963]
2025-05-29 14:41:39.765622: Epoch time: 76.06 s
2025-05-29 14:41:39.765690: Yayy! New best EMA pseudo Dice: 0.5142
2025-05-29 14:41:43.053848: 
2025-05-29 14:41:43.054129: Epoch 52
2025-05-29 14:41:43.054365: Current learning rate: 0.00843
2025-05-29 14:42:59.465630: train_loss -0.7174
2025-05-29 14:42:59.465985: val_loss -0.4957
2025-05-29 14:42:59.466143: Pseudo dice [0.8604, 0.5908, 0.2702, 0.5068, 0.0, 0.9168, 0.482, 0.664]
2025-05-29 14:42:59.466224: Epoch time: 76.41 s
2025-05-29 14:42:59.466273: Yayy! New best EMA pseudo Dice: 0.5164
2025-05-29 14:43:01.868273: 
2025-05-29 14:43:01.868500: Epoch 53
2025-05-29 14:43:01.868609: Current learning rate: 0.00839
2025-05-29 14:44:20.338766: train_loss -0.7327
2025-05-29 14:44:20.338974: val_loss -0.5254
2025-05-29 14:44:20.339091: Pseudo dice [0.8688, 0.5854, 0.257, 0.5279, 0.0, 0.9159, 0.5642, 0.6737]
2025-05-29 14:44:20.339185: Epoch time: 78.47 s
2025-05-29 14:44:20.339239: Yayy! New best EMA pseudo Dice: 0.5197
2025-05-29 14:44:23.970484: 
2025-05-29 14:44:23.970744: Epoch 54
2025-05-29 14:44:23.970916: Current learning rate: 0.00836
2025-05-29 14:45:40.865773: train_loss -0.7561
2025-05-29 14:45:40.866022: val_loss -0.4941
2025-05-29 14:45:40.866139: Pseudo dice [0.8481, 0.5506, 0.326, 0.4964, 0.0, 0.9123, 0.5338, 0.6364]
2025-05-29 14:45:40.866224: Epoch time: 76.9 s
2025-05-29 14:45:40.866278: Yayy! New best EMA pseudo Dice: 0.5215
2025-05-29 14:45:43.615809: 
2025-05-29 14:45:43.616152: Epoch 55
2025-05-29 14:45:43.616368: Current learning rate: 0.00833
2025-05-29 14:47:00.892232: train_loss -0.7841
2025-05-29 14:47:00.892523: val_loss -0.5308
2025-05-29 14:47:00.892648: Pseudo dice [0.8873, 0.5736, 0.3808, 0.5238, 0.0, 0.9106, 0.5355, 0.6644]
2025-05-29 14:47:00.892737: Epoch time: 77.28 s
2025-05-29 14:47:00.892892: Yayy! New best EMA pseudo Dice: 0.5253
2025-05-29 14:47:04.477793: 
2025-05-29 14:47:04.478045: Epoch 56
2025-05-29 14:47:04.478217: Current learning rate: 0.0083
2025-05-29 14:48:20.586713: train_loss -0.8613
2025-05-29 14:48:20.586960: val_loss -0.6589
2025-05-29 14:48:20.587083: Pseudo dice [0.8945, 0.6637, 0.3899, 0.6206, 0.0, 0.9172, 0.5348, 0.7013]
2025-05-29 14:48:20.587171: Epoch time: 76.11 s
2025-05-29 14:48:20.587224: Yayy! New best EMA pseudo Dice: 0.5318
2025-05-29 14:48:23.058854: 
2025-05-29 14:48:23.059173: Epoch 57
2025-05-29 14:48:23.059332: Current learning rate: 0.00827
2025-05-29 14:49:38.066181: train_loss -0.824
2025-05-29 14:49:38.066411: val_loss -0.4959
2025-05-29 14:49:38.066574: Pseudo dice [0.8963, 0.5608, 0.3598, 0.4598, 0.0, 0.9006, 0.5161, 0.6895]
2025-05-29 14:49:38.066667: Epoch time: 75.01 s
2025-05-29 14:49:38.066762: Yayy! New best EMA pseudo Dice: 0.5334
2025-05-29 14:49:40.846055: 
2025-05-29 14:49:40.846285: Epoch 58
2025-05-29 14:49:40.846392: Current learning rate: 0.00824
2025-05-29 14:50:53.646233: train_loss -0.7903
2025-05-29 14:50:53.646504: val_loss -0.514
2025-05-29 14:50:53.646622: Pseudo dice [0.9011, 0.5888, 0.3492, 0.5407, 0.0, 0.9305, 0.5529, 0.5669]
2025-05-29 14:50:53.646706: Epoch time: 72.8 s
2025-05-29 14:50:53.646758: Yayy! New best EMA pseudo Dice: 0.5355
2025-05-29 14:50:56.353562: 
2025-05-29 14:50:56.353854: Epoch 59
2025-05-29 14:50:56.353956: Current learning rate: 0.00821
2025-05-29 14:52:08.930532: train_loss -0.7639
2025-05-29 14:52:08.930746: val_loss -0.4867
2025-05-29 14:52:08.930859: Pseudo dice [0.8835, 0.5812, 0.3987, 0.528, 0.0, 0.8985, 0.5243, 0.6126]
2025-05-29 14:52:08.930939: Epoch time: 72.58 s
2025-05-29 14:52:08.930999: Yayy! New best EMA pseudo Dice: 0.5372
2025-05-29 14:52:11.606366: 
2025-05-29 14:52:11.606604: Epoch 60
2025-05-29 14:52:11.606779: Current learning rate: 0.00818
2025-05-29 14:53:24.654077: train_loss -0.7454
2025-05-29 14:53:24.654294: val_loss -0.4477
2025-05-29 14:53:24.654408: Pseudo dice [0.7709, 0.5696, 0.3138, 0.5408, 0.0, 0.8994, 0.3911, 0.5303]
2025-05-29 14:53:24.654511: Epoch time: 73.05 s
2025-05-29 14:53:25.997238: 
2025-05-29 14:53:25.997478: Epoch 61
2025-05-29 14:53:25.997584: Current learning rate: 0.00815
2025-05-29 14:54:38.844869: train_loss -0.6743
2025-05-29 14:54:38.845115: val_loss -0.4306
2025-05-29 14:54:38.845269: Pseudo dice [0.8708, 0.5187, 0.3497, 0.4788, 0.0, 0.9136, 0.4797, 0.5714]
2025-05-29 14:54:38.845359: Epoch time: 72.85 s
2025-05-29 14:54:40.178564: 
2025-05-29 14:54:40.178773: Epoch 62
2025-05-29 14:54:40.178997: Current learning rate: 0.00812
2025-05-29 14:55:52.264384: train_loss -0.8002
2025-05-29 14:55:52.264750: val_loss -0.4354
2025-05-29 14:55:52.264957: Pseudo dice [0.8805, 0.6043, 0.3388, 0.4007, 0.0, 0.9389, 0.5524, 0.6413]
2025-05-29 14:55:52.265041: Epoch time: 72.09 s
2025-05-29 14:55:54.294180: 
2025-05-29 14:55:54.294495: Epoch 63
2025-05-29 14:55:54.294616: Current learning rate: 0.00809
2025-05-29 14:57:07.220337: train_loss -0.8144
2025-05-29 14:57:07.220568: val_loss -0.4902
2025-05-29 14:57:07.220689: Pseudo dice [0.8848, 0.3743, 0.3549, 0.5409, 0.0198, 0.935, 0.5331, 0.6694]
2025-05-29 14:57:07.220776: Epoch time: 72.93 s
2025-05-29 14:57:08.580297: 
2025-05-29 14:57:08.580620: Epoch 64
2025-05-29 14:57:08.580778: Current learning rate: 0.00806
2025-05-29 14:58:22.911171: train_loss -0.7894
2025-05-29 14:58:22.911436: val_loss -0.4491
2025-05-29 14:58:22.911785: Pseudo dice [0.8766, 0.6209, 0.3904, 0.4288, 0.0, 0.9017, 0.5788, 0.576]
2025-05-29 14:58:22.911898: Epoch time: 74.33 s
2025-05-29 14:58:24.274493: 
2025-05-29 14:58:24.274701: Epoch 65
2025-05-29 14:58:24.274865: Current learning rate: 0.00803
2025-05-29 14:59:35.968105: train_loss -0.8068
2025-05-29 14:59:35.968293: val_loss -0.5141
2025-05-29 14:59:35.968406: Pseudo dice [0.8796, 0.6462, 0.3307, 0.5405, 0.004, 0.9046, 0.5675, 0.588]
2025-05-29 14:59:35.968492: Epoch time: 71.69 s
2025-05-29 14:59:35.968546: Yayy! New best EMA pseudo Dice: 0.5378
2025-05-29 14:59:38.838988: 
2025-05-29 14:59:38.839195: Epoch 66
2025-05-29 14:59:38.839293: Current learning rate: 0.008
2025-05-29 15:00:51.160568: train_loss -0.8649
2025-05-29 15:00:51.160767: val_loss -0.5683
2025-05-29 15:00:51.160877: Pseudo dice [0.8712, 0.6476, 0.3859, 0.5598, 0.0144, 0.9066, 0.5133, 0.6754]
2025-05-29 15:00:51.160950: Epoch time: 72.32 s
2025-05-29 15:00:51.161002: Yayy! New best EMA pseudo Dice: 0.5412
2025-05-29 15:00:53.619709: 
2025-05-29 15:00:53.620012: Epoch 67
2025-05-29 15:00:53.620197: Current learning rate: 0.00797
2025-05-29 15:02:05.254910: train_loss -0.8645
2025-05-29 15:02:05.255132: val_loss -0.5561
2025-05-29 15:02:05.255248: Pseudo dice [0.8873, 0.6375, 0.3862, 0.5933, 0.0054, 0.911, 0.5239, 0.5324]
2025-05-29 15:02:05.255341: Epoch time: 71.64 s
2025-05-29 15:02:05.255414: Yayy! New best EMA pseudo Dice: 0.543
2025-05-29 15:02:08.070962: 
2025-05-29 15:02:08.071293: Epoch 68
2025-05-29 15:02:08.071427: Current learning rate: 0.00793
2025-05-29 15:03:20.365088: train_loss -0.8833
2025-05-29 15:03:20.365432: val_loss -0.5545
2025-05-29 15:03:20.365560: Pseudo dice [0.9025, 0.659, 0.2522, 0.5094, 0.0422, 0.9242, 0.5539, 0.6736]
2025-05-29 15:03:20.365676: Epoch time: 72.3 s
2025-05-29 15:03:20.365729: Yayy! New best EMA pseudo Dice: 0.5452
2025-05-29 15:03:23.007894: 
2025-05-29 15:03:23.008135: Epoch 69
2025-05-29 15:03:23.008247: Current learning rate: 0.0079
2025-05-29 15:04:35.018474: train_loss -0.918
2025-05-29 15:04:35.018798: val_loss -0.5781
2025-05-29 15:04:35.018911: Pseudo dice [0.8945, 0.6864, 0.3973, 0.5405, 0.0869, 0.9104, 0.5672, 0.6974]
2025-05-29 15:04:35.019007: Epoch time: 72.01 s
2025-05-29 15:04:35.019060: Yayy! New best EMA pseudo Dice: 0.5504
2025-05-29 15:04:37.549877: 
2025-05-29 15:04:37.550240: Epoch 70
2025-05-29 15:04:37.550372: Current learning rate: 0.00787
2025-05-29 15:05:50.375010: train_loss -0.9203
2025-05-29 15:05:50.375219: val_loss -0.5833
2025-05-29 15:05:50.375340: Pseudo dice
2025-05-29 14:47:05.554764: 
2025-05-29 14:47:05.555115: Epoch 51
2025-05-29 14:47:05.555226: Current learning rate: 0.00846
2025-05-29 14:48:21.996691: train_loss -0.6919
2025-05-29 14:48:21.997030: val_loss -0.5537
2025-05-29 14:48:21.997149: Pseudo dice [0.8558, 0.5666, 0.3418, 0.6425, 0.0, 0.8547, 0.5488, 0.6517]
2025-05-29 14:48:21.997241: Epoch time: 76.44 s
2025-05-29 14:48:21.997305: Yayy! New best EMA pseudo Dice: 0.5323
2025-05-29 14:48:24.679804: 
2025-05-29 14:48:24.680133: Epoch 52
2025-05-29 14:48:24.680235: Current learning rate: 0.00843
2025-05-29 14:49:40.175685: train_loss -0.7255
2025-05-29 14:49:40.175907: val_loss -0.5975
2025-05-29 14:49:40.176023: Pseudo dice [0.8865, 0.6332, 0.3183, 0.6297, 0.0, 0.8885, 0.5787, 0.6625]
2025-05-29 14:49:40.176114: Epoch time: 75.5 s
2025-05-29 14:49:40.176265: Yayy! New best EMA pseudo Dice: 0.5366
2025-05-29 14:49:43.911099: 
2025-05-29 14:49:43.911409: Epoch 53
2025-05-29 14:49:43.911517: Current learning rate: 0.00839
2025-05-29 14:50:58.563758: train_loss -0.7696
2025-05-29 14:50:58.564071: val_loss -0.4968
2025-05-29 14:50:58.564209: Pseudo dice [0.8818, 0.5414, 0.3933, 0.5534, 0.0, 0.8411, 0.5122, 0.6244]
2025-05-29 14:50:58.564300: Epoch time: 74.65 s
2025-05-29 14:50:58.564353: Yayy! New best EMA pseudo Dice: 0.5372
2025-05-29 14:51:01.256954: 
2025-05-29 14:51:01.257175: Epoch 54
2025-05-29 14:51:01.257286: Current learning rate: 0.00836
2025-05-29 14:52:14.953444: train_loss -0.7522
2025-05-29 14:52:14.953691: val_loss -0.5722
2025-05-29 14:52:14.953809: Pseudo dice [0.8853, 0.5054, 0.3324, 0.6474, 0.0, 0.902, 0.5001, 0.699]
2025-05-29 14:52:14.953897: Epoch time: 73.7 s
2025-05-29 14:52:14.953951: Yayy! New best EMA pseudo Dice: 0.5394
2025-05-29 14:52:17.778797: 
2025-05-29 14:52:17.779067: Epoch 55
2025-05-29 14:52:17.779325: Current learning rate: 0.00833
2025-05-29 14:53:34.136906: train_loss -0.7252
2025-05-29 14:53:34.137153: val_loss -0.5653
2025-05-29 14:53:34.137268: Pseudo dice [0.8906, 0.5629, 0.3905, 0.5992, 0.0, 0.8919, 0.5241, 0.678]
2025-05-29 14:53:34.137354: Epoch time: 76.36 s
2025-05-29 14:53:34.137406: Yayy! New best EMA pseudo Dice: 0.5422
2025-05-29 14:53:37.013329: 
2025-05-29 14:53:37.013772: Epoch 56
2025-05-29 14:53:37.013906: Current learning rate: 0.0083
2025-05-29 14:54:54.408882: train_loss -0.7787
2025-05-29 14:54:54.409111: val_loss -0.5452
2025-05-29 14:54:54.409231: Pseudo dice [0.8973, 0.552, 0.3616, 0.6204, 0.0, 0.8583, 0.5542, 0.661]
2025-05-29 14:54:54.409389: Epoch time: 77.4 s
2025-05-29 14:54:54.409520: Yayy! New best EMA pseudo Dice: 0.5443
2025-05-29 14:54:57.665332: 
2025-05-29 14:54:57.665866: Epoch 57
2025-05-29 14:54:57.666181: Current learning rate: 0.00827
2025-05-29 14:56:13.145516: train_loss -0.7539
2025-05-29 14:56:13.145805: val_loss -0.5219
2025-05-29 14:56:13.145976: Pseudo dice [0.8594, 0.5151, 0.3844, 0.566, 0.0, 0.9013, 0.5344, 0.6153]
2025-05-29 14:56:13.146074: Epoch time: 75.48 s
2025-05-29 14:56:13.146125: Yayy! New best EMA pseudo Dice: 0.5446
2025-05-29 14:56:16.018214: 
2025-05-29 14:56:16.018545: Epoch 58
2025-05-29 14:56:16.018732: Current learning rate: 0.00824
2025-05-29 14:57:32.714329: train_loss -0.6702
2025-05-29 14:57:32.714629: val_loss -0.4602
2025-05-29 14:57:32.714758: Pseudo dice [0.828, 0.522, 0.3462, 0.6251, 0.0, 0.8723, 0.4664, 0.6146]
2025-05-29 14:57:32.714848: Epoch time: 76.7 s
2025-05-29 14:57:34.073538: 
2025-05-29 14:57:34.073870: Epoch 59
2025-05-29 14:57:34.073985: Current learning rate: 0.00821
2025-05-29 14:58:49.988217: train_loss -0.7086
2025-05-29 14:58:49.988461: val_loss -0.5675
2025-05-29 14:58:49.988627: Pseudo dice [0.895, 0.5681, 0.3897, 0.6129, 0.0, 0.8756, 0.5259, 0.7307]
2025-05-29 14:58:49.988784: Epoch time: 75.92 s
2025-05-29 14:58:49.988839: Yayy! New best EMA pseudo Dice: 0.5466
2025-05-29 14:58:52.843574: 
2025-05-29 14:58:52.843948: Epoch 60
2025-05-29 14:58:52.844133: Current learning rate: 0.00818
2025-05-29 15:00:06.107767: train_loss -0.7917
2025-05-29 15:00:06.108236: val_loss -0.5898
2025-05-29 15:00:06.108479: Pseudo dice [0.8858, 0.5897, 0.382, 0.654, 0.0, 0.8958, 0.5643, 0.7045]
2025-05-29 15:00:06.108672: Epoch time: 73.27 s
2025-05-29 15:00:06.108727: Yayy! New best EMA pseudo Dice: 0.5504
2025-05-29 15:00:08.774570: 
2025-05-29 15:00:08.774864: Epoch 61
2025-05-29 15:00:08.774976: Current learning rate: 0.00815
2025-05-29 15:01:23.737781: train_loss -0.7887
2025-05-29 15:01:23.738004: val_loss -0.5523
2025-05-29 15:01:23.738122: Pseudo dice [0.8938, 0.5882, 0.3911, 0.6455, 0.0, 0.8652, 0.5572, 0.6174]
2025-05-29 15:01:23.738206: Epoch time: 74.96 s
2025-05-29 15:01:23.738261: Yayy! New best EMA pseudo Dice: 0.5524
2025-05-29 15:01:26.474644: 
2025-05-29 15:01:26.475011: Epoch 62
2025-05-29 15:01:26.475149: Current learning rate: 0.00812
2025-05-29 15:02:40.207156: train_loss -0.8237
2025-05-29 15:02:40.207399: val_loss -0.6316
2025-05-29 15:02:40.207532: Pseudo dice [0.9, 0.621, 0.4106, 0.6885, 0.0, 0.9085, 0.5335, 0.6187]
2025-05-29 15:02:40.207628: Epoch time: 73.73 s
2025-05-29 15:02:40.207874: Yayy! New best EMA pseudo Dice: 0.5556
2025-05-29 15:02:42.953232: 
2025-05-29 15:02:42.953581: Epoch 63
2025-05-29 15:02:42.953789: Current learning rate: 0.00809
2025-05-29 15:03:57.040316: train_loss -0.7959
2025-05-29 15:03:57.040836: val_loss -0.5899
2025-05-29 15:03:57.040978: Pseudo dice [0.8789, 0.5764, 0.431, 0.6117, 0.0, 0.8982, 0.5335, 0.695]
2025-05-29 15:03:57.041074: Epoch time: 74.09 s
2025-05-29 15:03:57.041133: Yayy! New best EMA pseudo Dice: 0.5579
2025-05-29 15:04:00.184318: 
2025-05-29 15:04:00.184720: Epoch 64
2025-05-29 15:04:00.184828: Current learning rate: 0.00806
2025-05-29 15:05:14.854475: train_loss -0.8016
2025-05-29 15:05:14.854796: val_loss -0.4991
2025-05-29 15:05:14.854930: Pseudo dice [0.9008, 0.5903, 0.3665, 0.6357, 0.0, 0.9028, 0.5762, 0.6481]
2025-05-29 15:05:14.855017: Epoch time: 74.67 s
2025-05-29 15:05:14.855067: Yayy! New best EMA pseudo Dice: 0.5599
2025-05-29 15:05:17.657998: 
2025-05-29 15:05:17.658369: Epoch 65
2025-05-29 15:05:17.658606: Current learning rate: 0.00803
2025-05-29 15:06:31.480165: train_loss -0.8527
2025-05-29 15:06:31.480509: val_loss -0.6702
2025-05-29 15:06:31.480631: Pseudo dice [0.9155, 0.6363, 0.4451, 0.7047, 0.0, 0.9268, 0.5557, 0.7119]
2025-05-29 15:06:31.480743: Epoch time: 73.82 s
2025-05-29 15:06:31.480792: Yayy! New best EMA pseudo Dice: 0.5651
2025-05-29 15:06:34.482404: 
2025-05-29 15:06:34.482799: Epoch 66
2025-05-29 15:06:34.483124: Current learning rate: 0.008
2025-05-29 15:07:48.955067: train_loss -0.8437
2025-05-29 15:07:48.955522: val_loss -0.6083
2025-05-29 15:07:48.955667: Pseudo dice [0.906, 0.6243, 0.4081, 0.5926, 0.0, 0.9047, 0.578, 0.6947]
2025-05-29 15:07:48.955763: Epoch time: 74.47 s
2025-05-29 15:07:48.955848: Yayy! New best EMA pseudo Dice: 0.5674
2025-05-29 15:07:51.809835: 
2025-05-29 15:07:51.810248: Epoch 67
2025-05-29 15:07:51.810389: Current learning rate: 0.00797
2025-05-29 15:09:09.895946: train_loss -0.8609
2025-05-29 15:09:09.896168: val_loss -0.6039
2025-05-29 15:09:09.896281: Pseudo dice [0.9104, 0.6608, 0.3833, 0.6559, 0.0, 0.9109, 0.5276, 0.6971]
2025-05-29 15:09:09.896419: Epoch time: 78.09 s
2025-05-29 15:09:09.896553: Yayy! New best EMA pseudo Dice: 0.57
2025-05-29 15:09:12.568085: 
2025-05-29 15:09:12.568490: Epoch 68
2025-05-29 15:09:12.568619: Current learning rate: 0.00793
2025-05-29 15:10:30.394257: train_loss -0.8433
2025-05-29 15:10:30.394497: val_loss -0.6489
2025-05-29 15:10:30.394613: Pseudo dice [0.914, 0.6232, 0.397, 0.6519, 0.0, 0.8837, 0.6036, 0.7005]
2025-05-29 15:10:30.394697: Epoch time: 77.83 s
2025-05-29 15:10:30.394750: Yayy! New best EMA pseudo Dice: 0.5727
2025-05-29 15:10:34.031963: 
2025-05-29 15:10:34.032355: Epoch 69
2025-05-29 15:10:34.032482: Current learning rate: 0.0079
2025-05-29 15:12:27.674589: train_loss -0.8002
2025-05-29 15:12:27.675041: val_loss -0.5589
2025-05-29 15:12:27.675193: Pseudo dice [0.8768, 0.6209, 0.3729, 0.6198, 0.0, 0.892, 0.5611, 0.7006]
2025-05-29 15:12:27.675272: Epoch time: 113.64 s
2025-05-29 15:12:27.675320: Yayy! New best EMA pseudo Dice: 0.5735
2025-05-29 15:12:30.218717: 
2025-05-29 15:12:30.219025: Pseudo dice [0.8839, 0.6672, 0.401, 0.5626, 0.2541, 0.9107, 0.5343, 0.603]
2025-05-29 15:04:00.804772: Epoch time: 30.98 s
2025-05-29 15:04:02.214638: 
2025-05-29 15:04:02.214994: Epoch 152
2025-05-29 15:04:02.215106: Current learning rate: 0.00529
2025-05-29 15:04:33.355231: train_loss -1.1508
2025-05-29 15:04:33.355556: val_loss -0.6051
2025-05-29 15:04:33.355678: Pseudo dice [0.8966, 0.6807, 0.359, 0.6574, 0.2328, 0.8893, 0.5387, 0.5596]
2025-05-29 15:04:33.355783: Epoch time: 31.14 s
2025-05-29 15:04:34.725492: 
2025-05-29 15:04:34.725683: Epoch 153
2025-05-29 15:04:34.725777: Current learning rate: 0.00526
2025-05-29 15:05:05.854211: train_loss -1.1742
2025-05-29 15:05:05.854547: val_loss -0.617
2025-05-29 15:05:05.854677: Pseudo dice [0.8983, 0.6972, 0.4006, 0.6782, 0.1845, 0.9429, 0.5907, 0.6585]
2025-05-29 15:05:05.854755: Epoch time: 31.13 s
2025-05-29 15:05:07.235404: 
2025-05-29 15:05:07.235798: Epoch 154
2025-05-29 15:05:07.235897: Current learning rate: 0.00523
2025-05-29 15:05:38.312634: train_loss -1.1804
2025-05-29 15:05:38.313327: val_loss -0.6173
2025-05-29 15:05:38.313462: Pseudo dice [0.9005, 0.7353, 0.4238, 0.6602, 0.1541, 0.9197, 0.5875, 0.6241]
2025-05-29 15:05:38.313577: Epoch time: 31.08 s
2025-05-29 15:05:39.763644: 
2025-05-29 15:05:39.764761: Epoch 155
2025-05-29 15:05:39.765404: Current learning rate: 0.0052
2025-05-29 15:06:10.675924: train_loss -1.1853
2025-05-29 15:06:10.676316: val_loss -0.5996
2025-05-29 15:06:10.676429: Pseudo dice [0.8932, 0.6994, 0.3906, 0.6685, 0.1639, 0.8993, 0.5722, 0.5828]
2025-05-29 15:06:10.676550: Epoch time: 30.92 s
2025-05-29 15:06:12.088585: 
2025-05-29 15:06:12.088923: Epoch 156
2025-05-29 15:06:12.089227: Current learning rate: 0.00517
2025-05-29 15:06:42.867356: train_loss -1.153
2025-05-29 15:06:42.867595: val_loss -0.5252
2025-05-29 15:06:42.867717: Pseudo dice [0.8668, 0.6743, 0.4287, 0.6026, 0.154, 0.8867, 0.5833, 0.6136]
2025-05-29 15:06:42.867809: Epoch time: 30.78 s
2025-05-29 15:06:44.250100: 
2025-05-29 15:06:44.250414: Epoch 157
2025-05-29 15:06:44.250561: Current learning rate: 0.00513
2025-05-29 15:07:15.126662: train_loss -1.159
2025-05-29 15:07:15.126871: val_loss -0.6821
2025-05-29 15:07:15.126989: Pseudo dice [0.9128, 0.6906, 0.4635, 0.7205, 0.2875, 0.9073, 0.5571, 0.6584]
2025-05-29 15:07:15.127071: Epoch time: 30.88 s
2025-05-29 15:07:15.127122: Yayy! New best EMA pseudo Dice: 0.6189
2025-05-29 15:07:17.793497: 
2025-05-29 15:07:17.793701: Epoch 158
2025-05-29 15:07:17.793819: Current learning rate: 0.0051
2025-05-29 15:07:48.955428: train_loss -1.1575
2025-05-29 15:07:48.955721: val_loss -0.5201
2025-05-29 15:07:48.955857: Pseudo dice [0.8898, 0.6869, 0.4168, 0.6055, 0.0605, 0.8752, 0.5453, 0.6605]
2025-05-29 15:07:48.956017: Epoch time: 31.16 s
2025-05-29 15:07:51.707538: 
2025-05-29 15:07:51.707964: Epoch 159
2025-05-29 15:07:51.708272: Current learning rate: 0.00507
2025-05-29 15:08:31.069493: train_loss -1.1051
2025-05-29 15:08:31.069844: val_loss -0.7347
2025-05-29 15:08:31.070104: Pseudo dice [0.9109, 0.7474, 0.4777, 0.715, 0.3579, 0.9271, 0.5816, 0.6498]
2025-05-29 15:08:31.070270: Epoch time: 39.36 s
2025-05-29 15:08:31.070386: Yayy! New best EMA pseudo Dice: 0.6217
2025-05-29 15:08:33.677745: 
2025-05-29 15:08:33.678107: Epoch 160
2025-05-29 15:08:33.678219: Current learning rate: 0.00504
2025-05-29 15:09:04.918051: train_loss -1.0562
2025-05-29 15:09:04.918358: val_loss -0.6005
2025-05-29 15:09:04.918492: Pseudo dice [0.9056, 0.7136, 0.3853, 0.6831, 0.1209, 0.9231, 0.514, 0.5673]
2025-05-29 15:09:04.918589: Epoch time: 31.24 s
2025-05-29 15:09:06.295385: 
2025-05-29 15:09:06.295784: Epoch 161
2025-05-29 15:09:06.295881: Current learning rate: 0.005
2025-05-29 15:09:37.249393: train_loss -1.1259
2025-05-29 15:09:37.249856: val_loss -0.6456
2025-05-29 15:09:37.250015: Pseudo dice [0.895, 0.7277, 0.3653, 0.6647, 0.2525, 0.9267, 0.5585, 0.6388]
2025-05-29 15:09:37.250103: Epoch time: 30.96 s
2025-05-29 15:09:38.663376: 
2025-05-29 15:09:38.663680: Epoch 162
2025-05-29 15:09:38.664014: Current learning rate: 0.00497
2025-05-29 15:10:09.748801: train_loss -1.1545
2025-05-29 15:10:09.749130: val_loss -0.6719
2025-05-29 15:10:09.749249: Pseudo dice [0.8975, 0.6753, 0.3776, 0.7422, 0.2733, 0.9026, 0.5551, 0.6263]
2025-05-29 15:10:09.749379: Epoch time: 31.09 s
2025-05-29 15:10:11.165811: 
2025-05-29 15:10:11.166167: Epoch 163
2025-05-29 15:10:11.166265: Current learning rate: 0.00494
2025-05-29 15:11:58.890886: train_loss -1.1638
2025-05-29 15:11:58.891184: val_loss -0.6125
2025-05-29 15:11:58.891319: Pseudo dice [0.9033, 0.7364, 0.4061, 0.6689, 0.3503, 0.8845, 0.5754, 0.6436]
2025-05-29 15:11:58.891478: Epoch time: 107.73 s
2025-05-29 15:11:58.891815: Yayy! New best EMA pseudo Dice: 0.6241
2025-05-29 15:12:01.563926: 
2025-05-29 15:12:01.564095: Epoch 164
2025-05-29 15:12:01.564186: Current learning rate: 0.00491
2025-05-29 15:12:32.496520: train_loss -1.1426
2025-05-29 15:12:32.496902: val_loss -0.7475
2025-05-29 15:12:32.497025: Pseudo dice [0.8915, 0.7269, 0.4211, 0.7797, 0.3177, 0.9267, 0.5529, 0.6471]
2025-05-29 15:12:32.497108: Epoch time: 30.93 s
2025-05-29 15:12:32.497159: Yayy! New best EMA pseudo Dice: 0.6275
2025-05-29 15:12:34.874733: 
2025-05-29 15:12:34.875045: Epoch 165
2025-05-29 15:12:34.875290: Current learning rate: 0.00487
2025-05-29 15:13:05.918835: train_loss -1.1531
2025-05-29 15:13:05.919094: val_loss -0.6904
2025-05-29 15:13:05.919369: Pseudo dice [0.9017, 0.7104, 0.3957, 0.7271, 0.1691, 0.9398, 0.5711, 0.6982]
2025-05-29 15:13:05.919512: Epoch time: 31.05 s
2025-05-29 15:13:05.919622: Yayy! New best EMA pseudo Dice: 0.6286
2025-05-29 15:13:08.901220: 
2025-05-29 15:13:08.901624: Epoch 166
2025-05-29 15:13:08.902110: Current learning rate: 0.00484
2025-05-29 15:13:40.061131: train_loss -1.1027
2025-05-29 15:13:40.061499: val_loss -0.5167
2025-05-29 15:13:40.061613: Pseudo dice [0.8767, 0.6401, 0.4504, 0.5685, 0.1379, 0.8973, 0.5661, 0.6133]
2025-05-29 15:13:40.061694: Epoch time: 31.16 s
2025-05-29 15:13:41.413080: 
2025-05-29 15:13:41.413312: Epoch 167
2025-05-29 15:13:41.413422: Current learning rate: 0.00481
2025-05-29 15:14:12.123552: train_loss -1.132
2025-05-29 15:14:12.123776: val_loss -0.5984
2025-05-29 15:14:12.123892: Pseudo dice [0.9061, 0.7073, 0.4049, 0.6058, 0.2237, 0.9018, 0.5707, 0.6339]
2025-05-29 15:14:12.123974: Epoch time: 30.71 s
2025-05-29 15:14:13.472459: 
2025-05-29 15:14:13.472823: Epoch 168
2025-05-29 15:14:13.472987: Current learning rate: 0.00478
2025-05-29 15:14:44.376207: train_loss -1.1443
2025-05-29 15:14:44.376389: val_loss -0.5873
2025-05-29 15:14:44.376507: Pseudo dice [0.8871, 0.6943, 0.486, 0.6299, 0.281, 0.8963, 0.5631, 0.6466]
2025-05-29 15:14:44.376581: Epoch time: 30.91 s
2025-05-29 15:14:45.754278: 
2025-05-29 15:14:45.754526: Epoch 169
2025-05-29 15:14:45.754669: Current learning rate: 0.00474
2025-05-29 15:15:16.526886: train_loss -1.1482
2025-05-29 15:15:16.527200: val_loss -0.6296
2025-05-29 15:15:16.527377: Pseudo dice [0.9006, 0.6457, 0.4161, 0.6841, 0.1832, 0.9186, 0.54, 0.6301]
2025-05-29 15:15:16.527490: Epoch time: 30.77 s
2025-05-29 15:15:18.653356: 
2025-05-29 15:15:18.653756: Epoch 170
2025-05-29 15:15:18.653860: Current learning rate: 0.00471
2025-05-29 15:15:49.423302: train_loss -1.1712
2025-05-29 15:15:49.423554: val_loss -0.6682
2025-05-29 15:15:49.423685: Pseudo dice [0.8892, 0.6953, 0.3892, 0.7348, 0.1504, 0.9088, 0.575, 0.5811]
2025-05-29 15:15:49.423768: Epoch time: 30.77 s
2025-05-29 15:15:50.766266: 
2025-05-29 15:15:50.766613: Epoch 171
2025-05-29 15:15:50.766797: Current learning rate: 0.00468
2025-05-29 15:16:21.552196: train_loss -1.1757
2025-05-29 15:16:21.552380: val_loss -0.6229
2025-05-29 15:16:21.552634: Pseudo dice [0.8985, 0.7116, 0.4071, 0.6963, 0.0974, 0.8843, 0.5772, 0.6101]
2025-05-29 15:16:21.552741: Epoch time: 30.79 s
2025-05-29 15:16:22.948293: 
2025-05-29 15:16:22.948607: Epoch 172
2025-05-29 15:16:22.948709: Current learning rate: 0.00465
2025-05-29 15:16:53.806591: train_loss -1.1251
2025-05-29 15:16:53.806784: val_loss -0.5522
2025-05-29 15:16:53.807007: Pseudo dice [0.8704, 0.6739, 0.419, 0.6549, 0.1013, 0.8994, 0.5721, 0.6402]
2025-05-29 15:16:53.807165: Epoch time: 90.34 s
2025-05-29 14:52:49.139346: Yayy! New best EMA pseudo Dice: 0.4914
2025-05-29 14:52:52.386665: 
2025-05-29 14:52:52.387033: Epoch 51
2025-05-29 14:52:52.387201: Current learning rate: 0.00846
2025-05-29 14:54:22.919805: train_loss -0.7104
2025-05-29 14:54:22.920169: val_loss -0.5144
2025-05-29 14:54:22.920362: Pseudo dice [0.8769, 0.4954, 0.3494, 0.5717, 0.0, 0.7838, 0.4156, 0.5956]
2025-05-29 14:54:22.920462: Epoch time: 90.53 s
2025-05-29 14:54:22.920514: Yayy! New best EMA pseudo Dice: 0.4934
2025-05-29 14:54:25.696912: 
2025-05-29 14:54:25.697292: Epoch 52
2025-05-29 14:54:25.697566: Current learning rate: 0.00843
2025-05-29 14:55:54.351725: train_loss -0.7913
2025-05-29 14:55:54.351992: val_loss -0.6445
2025-05-29 14:55:54.352150: Pseudo dice [0.884, 0.5099, 0.3464, 0.709, 0.0, 0.8313, 0.5334, 0.7235]
2025-05-29 14:55:54.352247: Epoch time: 88.66 s
2025-05-29 14:55:54.352298: Yayy! New best EMA pseudo Dice: 0.5008
2025-05-29 14:55:57.229714: 
2025-05-29 14:55:57.230138: Epoch 53
2025-05-29 14:55:57.230243: Current learning rate: 0.00839
2025-05-29 14:57:25.925379: train_loss -0.7624
2025-05-29 14:57:25.925701: val_loss -0.5923
2025-05-29 14:57:25.925821: Pseudo dice [0.8841, 0.5342, 0.2423, 0.6608, 0.0, 0.8259, 0.4547, 0.708]
2025-05-29 14:57:25.925931: Epoch time: 88.7 s
2025-05-29 14:57:25.925981: Yayy! New best EMA pseudo Dice: 0.5046
2025-05-29 14:57:28.629840: 
2025-05-29 14:57:28.630225: Epoch 54
2025-05-29 14:57:28.630337: Current learning rate: 0.00836
2025-05-29 14:58:53.607554: train_loss -0.7535
2025-05-29 14:58:53.607770: val_loss -0.5895
2025-05-29 14:58:53.607879: Pseudo dice [0.8643, 0.4708, 0.325, 0.6767, 0.0, 0.7975, 0.4545, 0.7164]
2025-05-29 14:58:53.608044: Epoch time: 84.98 s
2025-05-29 14:58:53.608153: Yayy! New best EMA pseudo Dice: 0.5079
2025-05-29 14:58:55.971976: 
2025-05-29 14:58:55.972195: Epoch 55
2025-05-29 14:58:55.972335: Current learning rate: 0.00833
2025-05-29 15:00:18.609519: train_loss -0.739
2025-05-29 15:00:18.610638: val_loss -0.4629
2025-05-29 15:00:18.610785: Pseudo dice [0.825, 0.4369, 0.3578, 0.6106, 0.0, 0.8397, 0.4468, 0.6878]
2025-05-29 15:00:18.610978: Epoch time: 82.64 s
2025-05-29 15:00:18.611033: Yayy! New best EMA pseudo Dice: 0.5097
2025-05-29 15:00:21.365289: 
2025-05-29 15:00:21.365611: Epoch 56
2025-05-29 15:00:21.365735: Current learning rate: 0.0083
2025-05-29 15:01:43.161355: train_loss -0.7121
2025-05-29 15:01:43.162353: val_loss -0.5732
2025-05-29 15:01:43.162512: Pseudo dice [0.8586, 0.5162, 0.3307, 0.6575, 0.0, 0.8264, 0.4672, 0.6578]
2025-05-29 15:01:43.162692: Epoch time: 81.8 s
2025-05-29 15:01:43.162747: Yayy! New best EMA pseudo Dice: 0.5127
2025-05-29 15:01:45.654343: 
2025-05-29 15:01:45.654679: Epoch 57
2025-05-29 15:01:45.654809: Current learning rate: 0.00827
2025-05-29 15:03:08.996901: train_loss -0.7521
2025-05-29 15:03:08.997198: val_loss -0.5149
2025-05-29 15:03:08.997317: Pseudo dice [0.8657, 0.4928, 0.3177, 0.5722, 0.0, 0.8116, 0.4855, 0.6601]
2025-05-29 15:03:08.997409: Epoch time: 83.34 s
2025-05-29 15:03:08.997523: Yayy! New best EMA pseudo Dice: 0.514
2025-05-29 15:03:11.639154: 
2025-05-29 15:03:11.639367: Epoch 58
2025-05-29 15:03:11.639524: Current learning rate: 0.00824
2025-05-29 15:04:32.295987: train_loss -0.7494
2025-05-29 15:04:32.296342: val_loss -0.5816
2025-05-29 15:04:32.296501: Pseudo dice [0.8754, 0.5435, 0.3503, 0.6661, 0.0, 0.8396, 0.4859, 0.6737]
2025-05-29 15:04:32.296583: Epoch time: 80.66 s
2025-05-29 15:04:32.296633: Yayy! New best EMA pseudo Dice: 0.518
2025-05-29 15:04:35.192379: 
2025-05-29 15:04:35.192777: Epoch 59
2025-05-29 15:04:35.192985: Current learning rate: 0.00821
2025-05-29 15:06:00.010393: train_loss -0.7512
2025-05-29 15:06:00.010728: val_loss -0.5367
2025-05-29 15:06:00.010865: Pseudo dice [0.8647, 0.5191, 0.2987, 0.5996, 0.0, 0.8671, 0.486, 0.6842]
2025-05-29 15:06:00.011049: Epoch time: 84.82 s
2025-05-29 15:06:00.011107: Yayy! New best EMA pseudo Dice: 0.5202
2025-05-29 15:06:02.758160: 
2025-05-29 15:06:02.758347: Epoch 60
2025-05-29 15:06:02.758457: Current learning rate: 0.00818
2025-05-29 15:07:29.718396: train_loss -0.7732
2025-05-29 15:07:29.718739: val_loss -0.496
2025-05-29 15:07:29.718874: Pseudo dice [0.8776, 0.477, 0.3096, 0.5609, 0.0, 0.8303, 0.3706, 0.6457]
2025-05-29 15:07:29.718972: Epoch time: 86.96 s
2025-05-29 15:07:31.097420: 
2025-05-29 15:07:31.097886: Epoch 61
2025-05-29 15:07:31.098025: Current learning rate: 0.00815
2025-05-29 15:08:56.741728: train_loss -0.6875
2025-05-29 15:08:56.741955: val_loss -0.5514
2025-05-29 15:08:56.742071: Pseudo dice [0.8497, 0.4409, 0.3352, 0.6834, 0.0, 0.7774, 0.4002, 0.615]
2025-05-29 15:08:56.742155: Epoch time: 85.65 s
2025-05-29 15:08:58.790953: 
2025-05-29 15:08:58.791103: Epoch 62
2025-05-29 15:08:58.791204: Current learning rate: 0.00812
2025-05-29 15:10:30.106038: train_loss -0.6828
2025-05-29 15:10:30.106401: val_loss -0.656
2025-05-29 15:10:30.106525: Pseudo dice [0.844, 0.524, 0.3675, 0.757, 0.0, 0.8364, 0.4751, 0.6943]
2025-05-29 15:10:30.106618: Epoch time: 91.32 s
2025-05-29 15:10:30.106665: Yayy! New best EMA pseudo Dice: 0.5228
2025-05-29 15:10:33.950984: 
2025-05-29 15:10:33.951239: Epoch 63
2025-05-29 15:10:33.951345: Current learning rate: 0.00809
2025-05-29 15:12:36.952214: train_loss -0.781
2025-05-29 15:12:36.952549: val_loss -0.5793
2025-05-29 15:12:36.952671: Pseudo dice [0.8637, 0.5397, 0.3355, 0.6379, 0.0, 0.828, 0.4688, 0.7115]
2025-05-29 15:12:36.952766: Epoch time: 123.0 s
2025-05-29 15:12:36.952815: Yayy! New best EMA pseudo Dice: 0.5253
2025-05-29 15:12:39.569414: 
2025-05-29 15:12:39.569650: Epoch 64
2025-05-29 15:12:39.569779: Current learning rate: 0.00806
2025-05-29 15:14:02.950156: train_loss -0.7451
2025-05-29 15:14:02.950370: val_loss -0.5219
2025-05-29 15:14:02.950491: Pseudo dice [0.8725, 0.4789, 0.3466, 0.5909, 0.0, 0.8547, 0.4634, 0.6736]
2025-05-29 15:14:02.950575: Epoch time: 83.38 s
2025-05-29 15:14:02.950627: Yayy! New best EMA pseudo Dice: 0.5263
2025-05-29 15:14:05.617172: 
2025-05-29 15:14:05.617407: Epoch 65
2025-05-29 15:14:05.617543: Current learning rate: 0.00803
2025-05-29 15:15:30.079367: train_loss -0.7884
2025-05-29 15:15:30.079612: val_loss -0.4944
2025-05-29 15:15:30.079726: Pseudo dice [0.8817, 0.5136, 0.3623, 0.5229, 0.0, 0.8658, 0.4157, 0.6298]
2025-05-29 15:15:30.079823: Epoch time: 84.46 s
2025-05-29 15:15:31.417688: 
2025-05-29 15:15:31.417900: Epoch 66
2025-05-29 15:15:31.418001: Current learning rate: 0.008
2025-05-29 15:16:55.182390: train_loss -0.7535
2025-05-29 15:16:55.182626: val_loss -0.5597
2025-05-29 15:16:55.182745: Pseudo dice [0.8547, 0.5368, 0.3344, 0.6284, 0.0, 0.7815, 0.4042, 0.6951]
2025-05-29 15:16:55.182878: Epoch time: 83.77 s
2025-05-29 15:16:55.182976: Yayy! New best EMA pseudo Dice: 0.5264
2025-05-29 15:16:57.893030: 
2025-05-29 15:16:57.893326: Epoch 67
2025-05-29 15:16:57.893434: Current learning rate: 0.00797
2025-05-29 15:18:23.056056: train_loss -0.7592
2025-05-29 15:18:23.056351: val_loss -0.6185
2025-05-29 15:18:23.056493: Pseudo dice [0.8994, 0.5628, 0.3558, 0.6634, 0.0, 0.8507, 0.4298, 0.711]
2025-05-29 15:18:23.056599: Epoch time: 85.16 s
2025-05-29 15:18:23.056651: Yayy! New best EMA pseudo Dice: 0.5297
2025-05-29 15:18:25.679011: 
2025-05-29 15:18:25.679278: Epoch 68
2025-05-29 15:18:25.679419: Current learning rate: 0.00793
2025-05-29 15:19:49.865949: train_loss -0.7264
2025-05-29 15:19:49.866170: val_loss -0.5083
2025-05-29 15:19:49.866281: Pseudo dice [0.8359, 0.3319, 0.3261, 0.6574, 0.0, 0.7643, 0.3792, 0.6658]
2025-05-29 15:19:49.866363: Epoch time: 84.19 s
2025-05-29 15:19:51.200372: 
2025-05-29 15:19:51.201887: Epoch 69
2025-05-29 15:19:51.202181: Current learning rate: 0.0079
2025-05-29 15:21:13.137374: train_loss -0.7329
2025-05-29 15:21:13.137596: val_loss -0.5865
2025-05-29 15:21:13.137708: Pseudo dice [0.873, 0.5277, 0.3355, 0.6394, 0.0, 0.8336, 0.4867, 0.7806]
2025-05-29 15:21:13.137788: Epoch time: 81.94 s
2025-05-29 15:21:14.515115: 
2025-05-29 15:21:14.515473: Epoch 70
2025-05-29 15:21:14.515633: Current learning rate: 0.00787
2025-05-29 15:22:40.126887: train_loss -0.7627
2025-05-29 15:22:40.127112: val_loss -0.509
2025-05-29 15:22:40.127227: Epoch time: 30.86 s
2025-05-29 15:16:55.165336: 
2025-05-29 15:16:55.165662: Epoch 173
2025-05-29 15:16:55.165792: Current learning rate: 0.00461
2025-05-29 15:17:26.070220: train_loss -1.1138
2025-05-29 15:17:26.070436: val_loss -0.5979
2025-05-29 15:17:26.070575: Pseudo dice [0.8978, 0.698, 0.4129, 0.6518, 0.2116, 0.9015, 0.527, 0.5982]
2025-05-29 15:17:26.070725: Epoch time: 30.91 s
2025-05-29 15:17:27.403055: 
2025-05-29 15:17:27.403247: Epoch 174
2025-05-29 15:17:27.403340: Current learning rate: 0.00458
2025-05-29 15:17:58.065810: train_loss -1.1364
2025-05-29 15:17:58.066025: val_loss -0.6746
2025-05-29 15:17:58.066137: Pseudo dice [0.9086, 0.7027, 0.3744, 0.7269, 0.1211, 0.9296, 0.5811, 0.67]
2025-05-29 15:17:58.066225: Epoch time: 30.66 s
2025-05-29 15:17:59.415183: 
2025-05-29 15:17:59.415478: Epoch 175
2025-05-29 15:17:59.415581: Current learning rate: 0.00455
2025-05-29 15:18:30.479799: train_loss -1.1714
2025-05-29 15:18:30.480046: val_loss -0.6308
2025-05-29 15:18:30.480188: Pseudo dice [0.912, 0.7311, 0.404, 0.6481, 0.2502, 0.9026, 0.5459, 0.6195]
2025-05-29 15:18:30.480277: Epoch time: 31.07 s
2025-05-29 15:18:31.839574: 
2025-05-29 15:18:31.839931: Epoch 176
2025-05-29 15:18:31.840030: Current learning rate: 0.00452
2025-05-29 15:19:02.651548: train_loss -1.1652
2025-05-29 15:19:02.651757: val_loss -0.6143
2025-05-29 15:19:02.651862: Pseudo dice [0.9015, 0.7108, 0.455, 0.662, 0.0769, 0.9272, 0.5909, 0.6195]
2025-05-29 15:19:02.651938: Epoch time: 30.81 s
2025-05-29 15:19:04.014965: 
2025-05-29 15:19:04.015261: Epoch 177
2025-05-29 15:19:04.015458: Current learning rate: 0.00448
2025-05-29 15:19:34.973891: train_loss -1.1895
2025-05-29 15:19:34.974115: val_loss -0.6487
2025-05-29 15:19:34.974229: Pseudo dice [0.9005, 0.7448, 0.4369, 0.7268, 0.1877, 0.9288, 0.5817, 0.6065]
2025-05-29 15:19:34.974316: Epoch time: 30.96 s
2025-05-29 15:19:36.383056: 
2025-05-29 15:19:36.383276: Epoch 178
2025-05-29 15:19:36.383380: Current learning rate: 0.00445
2025-05-29 15:20:07.489960: train_loss -1.1861
2025-05-29 15:20:07.490201: val_loss -0.6217
2025-05-29 15:20:07.490321: Pseudo dice [0.901, 0.7268, 0.4358, 0.6195, 0.2454, 0.8986, 0.5694, 0.5969]
2025-05-29 15:20:07.490413: Epoch time: 31.11 s
2025-05-29 15:20:08.905057: 
2025-05-29 15:20:08.905213: Epoch 179
2025-05-29 15:20:08.905310: Current learning rate: 0.00442
2025-05-29 15:20:39.682572: train_loss -1.1834
2025-05-29 15:20:39.682883: val_loss -0.6075
2025-05-29 15:20:39.683005: Pseudo dice [0.8922, 0.6688, 0.4359, 0.6782, 0.1363, 0.9286, 0.5538, 0.6303]
2025-05-29 15:20:39.683090: Epoch time: 30.78 s
2025-05-29 15:20:41.022331: 
2025-05-29 15:20:41.022664: Epoch 180
2025-05-29 15:20:41.022795: Current learning rate: 0.00438
2025-05-29 15:21:11.961197: train_loss -1.1947
2025-05-29 15:21:11.961780: val_loss -0.6718
2025-05-29 15:21:11.961893: Pseudo dice [0.9044, 0.7111, 0.4274, 0.7501, 0.1853, 0.9411, 0.5675, 0.6023]
2025-05-29 15:21:11.961976: Epoch time: 30.94 s
2025-05-29 15:21:14.145292: 
2025-05-29 15:21:14.145679: Epoch 181
2025-05-29 15:21:14.145864: Current learning rate: 0.00435
2025-05-29 15:21:44.771745: train_loss -1.1691
2025-05-29 15:21:44.771943: val_loss -0.5987
2025-05-29 15:21:44.772063: Pseudo dice [0.8822, 0.6891, 0.3881, 0.6271, 0.1167, 0.9111, 0.5721, 0.5599]
2025-05-29 15:21:44.772141: Epoch time: 30.63 s
2025-05-29 15:21:46.113625: 
2025-05-29 15:21:46.114042: Epoch 182
2025-05-29 15:21:46.114134: Current learning rate: 0.00432
2025-05-29 15:22:17.067351: train_loss -1.1682
2025-05-29 15:22:17.067611: val_loss -0.5794
2025-05-29 15:22:17.067728: Pseudo dice [0.9098, 0.6989, 0.4305, 0.5948, 0.0765, 0.9188, 0.5805, 0.6699]
2025-05-29 15:22:17.067811: Epoch time: 30.95 s
2025-05-29 15:22:18.460542: 
2025-05-29 15:22:18.460881: Epoch 183
2025-05-29 15:22:18.461051: Current learning rate: 0.00429
2025-05-29 15:22:57.918492: train_loss -1.2139
2025-05-29 15:22:57.918662: val_loss -0.6695
2025-05-29 15:22:57.918764: Pseudo dice [0.9104, 0.705, 0.4691, 0.7229, 0.094, 0.9379, 0.5634, 0.6049]
2025-05-29 15:22:57.918836: Epoch time: 39.46 s
2025-05-29 15:22:59.372572: 
2025-05-29 15:22:59.372939: Epoch 184
2025-05-29 15:22:59.373044: Current learning rate: 0.00425
2025-05-29 15:23:30.091146: train_loss -1.2104
2025-05-29 15:23:30.091488: val_loss -0.5935
2025-05-29 15:23:30.091677: Pseudo dice [0.8788, 0.684, 0.4142, 0.6703, 0.1744, 0.91, 0.5843, 0.62]
2025-05-29 15:23:30.091764: Epoch time: 30.72 s
2025-05-29 15:23:31.448511: 
2025-05-29 15:23:31.448857: Epoch 185
2025-05-29 15:23:31.449012: Current learning rate: 0.00422
2025-05-29 15:24:02.294692: train_loss -1.2005
2025-05-29 15:24:02.294940: val_loss -0.6457
2025-05-29 15:24:02.295051: Pseudo dice [0.9124, 0.7426, 0.4296, 0.6797, 0.2093, 0.9258, 0.5611, 0.6301]
2025-05-29 15:24:02.295144: Epoch time: 30.85 s
2025-05-29 15:24:03.868018: 
2025-05-29 15:24:03.868401: Epoch 186
2025-05-29 15:24:03.868553: Current learning rate: 0.00419
2025-05-29 15:24:34.595530: train_loss -1.1888
2025-05-29 15:24:34.595736: val_loss -0.6563
2025-05-29 15:24:34.595849: Pseudo dice [0.9094, 0.7564, 0.4527, 0.6967, 0.2039, 0.9187, 0.5819, 0.5961]
2025-05-29 15:24:34.595931: Epoch time: 30.73 s
2025-05-29 15:24:35.958834: 
2025-05-29 15:24:35.959147: Epoch 187
2025-05-29 15:24:35.959256: Current learning rate: 0.00415
2025-05-29 15:25:06.850005: train_loss -1.1973
2025-05-29 15:25:06.850231: val_loss -0.5837
2025-05-29 15:25:06.850354: Pseudo dice [0.9033, 0.716, 0.4072, 0.5807, 0.2856, 0.8948, 0.5223, 0.6426]
2025-05-29 15:25:06.850457: Epoch time: 30.89 s
2025-05-29 15:25:08.186577: 
2025-05-29 15:25:08.186943: Epoch 188
2025-05-29 15:25:08.187087: Current learning rate: 0.00412
2025-05-29 15:25:39.059741: train_loss -1.2117
2025-05-29 15:25:39.059939: val_loss -0.6667
2025-05-29 15:25:39.060106: Pseudo dice [0.8964, 0.7123, 0.4308, 0.6658, 0.2066, 0.9274, 0.556, 0.6562]
2025-05-29 15:25:39.060268: Epoch time: 30.87 s
2025-05-29 15:25:40.417368: 
2025-05-29 15:25:40.417649: Epoch 189
2025-05-29 15:25:40.417755: Current learning rate: 0.00409
2025-05-29 15:26:11.406112: train_loss -1.1944
2025-05-29 15:26:11.406359: val_loss -0.6077
2025-05-29 15:26:11.406490: Pseudo dice [0.8892, 0.6951, 0.4261, 0.6943, 0.2423, 0.9099, 0.5568, 0.6356]
2025-05-29 15:26:11.406587: Epoch time: 30.99 s
2025-05-29 15:26:12.754849: 
2025-05-29 15:26:12.755113: Epoch 190
2025-05-29 15:26:12.755253: Current learning rate: 0.00405
2025-05-29 15:26:43.765058: train_loss -1.192
2025-05-29 15:26:43.765767: val_loss -0.6015
2025-05-29 15:26:43.765895: Pseudo dice [0.9099, 0.696, 0.4161, 0.6264, 0.186, 0.9037, 0.5912, 0.6495]
2025-05-29 15:26:43.766082: Epoch time: 31.01 s
2025-05-29 15:26:45.247565: 
2025-05-29 15:26:45.248535: Epoch 191
2025-05-29 15:26:45.248958: Current learning rate: 0.00402
2025-05-29 15:27:16.647973: train_loss -1.2062
2025-05-29 15:27:16.648584: val_loss -0.5258
2025-05-29 15:27:16.648702: Pseudo dice [0.8821, 0.7163, 0.4364, 0.5785, 0.153, 0.9077, 0.6013, 0.6136]
2025-05-29 15:27:16.648791: Epoch time: 31.4 s
2025-05-29 15:27:18.099782: 
2025-05-29 15:27:18.100095: Epoch 192
2025-05-29 15:27:18.100240: Current learning rate: 0.00399
2025-05-29 15:27:49.153287: train_loss -1.2122
2025-05-29 15:27:49.153696: val_loss -0.6893
2025-05-29 15:27:49.153953: Pseudo dice [0.9174, 0.715, 0.4337, 0.7249, 0.2979, 0.9282, 0.5638, 0.6589]
2025-05-29 15:27:49.154074: Epoch time: 31.05 s
2025-05-29 15:27:50.568469: 
2025-05-29 15:27:50.568754: Epoch 193
2025-05-29 15:27:50.568851: Current learning rate: 0.00395
2025-05-29 15:28:21.361650: train_loss -1.2075
2025-05-29 15:28:21.361924: val_loss -0.6387
2025-05-29 15:28:21.362045: Pseudo dice [0.8998, 0.7357, 0.4104, 0.7125, 0.0983, 0.9303, 0.5399, 0.6431]
2025-05-29 15:28:21.362130: Epoch time: 30.79 s
2025-05-29 15:28:22.777444: 
2025-05-29 15:28:22.777699: Epoch 194
2025-05-29 15:28:22.777810: Current learning rate: 0.00392
2025-05-29 15:28:53.743203: train_loss -1.1723
2025-05-29 15:28:53.743610: val_loss -0.4858
2025-05-29 15:28:53.743810: Pseudo dice [0.865, 0.6915, 0.4145, 0.5273, 0.1442, 0.8856, 0.5523, 0.565]
2025-05-29 15:28:53.743932: Epoch time: 30.97 s
2025-05-29 15:28:55.172104: 
2025-05-29 15:28:55.172402: [0.9064, 0.6404, 0.4185, 0.602, 0.1134, 0.914, 0.5352, 0.7012]
2025-05-29 15:05:50.375839: Epoch time: 72.83 s
2025-05-29 15:05:50.375906: Yayy! New best EMA pseudo Dice: 0.5558
2025-05-29 15:05:53.085579: 
2025-05-29 15:05:53.085742: Epoch 71
2025-05-29 15:05:53.085837: Current learning rate: 0.00784
2025-05-29 15:07:05.130770: train_loss -0.937
2025-05-29 15:07:05.130987: val_loss -0.5992
2025-05-29 15:07:05.131100: Pseudo dice [0.8964, 0.6329, 0.4189, 0.6326, 0.074, 0.9396, 0.4803, 0.7124]
2025-05-29 15:07:05.131184: Epoch time: 72.05 s
2025-05-29 15:07:05.131331: Yayy! New best EMA pseudo Dice: 0.56
2025-05-29 15:07:07.883457: 
2025-05-29 15:07:07.883741: Epoch 72
2025-05-29 15:07:07.883859: Current learning rate: 0.00781
2025-05-29 15:08:24.405337: train_loss -0.9115
2025-05-29 15:08:24.405541: val_loss -0.6756
2025-05-29 15:08:24.405696: Pseudo dice [0.9069, 0.6594, 0.3997, 0.6587, 0.1942, 0.9317, 0.5756, 0.6864]
2025-05-29 15:08:24.405787: Epoch time: 76.52 s
2025-05-29 15:08:24.405840: Yayy! New best EMA pseudo Dice: 0.5667
2025-05-29 15:08:27.039637: 
2025-05-29 15:08:27.039939: Epoch 73
2025-05-29 15:08:27.040087: Current learning rate: 0.00778
2025-05-29 15:09:40.555997: train_loss -0.8894
2025-05-29 15:09:40.556189: val_loss -0.6052
2025-05-29 15:09:40.556305: Pseudo dice [0.8922, 0.6761, 0.3979, 0.6045, 0.1034, 0.9212, 0.485, 0.6573]
2025-05-29 15:09:40.556458: Epoch time: 73.52 s
2025-05-29 15:09:40.556553: Yayy! New best EMA pseudo Dice: 0.5692
2025-05-29 15:09:43.179166: 
2025-05-29 15:09:43.179525: Epoch 74
2025-05-29 15:09:43.179689: Current learning rate: 0.00775
2025-05-29 15:11:27.202885: train_loss -0.9366
2025-05-29 15:11:27.203115: val_loss -0.5728
2025-05-29 15:11:27.203237: Pseudo dice [0.901, 0.6446, 0.3866, 0.5441, 0.2435, 0.9145, 0.5224, 0.6837]
2025-05-29 15:11:27.203320: Epoch time: 104.02 s
2025-05-29 15:11:27.203373: Yayy! New best EMA pseudo Dice: 0.5728
2025-05-29 15:11:29.505847: 
2025-05-29 15:11:29.506137: Epoch 75
2025-05-29 15:11:29.506283: Current learning rate: 0.00772
2025-05-29 15:12:52.673464: train_loss -0.9559
2025-05-29 15:12:52.674053: val_loss -0.5809
2025-05-29 15:12:52.674176: Pseudo dice [0.9065, 0.6572, 0.4537, 0.5455, 0.0146, 0.9068, 0.5058, 0.7219]
2025-05-29 15:12:52.674299: Epoch time: 83.17 s
2025-05-29 15:12:52.674403: Yayy! New best EMA pseudo Dice: 0.5744
2025-05-29 15:12:55.352197: 
2025-05-29 15:12:55.352612: Epoch 76
2025-05-29 15:12:55.352720: Current learning rate: 0.00769
2025-05-29 15:14:08.226048: train_loss -0.9136
2025-05-29 15:14:08.226581: val_loss -0.6246
2025-05-29 15:14:08.226700: Pseudo dice [0.8937, 0.665, 0.3982, 0.5732, 0.2171, 0.8854, 0.5874, 0.7472]
2025-05-29 15:14:08.226800: Epoch time: 72.88 s
2025-05-29 15:14:08.226881: Yayy! New best EMA pseudo Dice: 0.5791
2025-05-29 15:14:10.997304: 
2025-05-29 15:14:10.997642: Epoch 77
2025-05-29 15:14:10.997743: Current learning rate: 0.00766
2025-05-29 15:15:23.479681: train_loss -0.9433
2025-05-29 15:15:23.479900: val_loss -0.6341
2025-05-29 15:15:23.480011: Pseudo dice [0.9039, 0.6778, 0.4068, 0.6076, 0.1453, 0.9425, 0.5778, 0.7093]
2025-05-29 15:15:23.480094: Epoch time: 72.48 s
2025-05-29 15:15:23.480147: Yayy! New best EMA pseudo Dice: 0.5833
2025-05-29 15:15:26.160944: 
2025-05-29 15:15:26.161165: Epoch 78
2025-05-29 15:15:26.161259: Current learning rate: 0.00763
2025-05-29 15:16:38.604868: train_loss -0.9186
2025-05-29 15:16:38.605093: val_loss -0.6297
2025-05-29 15:16:38.605206: Pseudo dice [0.8941, 0.6862, 0.4347, 0.5792, 0.1491, 0.9217, 0.5119, 0.7495]
2025-05-29 15:16:38.605286: Epoch time: 72.45 s
2025-05-29 15:16:38.605343: Yayy! New best EMA pseudo Dice: 0.5866
2025-05-29 15:16:41.245804: 
2025-05-29 15:16:41.246147: Epoch 79
2025-05-29 15:16:41.246336: Current learning rate: 0.0076
2025-05-29 15:17:54.241656: train_loss -0.8705
2025-05-29 15:17:54.241961: val_loss -0.5905
2025-05-29 15:17:54.242079: Pseudo dice [0.8892, 0.6759, 0.4372, 0.553, 0.07, 0.8987, 0.5618, 0.6451]
2025-05-29 15:17:54.242162: Epoch time: 73.0 s
2025-05-29 15:17:54.242218: Yayy! New best EMA pseudo Dice: 0.587
2025-05-29 15:17:56.804296: 
2025-05-29 15:17:56.804592: Epoch 80
2025-05-29 15:17:56.804690: Current learning rate: 0.00756
2025-05-29 15:19:09.784560: train_loss -0.9093
2025-05-29 15:19:09.784846: val_loss -0.5662
2025-05-29 15:19:09.784964: Pseudo dice [0.8782, 0.6567, 0.3459, 0.5382, 0.0554, 0.9134, 0.5987, 0.6566]
2025-05-29 15:19:09.785042: Epoch time: 72.98 s
2025-05-29 15:19:11.196543: 
2025-05-29 15:19:11.197015: Epoch 81
2025-05-29 15:19:11.197119: Current learning rate: 0.00753
2025-05-29 15:20:26.305037: train_loss -0.9517
2025-05-29 15:20:26.305266: val_loss -0.6429
2025-05-29 15:20:26.305381: Pseudo dice [0.9061, 0.6725, 0.3809, 0.6022, 0.2404, 0.928, 0.5258, 0.7444]
2025-05-29 15:20:26.305484: Epoch time: 75.11 s
2025-05-29 15:20:26.305552: Yayy! New best EMA pseudo Dice: 0.5902
2025-05-29 15:20:28.983012: 
2025-05-29 15:20:28.983437: Epoch 82
2025-05-29 15:20:28.983634: Current learning rate: 0.0075
2025-05-29 15:21:41.604139: train_loss -0.972
2025-05-29 15:21:41.604405: val_loss -0.6269
2025-05-29 15:21:41.604615: Pseudo dice [0.8998, 0.652, 0.3301, 0.6104, 0.0143, 0.9198, 0.6098, 0.7488]
2025-05-29 15:21:41.604718: Epoch time: 72.62 s
2025-05-29 15:21:41.604775: Yayy! New best EMA pseudo Dice: 0.591
2025-05-29 15:21:44.183656: 
2025-05-29 15:21:44.183902: Epoch 83
2025-05-29 15:21:44.184032: Current learning rate: 0.00747
2025-05-29 15:23:03.514498: train_loss -0.9275
2025-05-29 15:23:03.514742: val_loss -0.5881
2025-05-29 15:23:03.514853: Pseudo dice [0.9083, 0.6482, 0.3358, 0.575, 0.2338, 0.9034, 0.568, 0.7334]
2025-05-29 15:23:03.514939: Epoch time: 79.33 s
2025-05-29 15:23:03.514994: Yayy! New best EMA pseudo Dice: 0.5933
2025-05-29 15:23:06.582558: 
2025-05-29 15:23:06.582894: Epoch 84
2025-05-29 15:23:06.583049: Current learning rate: 0.00744
2025-05-29 15:24:20.961123: train_loss -0.936
2025-05-29 15:24:20.961339: val_loss -0.6208
2025-05-29 15:24:20.961470: Pseudo dice [0.9077, 0.6636, 0.3745, 0.6323, 0.1471, 0.8962, 0.5576, 0.6852]
2025-05-29 15:24:20.961567: Epoch time: 74.38 s
2025-05-29 15:24:20.961622: Yayy! New best EMA pseudo Dice: 0.5947
2025-05-29 15:24:23.588253: 
2025-05-29 15:24:23.588606: Epoch 85
2025-05-29 15:24:23.588714: Current learning rate: 0.00741
2025-05-29 15:25:37.843520: train_loss -1.0059
2025-05-29 15:25:37.843722: val_loss -0.6412
2025-05-29 15:25:37.843832: Pseudo dice [0.9039, 0.6715, 0.3565, 0.6211, 0.3824, 0.9258, 0.4754, 0.7286]
2025-05-29 15:25:37.844046: Epoch time: 74.26 s
2025-05-29 15:25:37.844118: Yayy! New best EMA pseudo Dice: 0.5986
2025-05-29 15:25:40.437581: 
2025-05-29 15:25:40.437939: Epoch 86
2025-05-29 15:25:40.438165: Current learning rate: 0.00738
2025-05-29 15:26:55.365954: train_loss -0.9949
2025-05-29 15:26:55.366165: val_loss -0.6518
2025-05-29 15:26:55.366278: Pseudo dice [0.9097, 0.7027, 0.4096, 0.6701, 0.1935, 0.9188, 0.4795, 0.6101]
2025-05-29 15:26:55.366359: Epoch time: 74.93 s
2025-05-29 15:26:55.366416: Yayy! New best EMA pseudo Dice: 0.5999
2025-05-29 15:26:58.366210: 
2025-05-29 15:26:58.366570: Epoch 87
2025-05-29 15:26:58.366715: Current learning rate: 0.00735
2025-05-29 15:28:11.939238: train_loss -0.9961
2025-05-29 15:28:11.939544: val_loss -0.5584
2025-05-29 15:28:11.939665: Pseudo dice [0.9032, 0.6576, 0.3736, 0.5413, 0.0425, 0.9106, 0.478, 0.6043]
2025-05-29 15:28:11.939749: Epoch time: 73.57 s
2025-05-29 15:28:13.283640: 
2025-05-29 15:28:13.283819: Epoch 88
2025-05-29 15:28:13.284023: Current learning rate: 0.00732
2025-05-29 15:29:28.907198: train_loss -0.9674
2025-05-29 15:29:28.907465: val_loss -0.5309
2025-05-29 15:29:28.907591: Pseudo dice [0.8883, 0.6782, 0.3868, 0.5225, 0.155, 0.902, 0.5215, 0.7024]
2025-05-29 15:29:28.907725: Epoch time: 75.62 s
2025-05-29 15:29:30.247674: 
2025-05-29 15:29:30.247941: Epoch 89
2025-05-29 15:29:30.248092: Current learning rate: 0.00729
2025-05-29 15:30:43.664406: train_loss -0.8971
2025-05-29 15:30:43.664641: val_loss -0.5518
2025-05-29 15:30:43.664805: Pseudo dice [0.8902, 0.6408, 0.393, 0.5548, 0.2963, 0.9114, 0.5639, 0.7161]
2025-05-29 15:30:43.664894: Epoch time: 73.42 s
2025-05-29 15:30:44.998260: Epoch 70
2025-05-29 15:12:30.219474: Current learning rate: 0.00787
2025-05-29 15:13:44.639551: train_loss -0.8635
2025-05-29 15:13:44.639794: val_loss -0.7044
2025-05-29 15:13:44.639908: Pseudo dice [0.905, 0.631, 0.4133, 0.7181, 0.0, 0.8953, 0.5789, 0.7384]
2025-05-29 15:13:44.639991: Epoch time: 74.42 s
2025-05-29 15:13:44.640115: Yayy! New best EMA pseudo Dice: 0.5771
2025-05-29 15:13:47.430366: 
2025-05-29 15:13:47.430769: Epoch 71
2025-05-29 15:13:47.430870: Current learning rate: 0.00784
2025-05-29 15:15:02.001258: train_loss -0.8925
2025-05-29 15:15:02.001522: val_loss -0.5789
2025-05-29 15:15:02.001646: Pseudo dice [0.8986, 0.6607, 0.3881, 0.6034, 0.0, 0.9101, 0.5815, 0.6744]
2025-05-29 15:15:02.001739: Epoch time: 74.57 s
2025-05-29 15:15:02.001801: Yayy! New best EMA pseudo Dice: 0.5784
2025-05-29 15:15:05.480206: 
2025-05-29 15:15:05.480539: Epoch 72
2025-05-29 15:15:05.480707: Current learning rate: 0.00781
2025-05-29 15:16:19.642989: train_loss -0.8859
2025-05-29 15:16:19.643420: val_loss -0.6162
2025-05-29 15:16:19.643603: Pseudo dice [0.9142, 0.6561, 0.3687, 0.6093, 0.0, 0.9066, 0.5959, 0.7473]
2025-05-29 15:16:19.643703: Epoch time: 74.16 s
2025-05-29 15:16:19.643752: Yayy! New best EMA pseudo Dice: 0.5805
2025-05-29 15:16:22.435017: 
2025-05-29 15:16:22.435404: Epoch 73
2025-05-29 15:16:22.435535: Current learning rate: 0.00778
2025-05-29 15:17:37.047583: train_loss -0.8818
2025-05-29 15:17:37.048028: val_loss -0.622
2025-05-29 15:17:37.048161: Pseudo dice [0.9124, 0.615, 0.4047, 0.6733, 0.0, 0.9042, 0.5274, 0.6528]
2025-05-29 15:17:37.048249: Epoch time: 74.61 s
2025-05-29 15:17:37.048299: Yayy! New best EMA pseudo Dice: 0.5811
2025-05-29 15:17:39.661396: 
2025-05-29 15:17:39.661739: Epoch 74
2025-05-29 15:17:39.661856: Current learning rate: 0.00775
2025-05-29 15:18:54.275134: train_loss -0.8921
2025-05-29 15:18:54.275437: val_loss -0.6848
2025-05-29 15:18:54.275568: Pseudo dice [0.8962, 0.6361, 0.4021, 0.7295, 0.0, 0.8897, 0.5351, 0.7071]
2025-05-29 15:18:54.275659: Epoch time: 74.62 s
2025-05-29 15:18:54.275722: Yayy! New best EMA pseudo Dice: 0.5829
2025-05-29 15:18:57.058810: 
2025-05-29 15:18:57.059033: Epoch 75
2025-05-29 15:18:57.059150: Current learning rate: 0.00772
2025-05-29 15:20:13.706146: train_loss -0.8484
2025-05-29 15:20:13.706395: val_loss -0.599
2025-05-29 15:20:13.706525: Pseudo dice [0.9131, 0.537, 0.3777, 0.618, 0.0, 0.8941, 0.5644, 0.6976]
2025-05-29 15:20:13.706609: Epoch time: 76.65 s
2025-05-29 15:20:15.049676: 
2025-05-29 15:20:15.049946: Epoch 76
2025-05-29 15:20:15.050046: Current learning rate: 0.00769
2025-05-29 15:21:28.932047: train_loss -0.8366
2025-05-29 15:21:28.932287: val_loss -0.7027
2025-05-29 15:21:28.932503: Pseudo dice [0.9096, 0.6297, 0.4358, 0.7105, 0.0, 0.901, 0.5927, 0.7023]
2025-05-29 15:21:28.932610: Epoch time: 73.88 s
2025-05-29 15:21:28.932660: Yayy! New best EMA pseudo Dice: 0.585
2025-05-29 15:21:31.461952: 
2025-05-29 15:21:31.462250: Epoch 77
2025-05-29 15:21:31.462355: Current learning rate: 0.00766
2025-05-29 15:22:47.345613: train_loss -0.8698
2025-05-29 15:22:47.345836: val_loss -0.5156
2025-05-29 15:22:47.345949: Pseudo dice [0.8541, 0.5758, 0.3936, 0.61, 0.0, 0.8946, 0.5303, 0.5067]
2025-05-29 15:22:47.346035: Epoch time: 75.88 s
2025-05-29 15:22:48.684995: 
2025-05-29 15:22:48.685152: Epoch 78
2025-05-29 15:22:48.685261: Current learning rate: 0.00763
2025-05-29 15:24:04.886585: train_loss -0.892
2025-05-29 15:24:04.886925: val_loss -0.6417
2025-05-29 15:24:04.887040: Pseudo dice [0.903, 0.6504, 0.4075, 0.6533, 0.0, 0.8934, 0.5324, 0.6221]
2025-05-29 15:24:04.887136: Epoch time: 76.2 s
2025-05-29 15:24:06.244427: 
2025-05-29 15:24:06.244718: Epoch 79
2025-05-29 15:24:06.244819: Current learning rate: 0.0076
2025-05-29 15:25:19.874804: train_loss -0.8942
2025-05-29 15:25:19.875126: val_loss -0.618
2025-05-29 15:25:19.875247: Pseudo dice [0.8905, 0.6105, 0.3532, 0.6312, 0.0, 0.912, 0.5446, 0.6963]
2025-05-29 15:25:19.875350: Epoch time: 73.63 s
2025-05-29 15:25:21.733649: 
2025-05-29 15:25:21.734015: Epoch 80
2025-05-29 15:25:21.734153: Current learning rate: 0.00756
2025-05-29 15:26:36.099423: train_loss -0.8013
2025-05-29 15:26:36.099710: val_loss -0.6679
2025-05-29 15:26:36.099851: Pseudo dice [0.9132, 0.5887, 0.3884, 0.6819, 0.0, 0.9203, 0.5517, 0.7096]
2025-05-29 15:26:36.099944: Epoch time: 74.37 s
2025-05-29 15:26:37.510679: 
2025-05-29 15:26:37.510918: Epoch 81
2025-05-29 15:26:37.511062: Current learning rate: 0.00753
2025-05-29 15:27:50.842813: train_loss -0.8429
2025-05-29 15:27:50.843038: val_loss -0.5791
2025-05-29 15:27:50.843156: Pseudo dice [0.9199, 0.6239, 0.4172, 0.5804, 0.0, 0.8496, 0.61, 0.6618]
2025-05-29 15:27:50.843247: Epoch time: 73.33 s
2025-05-29 15:27:52.895565: 
2025-05-29 15:27:52.895825: Epoch 82
2025-05-29 15:27:52.896046: Current learning rate: 0.0075
2025-05-29 15:29:09.231487: train_loss -0.928
2025-05-29 15:29:09.231705: val_loss -0.6626
2025-05-29 15:29:09.231820: Pseudo dice [0.9104, 0.6586, 0.4173, 0.6799, 0.0, 0.9031, 0.5741, 0.717]
2025-05-29 15:29:09.231909: Epoch time: 76.34 s
2025-05-29 15:29:10.668567: 
2025-05-29 15:29:10.668991: Epoch 83
2025-05-29 15:29:10.669140: Current learning rate: 0.00747
2025-05-29 15:30:27.438620: train_loss -0.9376
2025-05-29 15:30:27.439002: val_loss -0.7039
2025-05-29 15:30:27.439175: Pseudo dice [0.9168, 0.6857, 0.4012, 0.7294, 0.0, 0.9046, 0.6281, 0.694]
2025-05-29 15:30:27.439254: Epoch time: 76.77 s
2025-05-29 15:30:27.439304: Yayy! New best EMA pseudo Dice: 0.5884
2025-05-29 15:30:29.953053: 
2025-05-29 15:30:29.953429: Epoch 84
2025-05-29 15:30:29.953570: Current learning rate: 0.00744
2025-05-29 15:31:46.531546: train_loss -0.9499
2025-05-29 15:31:46.531751: val_loss -0.7086
2025-05-29 15:31:46.532019: Pseudo dice [0.9184, 0.6655, 0.3615, 0.7332, 0.0, 0.9024, 0.5965, 0.6492]
2025-05-29 15:31:46.532111: Epoch time: 76.58 s
2025-05-29 15:31:46.532158: Yayy! New best EMA pseudo Dice: 0.5899
2025-05-29 15:31:49.158037: 
2025-05-29 15:31:49.158436: Epoch 85
2025-05-29 15:31:49.158556: Current learning rate: 0.00741
2025-05-29 15:33:03.541089: train_loss -0.9136
2025-05-29 15:33:03.541873: val_loss -0.6194
2025-05-29 15:33:03.542070: Pseudo dice [0.9088, 0.6597, 0.4214, 0.6776, 0.0, 0.9092, 0.5558, 0.6342]
2025-05-29 15:33:03.542179: Epoch time: 74.38 s
2025-05-29 15:33:03.542229: Yayy! New best EMA pseudo Dice: 0.5905
2025-05-29 15:33:06.357304: 
2025-05-29 15:33:06.357784: Epoch 86
2025-05-29 15:33:06.357899: Current learning rate: 0.00738
2025-05-29 15:34:20.931131: train_loss -0.9759
2025-05-29 15:34:20.931553: val_loss -0.672
2025-05-29 15:34:20.931698: Pseudo dice [0.9174, 0.6398, 0.4266, 0.7029, 0.0, 0.9048, 0.6088, 0.5514]
2025-05-29 15:34:20.931812: Epoch time: 74.58 s
2025-05-29 15:34:20.931961: Yayy! New best EMA pseudo Dice: 0.5909
2025-05-29 15:34:23.298245: 
2025-05-29 15:34:23.298691: Epoch 87
2025-05-29 15:34:23.298804: Current learning rate: 0.00735
2025-05-29 15:35:37.825677: train_loss -0.9353
2025-05-29 15:35:37.826442: val_loss -0.6775
2025-05-29 15:35:37.826571: Pseudo dice [0.9268, 0.6276, 0.4382, 0.6493, 0.0, 0.8937, 0.5868, 0.7116]
2025-05-29 15:35:37.826653: Epoch time: 74.53 s
2025-05-29 15:35:37.826701: Yayy! New best EMA pseudo Dice: 0.5922
2025-05-29 15:35:40.529832: 
2025-05-29 15:35:40.530177: Epoch 88
2025-05-29 15:35:40.530280: Current learning rate: 0.00732
2025-05-29 15:36:55.224873: train_loss -0.9515
2025-05-29 15:36:55.225252: val_loss -0.6576
2025-05-29 15:36:55.225373: Pseudo dice [0.9124, 0.5959, 0.4293, 0.7099, 0.0, 0.9239, 0.5638, 0.7189]
2025-05-29 15:36:55.225472: Epoch time: 74.7 s
2025-05-29 15:36:55.225535: Yayy! New best EMA pseudo Dice: 0.5937
2025-05-29 15:36:58.288193: 
2025-05-29 15:36:58.288445: Epoch 89
2025-05-29 15:36:58.288588: Current learning rate: 0.00729
2025-05-29 15:38:16.296225: train_loss -0.9785
2025-05-29 15:38:16.296462: val_loss -0.6493
2025-05-29 15:38:16.296585: Pseudo dice [0.9255, 0.6864, 0.4203, 0.6819, 0.0, 0.9111, 0.5772, 0.7968]
2025-05-29 15:38:16.296670: Epoch time: 78.01 s
2025-05-29 15:38:16.296722: Yayy! New best EMA pseudo Dice: 0.5968
2025-05-29 15:38:18.890174: 
2025-05-29 15:38:18.890499: Epoch 90 Epoch 195
2025-05-29 15:28:55.172884: Current learning rate: 0.00389
2025-05-29 15:29:26.176220: train_loss -1.1774
2025-05-29 15:29:26.176520: val_loss -0.6129
2025-05-29 15:29:26.176709: Pseudo dice [0.8985, 0.7194, 0.4355, 0.7065, 0.1638, 0.91, 0.5212, 0.6328]
2025-05-29 15:29:26.176828: Epoch time: 31.01 s
2025-05-29 15:29:27.559867: 
2025-05-29 15:29:27.560170: Epoch 196
2025-05-29 15:29:27.560297: Current learning rate: 0.00385
2025-05-29 15:29:58.474182: train_loss -1.213
2025-05-29 15:29:58.474533: val_loss -0.6258
2025-05-29 15:29:58.474644: Pseudo dice [0.8979, 0.7342, 0.3974, 0.7271, 0.1978, 0.9452, 0.5213, 0.5834]
2025-05-29 15:29:58.474719: Epoch time: 30.92 s
2025-05-29 15:29:59.825679: 
2025-05-29 15:29:59.825924: Epoch 197
2025-05-29 15:29:59.826070: Current learning rate: 0.00382
2025-05-29 15:30:30.738070: train_loss -1.2244
2025-05-29 15:30:30.738304: val_loss -0.639
2025-05-29 15:30:30.738421: Pseudo dice [0.9021, 0.7214, 0.4268, 0.6501, 0.1967, 0.9234, 0.5771, 0.6172]
2025-05-29 15:30:30.738508: Epoch time: 30.91 s
2025-05-29 15:30:32.084114: 
2025-05-29 15:30:32.084489: Epoch 198
2025-05-29 15:30:32.084590: Current learning rate: 0.00379
2025-05-29 15:31:03.020171: train_loss -1.2337
2025-05-29 15:31:03.020382: val_loss -0.6418
2025-05-29 15:31:03.020516: Pseudo dice [0.9075, 0.7318, 0.4129, 0.6897, 0.2676, 0.9155, 0.566, 0.6545]
2025-05-29 15:31:03.020604: Epoch time: 30.94 s
2025-05-29 15:31:04.374724: 
2025-05-29 15:31:04.375106: Epoch 199
2025-05-29 15:31:04.375202: Current learning rate: 0.00375
2025-05-29 15:31:35.581618: train_loss -1.2139
2025-05-29 15:31:35.582003: val_loss -0.587
2025-05-29 15:31:35.582137: Pseudo dice [0.8866, 0.6929, 0.3962, 0.6461, 0.3518, 0.8999, 0.5518, 0.6608]
2025-05-29 15:31:35.582210: Epoch time: 31.21 s
2025-05-29 15:31:38.360957: 
2025-05-29 15:31:38.361281: Epoch 200
2025-05-29 15:31:38.361531: Current learning rate: 0.00372
2025-05-29 15:32:09.034179: train_loss -1.2088
2025-05-29 15:32:09.034651: val_loss -0.5855
2025-05-29 15:32:09.034794: Pseudo dice [0.8693, 0.7033, 0.4267, 0.6771, 0.24, 0.9164, 0.5468, 0.5824]
2025-05-29 15:32:09.034882: Epoch time: 30.67 s
2025-05-29 15:32:10.422355: 
2025-05-29 15:32:10.422710: Epoch 201
2025-05-29 15:32:10.423022: Current learning rate: 0.00369
2025-05-29 15:32:41.327367: train_loss -1.2224
2025-05-29 15:32:41.327606: val_loss -0.5876
2025-05-29 15:32:41.327720: Pseudo dice [0.9017, 0.7144, 0.4003, 0.6305, 0.1772, 0.9329, 0.577, 0.6585]
2025-05-29 15:32:41.327811: Epoch time: 30.91 s
2025-05-29 15:32:43.471313: 
2025-05-29 15:32:43.471683: Epoch 202
2025-05-29 15:32:43.471826: Current learning rate: 0.00365
2025-05-29 15:33:14.202792: train_loss -1.2186
2025-05-29 15:33:14.203007: val_loss -0.6117
2025-05-29 15:33:14.203121: Pseudo dice [0.8997, 0.7391, 0.4573, 0.6739, 0.147, 0.9044, 0.5868, 0.608]
2025-05-29 15:33:14.203203: Epoch time: 30.73 s
2025-05-29 15:33:15.574090: 
2025-05-29 15:33:15.574577: Epoch 203
2025-05-29 15:33:15.574700: Current learning rate: 0.00362
2025-05-29 15:33:46.472661: train_loss -1.2374
2025-05-29 15:33:46.472907: val_loss -0.6275
2025-05-29 15:33:46.473022: Pseudo dice [0.9191, 0.6992, 0.4062, 0.646, 0.2164, 0.9351, 0.5331, 0.6647]
2025-05-29 15:33:46.473099: Epoch time: 30.9 s
2025-05-29 15:33:47.833481: 
2025-05-29 15:33:47.833810: Epoch 204
2025-05-29 15:33:47.833918: Current learning rate: 0.00359
2025-05-29 15:34:18.755849: train_loss -1.2327
2025-05-29 15:34:18.756027: val_loss -0.5753
2025-05-29 15:34:18.756156: Pseudo dice [0.8922, 0.7174, 0.428, 0.6201, 0.217, 0.9173, 0.575, 0.6138]
2025-05-29 15:34:18.756233: Epoch time: 30.92 s
2025-05-29 15:34:20.126363: 
2025-05-29 15:34:20.126779: Epoch 205
2025-05-29 15:34:20.126885: Current learning rate: 0.00355
2025-05-29 15:34:50.773251: train_loss -1.2075
2025-05-29 15:34:50.773521: val_loss -0.596
2025-05-29 15:34:50.773725: Pseudo dice [0.9039, 0.7, 0.4468, 0.6566, 0.0464, 0.9329, 0.5375, 0.6351]
2025-05-29 15:34:50.773880: Epoch time: 30.65 s
2025-05-29 15:34:52.107817: 
2025-05-29 15:34:52.108066: Epoch 206
2025-05-29 15:34:52.108205: Current learning rate: 0.00352
2025-05-29 15:35:22.959692: train_loss -1.219
2025-05-29 15:35:22.960462: val_loss -0.6562
2025-05-29 15:35:22.960667: Pseudo dice [0.9024, 0.7085, 0.4295, 0.7178, 0.1786, 0.9291, 0.5792, 0.6571]
2025-05-29 15:35:22.960788: Epoch time: 30.85 s
2025-05-29 15:35:24.397095: 
2025-05-29 15:35:24.397548: Epoch 207
2025-05-29 15:35:24.397745: Current learning rate: 0.00349
2025-05-29 15:35:55.202190: train_loss -1.2222
2025-05-29 15:35:55.202805: val_loss -0.5246
2025-05-29 15:35:55.202919: Pseudo dice [0.907, 0.6859, 0.3587, 0.6064, 0.0708, 0.9174, 0.5237, 0.646]
2025-05-29 15:35:55.202993: Epoch time: 30.81 s
2025-05-29 15:35:56.531096: 
2025-05-29 15:35:56.531438: Epoch 208
2025-05-29 15:35:56.531592: Current learning rate: 0.00345
2025-05-29 15:36:27.556690: train_loss -1.2104
2025-05-29 15:36:27.557081: val_loss -0.6497
2025-05-29 15:36:27.557260: Pseudo dice [0.9183, 0.6953, 0.4335, 0.6183, 0.2279, 0.9408, 0.5328, 0.666]
2025-05-29 15:36:27.557361: Epoch time: 31.03 s
2025-05-29 15:36:28.905307: 
2025-05-29 15:36:28.905710: Epoch 209
2025-05-29 15:36:28.905874: Current learning rate: 0.00342
2025-05-29 15:37:00.165975: train_loss -1.2421
2025-05-29 15:37:00.166217: val_loss -0.5568
2025-05-29 15:37:00.166326: Pseudo dice [0.8975, 0.7368, 0.424, 0.6367, 0.0768, 0.9166, 0.6131, 0.6803]
2025-05-29 15:37:00.166408: Epoch time: 31.26 s
2025-05-29 15:37:01.531481: 
2025-05-29 15:37:01.531844: Epoch 210
2025-05-29 15:37:01.531993: Current learning rate: 0.00338
2025-05-29 15:37:41.239649: train_loss -1.2349
2025-05-29 15:37:41.240027: val_loss -0.5988
2025-05-29 15:37:41.240165: Pseudo dice [0.9123, 0.6933, 0.3448, 0.67, 0.1855, 0.9286, 0.5776, 0.6783]
2025-05-29 15:37:41.240241: Epoch time: 39.71 s
2025-05-29 15:37:42.600644: 
2025-05-29 15:37:42.600860: Epoch 211
2025-05-29 15:37:42.601009: Current learning rate: 0.00335
2025-05-29 15:38:13.801597: train_loss -1.2348
2025-05-29 15:38:13.802591: val_loss -0.5397
2025-05-29 15:38:13.802752: Pseudo dice [0.8947, 0.7219, 0.3953, 0.6398, 0.1426, 0.9402, 0.5939, 0.5928]
2025-05-29 15:38:13.802937: Epoch time: 31.2 s
2025-05-29 15:38:15.223704: 
2025-05-29 15:38:15.223976: Epoch 212
2025-05-29 15:38:15.224079: Current learning rate: 0.00332
2025-05-29 15:38:46.117336: train_loss -1.2301
2025-05-29 15:38:46.117874: val_loss -0.6129
2025-05-29 15:38:46.117995: Pseudo dice [0.913, 0.7086, 0.4628, 0.5944, 0.3218, 0.9285, 0.5772, 0.6848]
2025-05-29 15:38:46.118158: Epoch time: 30.9 s
2025-05-29 15:38:48.236269: 
2025-05-29 15:38:48.237201: Epoch 213
2025-05-29 15:38:48.237890: Current learning rate: 0.00328
2025-05-29 15:39:19.629241: train_loss -1.2382
2025-05-29 15:39:19.629718: val_loss -0.4845
2025-05-29 15:39:19.629871: Pseudo dice [0.8953, 0.6406, 0.407, 0.5911, 0.2621, 0.9229, 0.6001, 0.6419]
2025-05-29 15:39:19.630162: Epoch time: 31.4 s
2025-05-29 15:39:21.019319: 
2025-05-29 15:39:21.020092: Epoch 214
2025-05-29 15:39:21.020503: Current learning rate: 0.00325
2025-05-29 15:39:52.138383: train_loss -1.2458
2025-05-29 15:39:52.138867: val_loss -0.5997
2025-05-29 15:39:52.138999: Pseudo dice [0.9049, 0.6692, 0.3987, 0.6034, 0.2283, 0.9332, 0.5999, 0.6687]
2025-05-29 15:39:52.139090: Epoch time: 31.12 s
2025-05-29 15:39:53.563151: 
2025-05-29 15:39:53.563577: Epoch 215
2025-05-29 15:39:53.563688: Current learning rate: 0.00321
2025-05-29 15:40:24.809176: train_loss -1.2443
2025-05-29 15:40:24.809963: val_loss -0.5444
2025-05-29 15:40:24.810114: Pseudo dice [0.8895, 0.686, 0.409, 0.5787, 0.1196, 0.9265, 0.5787, 0.6564]
2025-05-29 15:40:24.810264: Epoch time: 31.25 s
2025-05-29 15:40:26.185551: 
2025-05-29 15:40:26.185837: Epoch 216
2025-05-29 15:40:26.185964: Current learning rate: 0.00318
2025-05-29 15:40:57.311579: train_loss -1.2241
2025-05-29 15:40:57.311840: val_loss -0.627
2025-05-29 15:40:57.311958: Pseudo dice [0.9254, 0.6754, 0.4479, 0.6275, 0.239, 0.939, 0.5477, 0.742]
2025-05-29 15:40:57.312044: Epoch time: 31.13 s
2025-05-29 15:40:58.639862: 
2025-05-29 15:40:58.640246: Epoch 217
2025-05-29 15:40:58.640384: Current learning rate: 0.00315 Pseudo dice [0.8736, 0.5709, 0.311, 0.5522, 0.0, 0.8692, 0.4585, 0.6515]
2025-05-29 15:22:40.127653: Epoch time: 85.61 s
2025-05-29 15:22:40.127721: Yayy! New best EMA pseudo Dice: 0.5302
2025-05-29 15:22:42.709062: 
2025-05-29 15:22:42.709390: Epoch 71
2025-05-29 15:22:42.709552: Current learning rate: 0.00784
2025-05-29 15:24:10.493052: train_loss -0.8261
2025-05-29 15:24:10.493281: val_loss -0.5556
2025-05-29 15:24:10.493406: Pseudo dice [0.8699, 0.5359, 0.369, 0.6358, 0.0, 0.8219, 0.4364, 0.6849]
2025-05-29 15:24:10.493511: Epoch time: 87.79 s
2025-05-29 15:24:10.493574: Yayy! New best EMA pseudo Dice: 0.5316
2025-05-29 15:24:13.271896: 
2025-05-29 15:24:13.272328: Epoch 72
2025-05-29 15:24:13.272435: Current learning rate: 0.00781
2025-05-29 15:25:36.407732: train_loss -0.812
2025-05-29 15:25:36.408045: val_loss -0.5993
2025-05-29 15:25:36.408213: Pseudo dice [0.8862, 0.5815, 0.365, 0.6016, 0.0, 0.8181, 0.4957, 0.7267]
2025-05-29 15:25:36.408302: Epoch time: 83.14 s
2025-05-29 15:25:36.408350: Yayy! New best EMA pseudo Dice: 0.5344
2025-05-29 15:25:39.054932: 
2025-05-29 15:25:39.055438: Epoch 73
2025-05-29 15:25:39.055605: Current learning rate: 0.00778
2025-05-29 15:27:07.791657: train_loss -0.8144
2025-05-29 15:27:07.791968: val_loss -0.5508
2025-05-29 15:27:07.792091: Pseudo dice [0.8894, 0.5415, 0.3763, 0.5586, 0.0, 0.8013, 0.4168, 0.7342]
2025-05-29 15:27:07.792191: Epoch time: 88.74 s
2025-05-29 15:27:07.792261: Yayy! New best EMA pseudo Dice: 0.5349
2025-05-29 15:27:10.569653: 
2025-05-29 15:27:10.570047: Epoch 74
2025-05-29 15:27:10.570142: Current learning rate: 0.00775
2025-05-29 15:28:36.212177: train_loss -0.8334
2025-05-29 15:28:36.212392: val_loss -0.4515
2025-05-29 15:28:36.212512: Pseudo dice [0.8476, 0.5288, 0.3032, 0.5012, 0.0, 0.8175, 0.4749, 0.6887]
2025-05-29 15:28:36.212603: Epoch time: 85.64 s
2025-05-29 15:28:37.541882: 
2025-05-29 15:28:37.542222: Epoch 75
2025-05-29 15:28:37.542320: Current learning rate: 0.00772
2025-05-29 15:30:07.314021: train_loss -0.7839
2025-05-29 15:30:07.314313: val_loss -0.6397
2025-05-29 15:30:07.314430: Pseudo dice [0.8699, 0.5572, 0.3405, 0.7324, 0.0, 0.8313, 0.4549, 0.7379]
2025-05-29 15:30:07.314553: Epoch time: 89.77 s
2025-05-29 15:30:07.314602: Yayy! New best EMA pseudo Dice: 0.5366
2025-05-29 15:30:10.084491: 
2025-05-29 15:30:10.084904: Epoch 76
2025-05-29 15:30:10.085002: Current learning rate: 0.00769
2025-05-29 15:31:39.320336: train_loss -0.8275
2025-05-29 15:31:39.320567: val_loss -0.6307
2025-05-29 15:31:39.320693: Pseudo dice [0.8901, 0.5618, 0.3606, 0.7015, 0.0, 0.8236, 0.4587, 0.7038]
2025-05-29 15:31:39.320780: Epoch time: 89.24 s
2025-05-29 15:31:39.320832: Yayy! New best EMA pseudo Dice: 0.5392
2025-05-29 15:31:41.873871: 
2025-05-29 15:31:41.874161: Epoch 77
2025-05-29 15:31:41.874279: Current learning rate: 0.00766
2025-05-29 15:33:08.938054: train_loss -0.8049
2025-05-29 15:33:08.938281: val_loss -0.6105
2025-05-29 15:33:08.938395: Pseudo dice [0.867, 0.4838, 0.2895, 0.7297, 0.0, 0.8399, 0.44, 0.6688]
2025-05-29 15:33:08.938497: Epoch time: 87.07 s
2025-05-29 15:33:08.938626: Yayy! New best EMA pseudo Dice: 0.5393
2025-05-29 15:33:11.825416: 
2025-05-29 15:33:11.825851: Epoch 78
2025-05-29 15:33:11.826019: Current learning rate: 0.00763
2025-05-29 15:34:40.470608: train_loss -0.8185
2025-05-29 15:34:40.470987: val_loss -0.5603
2025-05-29 15:34:40.471146: Pseudo dice [0.8716, 0.539, 0.3308, 0.6237, 0.0, 0.8208, 0.4225, 0.7408]
2025-05-29 15:34:40.471314: Epoch time: 88.65 s
2025-05-29 15:34:40.471369: Yayy! New best EMA pseudo Dice: 0.5397
2025-05-29 15:34:43.033787: 
2025-05-29 15:34:43.033958: Epoch 79
2025-05-29 15:34:43.034096: Current learning rate: 0.0076
2025-05-29 15:36:09.293024: train_loss -0.8082
2025-05-29 15:36:09.293488: val_loss -0.4231
2025-05-29 15:36:09.293617: Pseudo dice [0.8877, 0.532, 0.3887, 0.4699, 0.0, 0.7708, 0.4928, 0.6789]
2025-05-29 15:36:09.293691: Epoch time: 86.26 s
2025-05-29 15:36:10.665834: 
2025-05-29 15:36:10.666027: Epoch 80
2025-05-29 15:36:10.666125: Current learning rate: 0.00756
2025-05-29 15:37:37.600713: train_loss -0.8403
2025-05-29 15:37:37.600938: val_loss -0.5421
2025-05-29 15:37:37.601051: Pseudo dice [0.8745, 0.5307, 0.3892, 0.601, 0.0, 0.8066, 0.4858, 0.7183]
2025-05-29 15:37:37.601133: Epoch time: 86.94 s
2025-05-29 15:37:37.601184: Yayy! New best EMA pseudo Dice: 0.5397
2025-05-29 15:37:40.309653: 
2025-05-29 15:37:40.309995: Epoch 81
2025-05-29 15:37:40.310117: Current learning rate: 0.00753
2025-05-29 15:39:02.214217: train_loss -0.8639
2025-05-29 15:39:02.214509: val_loss -0.6551
2025-05-29 15:39:02.214652: Pseudo dice [0.8667, 0.5931, 0.4082, 0.731, 0.0, 0.8925, 0.4758, 0.7665]
2025-05-29 15:39:02.214745: Epoch time: 81.91 s
2025-05-29 15:39:02.214806: Yayy! New best EMA pseudo Dice: 0.5449
2025-05-29 15:39:05.077239: 
2025-05-29 15:39:05.077456: Epoch 82
2025-05-29 15:39:05.077607: Current learning rate: 0.0075
2025-05-29 15:40:31.315003: train_loss -0.9124
2025-05-29 15:40:31.315226: val_loss -0.6
2025-05-29 15:40:31.315434: Pseudo dice [0.8875, 0.6173, 0.4318, 0.6137, 0.0, 0.8397, 0.491, 0.7209]
2025-05-29 15:40:31.315535: Epoch time: 86.24 s
2025-05-29 15:40:31.315598: Yayy! New best EMA pseudo Dice: 0.548
2025-05-29 15:40:34.638766: 
2025-05-29 15:40:34.639131: Epoch 83
2025-05-29 15:40:34.639246: Current learning rate: 0.00747
2025-05-29 15:42:03.788257: train_loss -0.9017
2025-05-29 15:42:03.788440: val_loss -0.545
2025-05-29 15:42:03.788564: Pseudo dice [0.9017, 0.5801, 0.3604, 0.5611, 0.0, 0.8073, 0.4154, 0.7661]
2025-05-29 15:42:03.788640: Epoch time: 89.15 s
2025-05-29 15:42:03.788690: Yayy! New best EMA pseudo Dice: 0.5481
2025-05-29 15:42:06.293921: 
2025-05-29 15:42:06.294193: Epoch 84
2025-05-29 15:42:06.294286: Current learning rate: 0.00744
2025-05-29 15:43:37.008821: train_loss -0.8707
2025-05-29 15:43:37.009064: val_loss -0.4883
2025-05-29 15:43:37.009234: Pseudo dice [0.8415, 0.5776, 0.3718, 0.5484, 0.0, 0.7696, 0.4464, 0.7438]
2025-05-29 15:43:37.009313: Epoch time: 90.72 s
2025-05-29 15:43:38.315232: 
2025-05-29 15:43:38.315508: Epoch 85
2025-05-29 15:43:38.315764: Current learning rate: 0.00741
2025-05-29 15:45:07.600670: train_loss -0.8786
2025-05-29 15:45:07.600982: val_loss -0.5355
2025-05-29 15:45:07.601099: Pseudo dice [0.9028, 0.5765, 0.3406, 0.5619, 0.0, 0.8422, 0.4522, 0.7576]
2025-05-29 15:45:07.601186: Epoch time: 89.29 s
2025-05-29 15:45:08.900491: 
2025-05-29 15:45:08.900779: Epoch 86
2025-05-29 15:45:08.901021: Current learning rate: 0.00738
2025-05-29 15:46:39.680701: train_loss -0.9169
2025-05-29 15:46:39.680988: val_loss -0.7125
2025-05-29 15:46:39.681109: Pseudo dice [0.8815, 0.5631, 0.4082, 0.7673, 0.0, 0.8535, 0.4149, 0.7875]
2025-05-29 15:46:39.681199: Epoch time: 90.78 s
2025-05-29 15:46:39.681264: Yayy! New best EMA pseudo Dice: 0.5514
2025-05-29 15:46:42.056476: 
2025-05-29 15:46:42.056881: Epoch 87
2025-05-29 15:46:42.057025: Current learning rate: 0.00735
2025-05-29 15:48:11.809540: train_loss -0.8583
2025-05-29 15:48:11.809880: val_loss -0.6802
2025-05-29 15:48:11.809997: Pseudo dice [0.8818, 0.6086, 0.3871, 0.7635, 0.0, 0.8622, 0.491, 0.7102]
2025-05-29 15:48:11.810091: Epoch time: 89.75 s
2025-05-29 15:48:11.810213: Yayy! New best EMA pseudo Dice: 0.5551
2025-05-29 15:48:14.449474: 
2025-05-29 15:48:14.449692: Epoch 88
2025-05-29 15:48:14.449790: Current learning rate: 0.00732
2025-05-29 15:49:44.166188: train_loss -0.911
2025-05-29 15:49:44.166416: val_loss -0.6347
2025-05-29 15:49:44.166539: Pseudo dice [0.8809, 0.6429, 0.3667, 0.6808, 0.0, 0.8024, 0.4371, 0.7083]
2025-05-29 15:49:44.166626: Epoch time: 89.72 s
2025-05-29 15:49:44.166679: Yayy! New best EMA pseudo Dice: 0.5561
2025-05-29 15:49:46.711541: 
2025-05-29 15:49:46.711868: Epoch 89
2025-05-29 15:49:46.711967: Current learning rate: 0.00729
2025-05-29 15:51:17.193029: train_loss -0.9117
2025-05-29 15:51:17.193340: val_loss -0.5383
2025-05-29 15:51:17.193557: Pseudo dice [0.8919, 0.5604, 0.4004, 0.5671, 0.0112, 0.783, 0.4933, 0.745]
2025-05-29 15:51:17.193656: Epoch time: 90.48 s
2025-05-29 15:51:17.193706: Yayy! New best EMA pseudo Dice: 0.5561
2025-05-29 15:51:19.712189: 
2025-05-29 15:51:19.712573:
2025-05-29 15:41:29.673746: train_loss -1.2292
2025-05-29 15:41:29.779928: val_loss -0.5359
2025-05-29 15:41:29.780078: Pseudo dice [0.9096, 0.726, 0.4084, 0.5789, 0.1498, 0.914, 0.5839, 0.6746]
2025-05-29 15:41:29.780184: Epoch time: 31.03 s
2025-05-29 15:41:31.120957: 
2025-05-29 15:41:31.121282: Epoch 218
2025-05-29 15:41:31.121379: Current learning rate: 0.00311
2025-05-29 15:42:02.223251: train_loss -1.229
2025-05-29 15:42:02.223903: val_loss -0.5971
2025-05-29 15:42:02.224117: Pseudo dice [0.8952, 0.7125, 0.4184, 0.6056, 0.163, 0.9197, 0.6094, 0.6761]
2025-05-29 15:42:02.224286: Epoch time: 31.1 s
2025-05-29 15:42:03.614302: 
2025-05-29 15:42:03.614964: Epoch 219
2025-05-29 15:42:03.615065: Current learning rate: 0.00308
2025-05-29 15:42:35.327551: train_loss -1.2441
2025-05-29 15:42:35.327958: val_loss -0.5403
2025-05-29 15:42:35.328171: Pseudo dice [0.9032, 0.6697, 0.4249, 0.6184, 0.1049, 0.9278, 0.5816, 0.6718]
2025-05-29 15:42:35.328269: Epoch time: 31.72 s
2025-05-29 15:42:36.700382: 
2025-05-29 15:42:36.700760: Epoch 220
2025-05-29 15:42:36.700891: Current learning rate: 0.00304
2025-05-29 15:43:16.131413: train_loss -1.233
2025-05-29 15:43:16.131741: val_loss -0.5611
2025-05-29 15:43:16.132011: Pseudo dice [0.8936, 0.73, 0.4207, 0.6176, 0.1425, 0.8827, 0.5996, 0.637]
2025-05-29 15:43:16.132146: Epoch time: 39.43 s
2025-05-29 15:43:17.484060: 
2025-05-29 15:43:17.484419: Epoch 221
2025-05-29 15:43:17.484535: Current learning rate: 0.00301
2025-05-29 15:43:48.293604: train_loss -1.2371
2025-05-29 15:43:48.293947: val_loss -0.6058
2025-05-29 15:43:48.294071: Pseudo dice [0.9092, 0.723, 0.4507, 0.6141, 0.1259, 0.9161, 0.6046, 0.6789]
2025-05-29 15:43:48.294191: Epoch time: 30.81 s
2025-05-29 15:43:49.699385: 
2025-05-29 15:43:49.699745: Epoch 222
2025-05-29 15:43:49.699873: Current learning rate: 0.00297
2025-05-29 15:44:20.919206: train_loss -1.2336
2025-05-29 15:44:20.919431: val_loss -0.6371
2025-05-29 15:44:20.919557: Pseudo dice [0.908, 0.7199, 0.396, 0.6973, 0.2697, 0.9174, 0.5975, 0.6715]
2025-05-29 15:44:20.919705: Epoch time: 31.22 s
2025-05-29 15:44:22.260331: 
2025-05-29 15:44:22.260712: Epoch 223
2025-05-29 15:44:22.260815: Current learning rate: 0.00294
2025-05-29 15:44:53.417950: train_loss -1.2538
2025-05-29 15:44:53.418171: val_loss -0.5356
2025-05-29 15:44:53.418300: Pseudo dice [0.9091, 0.7102, 0.4045, 0.5843, 0.2189, 0.9155, 0.5576, 0.7009]
2025-05-29 15:44:53.418430: Epoch time: 31.16 s
2025-05-29 15:44:54.762430: 
2025-05-29 15:44:54.762781: Epoch 224
2025-05-29 15:44:54.762876: Current learning rate: 0.00291
2025-05-29 15:45:25.871913: train_loss -1.2298
2025-05-29 15:45:25.872164: val_loss -0.578
2025-05-29 15:45:25.872281: Pseudo dice [0.8966, 0.7336, 0.3955, 0.6112, 0.1756, 0.9259, 0.5404, 0.6223]
2025-05-29 15:45:25.872359: Epoch time: 31.11 s
2025-05-29 15:45:28.072292: 
2025-05-29 15:45:28.073354: Epoch 225
2025-05-29 15:45:28.073947: Current learning rate: 0.00287
2025-05-29 15:45:59.351513: train_loss -1.2353
2025-05-29 15:45:59.351864: val_loss -0.4808
2025-05-29 15:45:59.352048: Pseudo dice [0.8857, 0.6903, 0.3665, 0.6198, 0.1361, 0.9198, 0.5612, 0.5668]
2025-05-29 15:45:59.352135: Epoch time: 31.28 s
2025-05-29 15:46:00.831134: 
2025-05-29 15:46:00.831717: Epoch 226
2025-05-29 15:46:00.832094: Current learning rate: 0.00284
2025-05-29 15:46:39.951839: train_loss -1.2477
2025-05-29 15:46:39.952720: val_loss -0.6014
2025-05-29 15:46:39.952886: Pseudo dice [0.9014, 0.6835, 0.4206, 0.6469, 0.1824, 0.9204, 0.5617, 0.6637]
2025-05-29 15:46:39.953087: Epoch time: 39.12 s
2025-05-29 15:46:41.426103: 
2025-05-29 15:46:41.426620: Epoch 227
2025-05-29 15:46:41.426808: Current learning rate: 0.0028
2025-05-29 15:47:12.603329: train_loss -1.2395
2025-05-29 15:47:12.603901: val_loss -0.6027
2025-05-29 15:47:12.604143: Pseudo dice [0.8882, 0.6841, 0.4406, 0.6889, 0.2166, 0.9394, 0.5545, 0.6149]
2025-05-29 15:47:12.604235: Epoch time: 31.18 s
2025-05-29 15:47:13.987970: 
2025-05-29 15:47:13.988331: Epoch 228
2025-05-29 15:47:13.988494: Current learning rate: 0.00277
2025-05-29 15:47:44.765054: train_loss -1.2297
2025-05-29 15:47:44.765540: val_loss -0.6062
2025-05-29 15:47:44.765712: Pseudo dice [0.8945, 0.701, 0.4319, 0.6974, 0.0677, 0.9148, 0.5851, 0.6623]
2025-05-29 15:47:44.765799: Epoch time: 30.78 s
2025-05-29 15:47:46.151527: 
2025-05-29 15:47:46.151971: Epoch 229
2025-05-29 15:47:46.152116: Current learning rate: 0.00273
2025-05-29 15:48:17.139021: train_loss -1.2595
2025-05-29 15:48:17.139604: val_loss -0.556
2025-05-29 15:48:17.139924: Pseudo dice [0.8992, 0.6913, 0.421, 0.6672, 0.1057, 0.9442, 0.5411, 0.6217]
2025-05-29 15:48:17.140129: Epoch time: 30.99 s
2025-05-29 15:48:18.491902: 
2025-05-29 15:48:18.492269: Epoch 230
2025-05-29 15:48:18.492366: Current learning rate: 0.0027
2025-05-29 15:48:49.424972: train_loss -1.2678
2025-05-29 15:48:49.425204: val_loss -0.5319
2025-05-29 15:48:49.425319: Pseudo dice [0.894, 0.6926, 0.4206, 0.587, 0.1344, 0.8972, 0.5793, 0.6726]
2025-05-29 15:48:49.425420: Epoch time: 30.93 s
2025-05-29 15:48:50.797325: 
2025-05-29 15:48:50.797697: Epoch 231
2025-05-29 15:48:50.797799: Current learning rate: 0.00266
2025-05-29 15:49:21.726328: train_loss -1.2555
2025-05-29 15:49:21.726572: val_loss -0.5354
2025-05-29 15:49:21.726689: Pseudo dice [0.8981, 0.7024, 0.3867, 0.5705, 0.2245, 0.8845, 0.6017, 0.6948]
2025-05-29 15:49:21.726781: Epoch time: 30.93 s
2025-05-29 15:49:23.073868: 
2025-05-29 15:49:23.074135: Epoch 232
2025-05-29 15:49:23.074263: Current learning rate: 0.00263
2025-05-29 15:49:54.028090: train_loss -1.2584
2025-05-29 15:49:54.028286: val_loss -0.5168
2025-05-29 15:49:54.028407: Pseudo dice [0.9089, 0.6713, 0.3974, 0.6016, 0.2532, 0.934, 0.5749, 0.6936]
2025-05-29 15:49:54.028495: Epoch time: 30.96 s
2025-05-29 15:49:55.360590: 
2025-05-29 15:49:55.360876: Epoch 233
2025-05-29 15:49:55.361058: Current learning rate: 0.00259
2025-05-29 15:50:26.137277: train_loss -1.2607
2025-05-29 15:50:26.137522: val_loss -0.5767
2025-05-29 15:50:26.137709: Pseudo dice [0.9194, 0.6633, 0.3956, 0.6222, 0.2147, 0.9313, 0.5834, 0.7202]
2025-05-29 15:50:26.137880: Epoch time: 30.78 s
2025-05-29 15:50:27.479008: 
2025-05-29 15:50:27.479358: Epoch 234
2025-05-29 15:50:27.479462: Current learning rate: 0.00256
2025-05-29 15:50:58.489229: train_loss -1.2512
2025-05-29 15:50:58.489466: val_loss -0.5443
2025-05-29 15:50:58.489635: Pseudo dice [0.9131, 0.6988, 0.3996, 0.592, 0.0822, 0.9184, 0.5948, 0.6818]
2025-05-29 15:50:58.489804: Epoch time: 31.01 s
2025-05-29 15:51:00.010037: 
2025-05-29 15:51:00.010420: Epoch 235
2025-05-29 15:51:00.010586: Current learning rate: 0.00252
2025-05-29 15:51:30.574382: train_loss -1.2572
2025-05-29 15:51:30.574614: val_loss -0.5723
2025-05-29 15:51:30.574725: Pseudo dice [0.8911, 0.7263, 0.4275, 0.6495, 0.0868, 0.9282, 0.6261, 0.6109]
2025-05-29 15:51:30.574819: Epoch time: 30.57 s
2025-05-29 15:51:32.577660: 
2025-05-29 15:51:32.577910: Epoch 236
2025-05-29 15:51:32.578020: Current learning rate: 0.00249
2025-05-29 15:52:03.540786: train_loss -1.2612
2025-05-29 15:52:03.540981: val_loss -0.5644
2025-05-29 15:52:03.541134: Pseudo dice [0.8889, 0.7186, 0.4394, 0.6141, 0.1088, 0.9221, 0.5761, 0.616]
2025-05-29 15:52:03.541216: Epoch time: 30.96 s
2025-05-29 15:52:04.872492: 
2025-05-29 15:52:04.872883: Epoch 237
2025-05-29 15:52:04.872990: Current learning rate: 0.00245
2025-05-29 15:52:35.765348: train_loss -1.2442
2025-05-29 15:52:35.765751: val_loss -0.642
2025-05-29 15:52:35.765884: Pseudo dice [0.9141, 0.7115, 0.4096, 0.6555, 0.2043, 0.9265, 0.5332, 0.6644]
2025-05-29 15:52:35.765957: Epoch time: 30.89 s
2025-05-29 15:52:37.113434: 
2025-05-29 15:52:37.113691: Epoch 238
2025-05-29 15:52:37.113788: Current learning rate: 0.00242
2025-05-29 15:53:07.970198: train_loss -1.2755
2025-05-29 15:53:07.970469: val_loss -0.612
2025-05-29 15:53:07.970589: Pseudo dice [0.9046, 0.7253, 0.43, 0.6839, 0.1077, 0.9403, 0.5646, 0.55]
2025-05-29 15:53:07.970677: Epoch time: 30.86 s
2025-05-29 15:53:09.379024: 
2025-05-29 15:53:09.379393: Epoch 239
2025-05-29 15:53:09.379498: Current learning rate: 0.00238
2025-05-29 15:53:40.305804: train_loss -1.2673
2025-05-29 15:53:40.306055: 
2025-05-29 15:30:44.998893: Epoch 90
2025-05-29 15:30:44.999058: Current learning rate: 0.00725
2025-05-29 15:31:57.761693: train_loss -0.9803
2025-05-29 15:31:57.761928: val_loss -0.5984
2025-05-29 15:31:57.762044: Pseudo dice [0.9102, 0.7064, 0.4246, 0.5767, 0.292, 0.9241, 0.5363, 0.7177]
2025-05-29 15:31:57.762134: Epoch time: 72.76 s
2025-05-29 15:31:57.762189: Yayy! New best EMA pseudo Dice: 0.6023
2025-05-29 15:32:00.381553: 
2025-05-29 15:32:00.381883: Epoch 91
2025-05-29 15:32:00.381981: Current learning rate: 0.00722
2025-05-29 15:33:12.949423: train_loss -0.9939
2025-05-29 15:33:12.949612: val_loss -0.6118
2025-05-29 15:33:12.949727: Pseudo dice [0.918, 0.7115, 0.4025, 0.6249, 0.1619, 0.9392, 0.5692, 0.5918]
2025-05-29 15:33:12.949803: Epoch time: 72.57 s
2025-05-29 15:33:12.949857: Yayy! New best EMA pseudo Dice: 0.6036
2025-05-29 15:33:15.488901: 
2025-05-29 15:33:15.489194: Epoch 92
2025-05-29 15:33:15.489296: Current learning rate: 0.00719
2025-05-29 15:34:28.493392: train_loss -1.0131
2025-05-29 15:34:28.493699: val_loss -0.6595
2025-05-29 15:34:28.493818: Pseudo dice [0.9079, 0.7064, 0.4196, 0.6493, 0.1937, 0.9394, 0.5462, 0.6467]
2025-05-29 15:34:28.493927: Epoch time: 73.01 s
2025-05-29 15:34:28.494120: Yayy! New best EMA pseudo Dice: 0.6058
2025-05-29 15:34:31.055631: 
2025-05-29 15:34:31.056074: Epoch 93
2025-05-29 15:34:31.056175: Current learning rate: 0.00716
2025-05-29 15:35:43.973145: train_loss -0.9866
2025-05-29 15:35:43.973441: val_loss -0.6092
2025-05-29 15:35:43.973574: Pseudo dice [0.8984, 0.654, 0.377, 0.569, 0.1371, 0.918, 0.602, 0.7312]
2025-05-29 15:35:43.973650: Epoch time: 72.92 s
2025-05-29 15:35:43.973712: Yayy! New best EMA pseudo Dice: 0.6063
2025-05-29 15:35:46.540538: 
2025-05-29 15:35:46.540819: Epoch 94
2025-05-29 15:35:46.540921: Current learning rate: 0.00713
2025-05-29 15:36:58.746814: train_loss -0.981
2025-05-29 15:36:58.747048: val_loss -0.6378
2025-05-29 15:36:58.747162: Pseudo dice [0.9068, 0.7105, 0.3065, 0.6108, 0.2422, 0.9399, 0.5811, 0.7372]
2025-05-29 15:36:58.747243: Epoch time: 72.21 s
2025-05-29 15:36:58.747293: Yayy! New best EMA pseudo Dice: 0.6086
2025-05-29 15:37:02.062179: 
2025-05-29 15:37:02.062420: Epoch 95
2025-05-29 15:37:02.062543: Current learning rate: 0.0071
2025-05-29 15:38:19.637230: train_loss -0.9942
2025-05-29 15:38:19.637467: val_loss -0.5135
2025-05-29 15:38:19.637584: Pseudo dice [0.8994, 0.6409, 0.3556, 0.4964, 0.0674, 0.9271, 0.5741, 0.6709]
2025-05-29 15:38:19.637671: Epoch time: 77.58 s
2025-05-29 15:38:20.975016: 
2025-05-29 15:38:20.975282: Epoch 96
2025-05-29 15:38:20.975425: Current learning rate: 0.00707
2025-05-29 15:39:37.591011: train_loss -0.9863
2025-05-29 15:39:37.591227: val_loss -0.6479
2025-05-29 15:39:37.591344: Pseudo dice [0.9024, 0.7253, 0.4267, 0.6443, 0.1265, 0.8926, 0.5382, 0.7112]
2025-05-29 15:39:37.591433: Epoch time: 76.62 s
2025-05-29 15:39:38.945033: 
2025-05-29 15:39:38.945398: Epoch 97
2025-05-29 15:39:38.945588: Current learning rate: 0.00704
2025-05-29 15:40:56.449733: train_loss -1.0321
2025-05-29 15:40:56.449969: val_loss -0.6572
2025-05-29 15:40:56.450087: Pseudo dice [0.9125, 0.7013, 0.4225, 0.6437, 0.1899, 0.917, 0.5319, 0.6884]
2025-05-29 15:40:56.450172: Epoch time: 77.51 s
2025-05-29 15:40:56.450226: Yayy! New best EMA pseudo Dice: 0.6091
2025-05-29 15:40:59.235091: 
2025-05-29 15:40:59.235348: Epoch 98
2025-05-29 15:40:59.235459: Current learning rate: 0.007
2025-05-29 15:42:14.941531: train_loss -1.0346
2025-05-29 15:42:14.941851: val_loss -0.6484
2025-05-29 15:42:14.941991: Pseudo dice [0.9127, 0.6893, 0.4002, 0.5512, 0.17, 0.9036, 0.493, 0.7121]
2025-05-29 15:42:14.942099: Epoch time: 75.71 s
2025-05-29 15:42:16.648822: 
2025-05-29 15:42:16.648988: Epoch 99
2025-05-29 15:42:16.649090: Current learning rate: 0.00697
2025-05-29 15:43:33.037549: train_loss -0.9811
2025-05-29 15:43:33.037786: val_loss -0.6364
2025-05-29 15:43:33.037932: Pseudo dice [0.8892, 0.6892, 0.4141, 0.606, 0.1861, 0.8857, 0.574, 0.6948]
2025-05-29 15:43:33.038028: Epoch time: 76.39 s
2025-05-29 15:43:34.480278: Yayy! New best EMA pseudo Dice: 0.6095
2025-05-29 15:43:37.184082: 
2025-05-29 15:43:37.184443: Epoch 100
2025-05-29 15:43:37.184595: Current learning rate: 0.00694
2025-05-29 15:44:51.146882: train_loss -0.9691
2025-05-29 15:44:51.147109: val_loss -0.5526
2025-05-29 15:44:51.147225: Pseudo dice [0.902, 0.6868, 0.4021, 0.4729, 0.2109, 0.9098, 0.5574, 0.6556]
2025-05-29 15:44:51.147310: Epoch time: 73.96 s
2025-05-29 15:44:52.558534: 
2025-05-29 15:44:52.558860: Epoch 101
2025-05-29 15:44:52.558986: Current learning rate: 0.00691
2025-05-29 15:46:05.452074: train_loss -1.0218
2025-05-29 15:46:05.452294: val_loss -0.6532
2025-05-29 15:46:05.452408: Pseudo dice [0.9032, 0.6823, 0.4089, 0.6053, 0.1761, 0.9332, 0.5669, 0.6749]
2025-05-29 15:46:05.452502: Epoch time: 72.89 s
2025-05-29 15:46:05.452560: Yayy! New best EMA pseudo Dice: 0.6095
2025-05-29 15:46:08.283691: 
2025-05-29 15:46:08.284106: Epoch 102
2025-05-29 15:46:08.284220: Current learning rate: 0.00688
2025-05-29 15:47:25.556041: train_loss -1.0395
2025-05-29 15:47:25.556234: val_loss -0.6989
2025-05-29 15:47:25.556346: Pseudo dice [0.9083, 0.7142, 0.4652, 0.6682, 0.079, 0.9228, 0.5529, 0.7143]
2025-05-29 15:47:25.556423: Epoch time: 77.27 s
2025-05-29 15:47:25.556485: Yayy! New best EMA pseudo Dice: 0.6114
2025-05-29 15:47:28.247176: 
2025-05-29 15:47:28.247485: Epoch 103
2025-05-29 15:47:28.247598: Current learning rate: 0.00685
2025-05-29 15:48:40.705330: train_loss -1.0459
2025-05-29 15:48:40.705558: val_loss -0.5864
2025-05-29 15:48:40.705679: Pseudo dice [0.9103, 0.728, 0.3924, 0.5577, 0.1321, 0.8891, 0.5485, 0.6518]
2025-05-29 15:48:40.705765: Epoch time: 72.46 s
2025-05-29 15:48:42.044573: 
2025-05-29 15:48:42.044795: Epoch 104
2025-05-29 15:48:42.044906: Current learning rate: 0.00682
2025-05-29 15:49:54.837009: train_loss -1.064
2025-05-29 15:49:54.837266: val_loss -0.6949
2025-05-29 15:49:54.837379: Pseudo dice [0.9217, 0.6987, 0.4519, 0.6471, 0.1682, 0.9382, 0.5915, 0.7102]
2025-05-29 15:49:54.837472: Epoch time: 72.79 s
2025-05-29 15:49:54.837530: Yayy! New best EMA pseudo Dice: 0.6134
2025-05-29 15:49:57.217505: 
2025-05-29 15:49:57.217662: Epoch 105
2025-05-29 15:49:57.217825: Current learning rate: 0.00679
2025-05-29 15:51:11.719247: train_loss -1.0354
2025-05-29 15:51:11.719474: val_loss -0.6669
2025-05-29 15:51:11.719664: Pseudo dice [0.9199, 0.7107, 0.408, 0.5793, 0.293, 0.9326, 0.5908, 0.7145]
2025-05-29 15:51:11.719772: Epoch time: 74.5 s
2025-05-29 15:51:11.719865: Yayy! New best EMA pseudo Dice: 0.6164
2025-05-29 15:51:14.987312: 
2025-05-29 15:51:14.987641: Epoch 106
2025-05-29 15:51:14.987783: Current learning rate: 0.00675
2025-05-29 15:52:28.335675: train_loss -1.018
2025-05-29 15:52:28.335966: val_loss -0.6702
2025-05-29 15:52:28.336123: Pseudo dice [0.92, 0.703, 0.4417, 0.6579, 0.2532, 0.8667, 0.5925, 0.7496]
2025-05-29 15:52:28.336309: Epoch time: 73.35 s
2025-05-29 15:52:28.336422: Yayy! New best EMA pseudo Dice: 0.6196
2025-05-29 15:52:30.967765: 
2025-05-29 15:52:30.968033: Epoch 107
2025-05-29 15:52:30.968312: Current learning rate: 0.00672
2025-05-29 15:53:45.212495: train_loss -1.0273
2025-05-29 15:53:45.212828: val_loss -0.6883
2025-05-29 15:53:45.212946: Pseudo dice [0.9013, 0.7115, 0.4234, 0.7003, 0.2849, 0.9245, 0.4333, 0.6452]
2025-05-29 15:53:45.213029: Epoch time: 74.25 s
2025-05-29 15:53:45.213092: Yayy! New best EMA pseudo Dice: 0.6204
2025-05-29 15:53:47.785666: 
2025-05-29 15:53:47.786046: Epoch 108
2025-05-29 15:53:47.786171: Current learning rate: 0.00669
2025-05-29 15:55:00.629906: train_loss -1.0441
2025-05-29 15:55:00.630114: val_loss -0.7357
2025-05-29 15:55:00.630229: Pseudo dice [0.912, 0.7135, 0.4656, 0.7347, 0.2782, 0.9462, 0.5214, 0.7199]
2025-05-29 15:55:00.630319: Epoch time: 72.85 s
2025-05-29 15:55:00.630383: Yayy! New best EMA pseudo Dice: 0.6245
2025-05-29 15:55:03.600942: 
2025-05-29 15:55:03.601189: Epoch 109
2025-05-29 15:55:03.601359: Current learning rate: 0.00666
2025-05-29 15:59:47.498673: train_loss -1.0703
2025-05-29 15:59:47.498976: val_loss -0.7566
2025-05-29 15:59:47.499097: Pseudo dice [0.9243, 0.7588, 0.4415, 0.7145, 0.2127, 0.9208, 0.5631, 0.7962]
2025-05-29 15:38:18.890932: Current learning rate: 0.00725
2025-05-29 15:39:36.549915: train_loss -0.975
2025-05-29 15:39:36.550109: val_loss -0.6025
2025-05-29 15:39:36.550229: Pseudo dice [0.9197, 0.6451, 0.4622, 0.6095, 0.1036, 0.9313, 0.5871, 0.5968]
2025-05-29 15:39:36.550306: Epoch time: 77.66 s
2025-05-29 15:39:36.550359: Yayy! New best EMA pseudo Dice: 0.5978
2025-05-29 15:39:39.219045: 
2025-05-29 15:39:39.219414: Epoch 91
2025-05-29 15:39:39.219548: Current learning rate: 0.00722
2025-05-29 15:40:57.402574: train_loss -0.8862
2025-05-29 15:40:57.402917: val_loss -0.5148
2025-05-29 15:40:57.403070: Pseudo dice [0.9081, 0.6545, 0.4526, 0.4681, 0.1788, 0.8817, 0.5583, 0.6999]
2025-05-29 15:40:57.403164: Epoch time: 78.18 s
2025-05-29 15:40:57.403216: Yayy! New best EMA pseudo Dice: 0.598
2025-05-29 15:41:00.191067: 
2025-05-29 15:41:00.191388: Epoch 92
2025-05-29 15:41:00.191526: Current learning rate: 0.00719
2025-05-29 15:42:16.346692: train_loss -0.9073
2025-05-29 15:42:16.347147: val_loss -0.692
2025-05-29 15:42:16.347291: Pseudo dice [0.9065, 0.6436, 0.4138, 0.7184, 0.2425, 0.9139, 0.5117, 0.7217]
2025-05-29 15:42:16.347390: Epoch time: 76.16 s
2025-05-29 15:42:16.347445: Yayy! New best EMA pseudo Dice: 0.6016
2025-05-29 15:42:20.192636: 
2025-05-29 15:42:20.192937: Epoch 93
2025-05-29 15:42:20.193096: Current learning rate: 0.00716
2025-05-29 15:43:36.969102: train_loss -0.9369
2025-05-29 15:43:36.969362: val_loss -0.8147
2025-05-29 15:43:36.969488: Pseudo dice [0.9327, 0.669, 0.4502, 0.7799, 0.2412, 0.9195, 0.5949, 0.6474]
2025-05-29 15:43:36.969579: Epoch time: 76.78 s
2025-05-29 15:43:36.969642: Yayy! New best EMA pseudo Dice: 0.6069
2025-05-29 15:43:39.450475: 
2025-05-29 15:43:39.450739: Epoch 94
2025-05-29 15:43:39.450915: Current learning rate: 0.00713
2025-05-29 15:44:55.929458: train_loss -1.0038
2025-05-29 15:44:55.929674: val_loss -0.7084
2025-05-29 15:44:55.929807: Pseudo dice [0.9161, 0.6737, 0.3987, 0.6872, 0.3051, 0.9183, 0.6054, 0.7765]
2025-05-29 15:44:55.929916: Epoch time: 76.48 s
2025-05-29 15:44:55.929989: Yayy! New best EMA pseudo Dice: 0.6122
2025-05-29 15:44:58.739148: 
2025-05-29 15:44:58.739644: Epoch 95
2025-05-29 15:44:58.739763: Current learning rate: 0.0071
2025-05-29 15:46:13.473415: train_loss -1.0033
2025-05-29 15:46:13.473743: val_loss -0.6609
2025-05-29 15:46:13.473867: Pseudo dice [0.9191, 0.6601, 0.4343, 0.6916, 0.2639, 0.9074, 0.6023, 0.7177]
2025-05-29 15:46:13.473950: Epoch time: 74.74 s
2025-05-29 15:46:13.474011: Yayy! New best EMA pseudo Dice: 0.616
2025-05-29 15:46:16.080596: 
2025-05-29 15:46:16.080948: Epoch 96
2025-05-29 15:46:16.081052: Current learning rate: 0.00707
2025-05-29 15:47:35.127311: train_loss -1.0228
2025-05-29 15:47:35.127692: val_loss -0.6707
2025-05-29 15:47:35.127915: Pseudo dice [0.9119, 0.7059, 0.4569, 0.6567, 0.093, 0.9245, 0.6392, 0.6336]
2025-05-29 15:47:35.128109: Epoch time: 79.05 s
2025-05-29 15:47:35.128225: Yayy! New best EMA pseudo Dice: 0.6171
2025-05-29 15:47:37.768677: 
2025-05-29 15:47:37.769018: Epoch 97
2025-05-29 15:47:37.769126: Current learning rate: 0.00704
2025-05-29 15:48:53.917151: train_loss -0.998
2025-05-29 15:48:53.917398: val_loss -0.6659
2025-05-29 15:48:53.917532: Pseudo dice [0.9086, 0.6529, 0.3838, 0.6458, 0.2663, 0.9177, 0.5929, 0.6915]
2025-05-29 15:48:53.917623: Epoch time: 76.15 s
2025-05-29 15:48:53.917675: Yayy! New best EMA pseudo Dice: 0.6187
2025-05-29 15:48:56.525706: 
2025-05-29 15:48:56.526011: Epoch 98
2025-05-29 15:48:56.526112: Current learning rate: 0.007
2025-05-29 15:50:12.198585: train_loss -0.9739
2025-05-29 15:50:12.198879: val_loss -0.6606
2025-05-29 15:50:12.199000: Pseudo dice [0.93, 0.6216, 0.4048, 0.679, 0.2215, 0.926, 0.6025, 0.7467]
2025-05-29 15:50:12.199088: Epoch time: 75.67 s
2025-05-29 15:50:12.199147: Yayy! New best EMA pseudo Dice: 0.621
2025-05-29 15:50:14.438954: 
2025-05-29 15:50:14.439229: Epoch 99
2025-05-29 15:50:14.439329: Current learning rate: 0.00697
2025-05-29 15:51:27.991275: train_loss -0.9588
2025-05-29 15:51:27.991569: val_loss -0.6409
2025-05-29 15:51:27.991733: Pseudo dice [0.9125, 0.6937, 0.409, 0.6081, 0.0718, 0.9078, 0.6139, 0.6979]
2025-05-29 15:51:27.991839: Epoch time: 73.55 s
2025-05-29 15:51:30.457046: 
2025-05-29 15:51:30.457218: Epoch 100
2025-05-29 15:51:30.457317: Current learning rate: 0.00694
2025-05-29 15:52:44.875985: train_loss -0.9784
2025-05-29 15:52:44.876242: val_loss -0.5811
2025-05-29 15:52:44.876472: Pseudo dice [0.9068, 0.6722, 0.3746, 0.5992, 0.1908, 0.9271, 0.6061, 0.6492]
2025-05-29 15:52:44.876576: Epoch time: 74.42 s
2025-05-29 15:52:46.508669: 
2025-05-29 15:52:46.509112: Epoch 101
2025-05-29 15:52:46.509586: Current learning rate: 0.00691
2025-05-29 15:54:00.665442: train_loss -1.0425
2025-05-29 15:54:00.665683: val_loss -0.6489
2025-05-29 15:54:00.665899: Pseudo dice [0.9153, 0.6847, 0.4302, 0.6699, 0.2047, 0.9029, 0.5843, 0.6994]
2025-05-29 15:54:00.666025: Epoch time: 74.16 s
2025-05-29 15:54:00.666131: Yayy! New best EMA pseudo Dice: 0.6215
2025-05-29 15:54:03.544393: 
2025-05-29 15:54:03.544747: Epoch 102
2025-05-29 15:54:03.544861: Current learning rate: 0.00688
2025-05-29 15:55:18.393247: train_loss -0.9981
2025-05-29 15:55:18.393802: val_loss -0.6874
2025-05-29 15:55:18.393999: Pseudo dice [0.9152, 0.6589, 0.4422, 0.6512, 0.086, 0.9004, 0.5621, 0.7368]
2025-05-29 15:55:18.394092: Epoch time: 74.85 s
2025-05-29 15:55:19.867826: 
2025-05-29 15:55:19.868080: Epoch 103
2025-05-29 15:55:19.868263: Current learning rate: 0.00685
2025-05-29 16:00:58.465868: train_loss -0.9142
2025-05-29 16:00:58.466278: val_loss -0.6767
2025-05-29 16:00:58.466412: Pseudo dice [0.9034, 0.6722, 0.4208, 0.6457, 0.2469, 0.8922, 0.5946, 0.6523]
2025-05-29 16:00:58.466509: Epoch time: 338.6 s
2025-05-29 16:00:58.466573: Yayy! New best EMA pseudo Dice: 0.622
2025-05-29 16:01:01.955290: 
2025-05-29 16:01:01.955696: Epoch 104
2025-05-29 16:01:01.955842: Current learning rate: 0.00682
2025-05-29 16:05:00.145026: train_loss -0.9873
2025-05-29 16:05:00.145334: val_loss -0.7079
2025-05-29 16:05:00.145464: Pseudo dice [0.9162, 0.704, 0.3336, 0.7449, 0.0963, 0.9133, 0.6125, 0.7271]
2025-05-29 16:05:00.145555: Epoch time: 238.19 s
2025-05-29 16:05:00.145616: Yayy! New best EMA pseudo Dice: 0.6229
2025-05-29 16:05:02.933496: 
2025-05-29 16:05:02.933752: Epoch 105
2025-05-29 16:05:02.933853: Current learning rate: 0.00679
2025-05-29 16:10:18.580874: train_loss -0.9888
2025-05-29 16:10:18.581161: val_loss -0.6921
2025-05-29 16:10:18.581356: Pseudo dice [0.9136, 0.6501, 0.4114, 0.761, 0.2244, 0.9062, 0.5959, 0.6292]
2025-05-29 16:10:18.581458: Epoch time: 315.65 s
2025-05-29 16:10:18.581522: Yayy! New best EMA pseudo Dice: 0.6242
2025-05-29 16:10:21.324611: 
2025-05-29 16:10:21.325039: Epoch 106
2025-05-29 16:10:21.325142: Current learning rate: 0.00675
2025-05-29 16:15:17.026530: train_loss -1.0062
2025-05-29 16:15:17.027063: val_loss -0.6705
2025-05-29 16:15:17.027380: Pseudo dice [0.927, 0.7253, 0.3175, 0.7294, 0.0659, 0.9042, 0.62, 0.7352]
2025-05-29 16:15:17.027582: Epoch time: 295.7 s
2025-05-29 16:15:17.027737: Yayy! New best EMA pseudo Dice: 0.6246
2025-05-29 16:15:19.569063: 
2025-05-29 16:15:19.569273: Epoch 107
2025-05-29 16:15:19.569368: Current learning rate: 0.00672
2025-05-29 16:20:20.608247: train_loss -1.0356
2025-05-29 16:20:20.608542: val_loss -0.7018
2025-05-29 16:20:20.608674: Pseudo dice [0.9276, 0.7325, 0.3899, 0.6976, 0.2469, 0.917, 0.6139, 0.7917]
2025-05-29 16:20:20.608771: Epoch time: 301.04 s
2025-05-29 16:20:20.608825: Yayy! New best EMA pseudo Dice: 0.6286
2025-05-29 16:20:23.388525: 
2025-05-29 16:20:23.388841: Epoch 108
2025-05-29 16:20:23.389010: Current learning rate: 0.00669
2025-05-29 16:26:02.361136: train_loss -1.0346
2025-05-29 16:26:02.361516: val_loss -0.6777
2025-05-29 16:26:02.361725: Pseudo dice [0.9208, 0.6917, 0.4116, 0.6534, 0.2397, 0.8938, 0.584, 0.6771]
2025-05-29 16:26:02.361900: Epoch time: 338.97 s
2025-05-29 16:26:02.362168: Yayy! New best EMA pseudo Dice: 0.6292
2025-05-29 16:26:05.471047: 
2025-05-29 16:26:05.471349: Epoch 109
2025-05-29 16:26:05.471496: Current learning rate: 0.00666
2025-05-29 16:31:11.222814: train_loss -1.043 val_loss -0.5881
2025-05-29 15:53:40.306501: Pseudo dice [0.9089, 0.7219, 0.4339, 0.6161, 0.1826, 0.9206, 0.5798, 0.6643]
2025-05-29 15:53:40.306622: Epoch time: 30.93 s
2025-05-29 15:53:41.675818: 
2025-05-29 15:53:41.676026: Epoch 240
2025-05-29 15:53:41.676128: Current learning rate: 0.00235
2025-05-29 15:54:12.475211: train_loss -1.2794
2025-05-29 15:54:12.475492: val_loss -0.5655
2025-05-29 15:54:12.475609: Pseudo dice [0.9143, 0.7233, 0.4407, 0.6105, 0.0895, 0.9251, 0.5598, 0.6597]
2025-05-29 15:54:12.475695: Epoch time: 30.8 s
2025-05-29 15:54:13.817538: 
2025-05-29 15:54:13.817877: Epoch 241
2025-05-29 15:54:13.817985: Current learning rate: 0.00231
2025-05-29 15:54:45.185497: train_loss -1.2855
2025-05-29 15:54:45.185750: val_loss -0.5164
2025-05-29 15:54:45.185906: Pseudo dice [0.9025, 0.7299, 0.3907, 0.5799, 0.1041, 0.9321, 0.5433, 0.6316]
2025-05-29 15:54:45.185995: Epoch time: 31.37 s
2025-05-29 15:54:46.632687: 
2025-05-29 15:54:46.633004: Epoch 242
2025-05-29 15:54:46.633137: Current learning rate: 0.00228
2025-05-29 15:55:18.665993: train_loss -1.2744
2025-05-29 15:55:18.666239: val_loss -0.5697
2025-05-29 15:55:18.666355: Pseudo dice [0.9051, 0.6962, 0.4276, 0.6413, 0.1456, 0.9362, 0.5622, 0.6455]
2025-05-29 15:55:18.666502: Epoch time: 32.03 s
2025-05-29 15:55:20.521399: 
2025-05-29 15:55:20.521820: Epoch 243
2025-05-29 15:55:20.521924: Current learning rate: 0.00224
2025-05-29 15:58:45.411801: train_loss -1.2582
2025-05-29 15:58:45.412095: val_loss -0.6578
2025-05-29 15:58:45.412216: Pseudo dice [0.9034, 0.6953, 0.403, 0.6922, 0.1795, 0.9362, 0.5948, 0.6083]
2025-05-29 15:58:45.412302: Epoch time: 204.89 s
2025-05-29 15:58:46.766452: 
2025-05-29 15:58:46.766663: Epoch 244
2025-05-29 15:58:46.766765: Current learning rate: 0.00221
2025-05-29 16:01:58.294979: train_loss -1.2689
2025-05-29 16:01:58.295217: val_loss -0.589
2025-05-29 16:01:58.295551: Pseudo dice [0.9053, 0.7203, 0.3829, 0.5971, 0.0901, 0.9235, 0.5879, 0.6668]
2025-05-29 16:01:58.295662: Epoch time: 191.53 s
2025-05-29 16:01:59.691708: 
2025-05-29 16:01:59.691922: Epoch 245
2025-05-29 16:01:59.692043: Current learning rate: 0.00217
2025-05-29 16:04:34.980113: train_loss -1.2828
2025-05-29 16:04:34.980495: val_loss -0.5851
2025-05-29 16:04:34.980658: Pseudo dice [0.9049, 0.7499, 0.4272, 0.6272, 0.0812, 0.9333, 0.5831, 0.6625]
2025-05-29 16:04:34.980746: Epoch time: 155.29 s
2025-05-29 16:04:36.367532: 
2025-05-29 16:04:36.367857: Epoch 246
2025-05-29 16:04:36.368048: Current learning rate: 0.00214
2025-05-29 16:08:05.419128: train_loss -1.2861
2025-05-29 16:08:05.419368: val_loss -0.6495
2025-05-29 16:08:05.419494: Pseudo dice [0.9156, 0.7348, 0.4026, 0.664, 0.1381, 0.9418, 0.5927, 0.685]
2025-05-29 16:08:05.419581: Epoch time: 209.05 s
2025-05-29 16:08:07.437075: 
2025-05-29 16:08:07.437395: Epoch 247
2025-05-29 16:08:07.437546: Current learning rate: 0.0021
2025-05-29 16:10:35.131868: train_loss -1.2743
2025-05-29 16:10:35.132211: val_loss -0.5637
2025-05-29 16:10:35.132334: Pseudo dice [0.9125, 0.7341, 0.4345, 0.5779, 0.1326, 0.931, 0.5613, 0.6834]
2025-05-29 16:10:35.132430: Epoch time: 147.7 s
2025-05-29 16:10:36.510065: 
2025-05-29 16:10:36.510457: Epoch 248
2025-05-29 16:10:36.510636: Current learning rate: 0.00207
2025-05-29 16:13:29.945097: train_loss -1.2821
2025-05-29 16:13:29.945393: val_loss -0.6229
2025-05-29 16:13:29.945551: Pseudo dice [0.9032, 0.7296, 0.4227, 0.6618, 0.1137, 0.9245, 0.56, 0.6574]
2025-05-29 16:13:29.945706: Epoch time: 173.44 s
2025-05-29 16:13:31.333809: 
2025-05-29 16:13:31.334190: Epoch 249
2025-05-29 16:13:31.334305: Current learning rate: 0.00203
2025-05-29 16:16:24.192621: train_loss -1.2767
2025-05-29 16:16:24.192908: val_loss -0.5185
2025-05-29 16:16:24.193036: Pseudo dice [0.9059, 0.7089, 0.4738, 0.5968, 0.0912, 0.9289, 0.5956, 0.5997]
2025-05-29 16:16:24.193124: Epoch time: 172.86 s
2025-05-29 16:16:27.057018: 
2025-05-29 16:16:27.057389: Epoch 250
2025-05-29 16:16:27.057561: Current learning rate: 0.00199
2025-05-29 16:19:45.510384: train_loss -1.2667
2025-05-29 16:19:45.511255: val_loss -0.5442
2025-05-29 16:19:45.511480: Pseudo dice [0.9061, 0.7029, 0.4707, 0.5414, 0.1742, 0.9445, 0.5519, 0.641]
2025-05-29 16:19:45.511664: Epoch time: 198.45 s
2025-05-29 16:19:47.030353: 
2025-05-29 16:19:47.030716: Epoch 251
2025-05-29 16:19:47.030833: Current learning rate: 0.00196
2025-05-29 16:22:59.542210: train_loss -1.2832
2025-05-29 16:22:59.543054: val_loss -0.4767
2025-05-29 16:22:59.543260: Pseudo dice [0.903, 0.6969, 0.3826, 0.5437, 0.081, 0.8987, 0.55, 0.6174]
2025-05-29 16:22:59.543524: Epoch time: 192.51 s
2025-05-29 16:23:00.965202: 
2025-05-29 16:23:00.965760: Epoch 252
2025-05-29 16:23:00.966006: Current learning rate: 0.00192
2025-05-29 16:26:16.828652: train_loss -1.2714
2025-05-29 16:26:16.829155: val_loss -0.4948
2025-05-29 16:26:16.829278: Pseudo dice [0.8961, 0.711, 0.3908, 0.5584, 0.0911, 0.9183, 0.5878, 0.6341]
2025-05-29 16:26:16.829368: Epoch time: 195.87 s
2025-05-29 16:26:18.222675: 
2025-05-29 16:26:18.222914: Epoch 253
2025-05-29 16:26:18.223098: Current learning rate: 0.00189
2025-05-29 16:29:26.005661: train_loss -1.2857
2025-05-29 16:29:26.005883: val_loss -0.6155
2025-05-29 16:29:26.006001: Pseudo dice [0.8948, 0.7015, 0.4473, 0.7026, 0.1707, 0.9456, 0.5771, 0.6484]
2025-05-29 16:29:26.006110: Epoch time: 187.78 s
2025-05-29 16:29:27.398285: 
2025-05-29 16:29:27.398525: Epoch 254
2025-05-29 16:29:27.398659: Current learning rate: 0.00185
2025-05-29 16:32:18.774039: train_loss -1.2809
2025-05-29 16:32:18.774276: val_loss -0.5648
2025-05-29 16:32:18.774398: Pseudo dice [0.9067, 0.7116, 0.3964, 0.6267, 0.0949, 0.9096, 0.577, 0.6806]
2025-05-29 16:32:18.774561: Epoch time: 171.38 s
2025-05-29 16:32:20.143069: 
2025-05-29 16:32:20.143257: Epoch 255
2025-05-29 16:32:20.143352: Current learning rate: 0.00181
2025-05-29 16:34:59.407377: train_loss -1.2778
2025-05-29 16:34:59.407616: val_loss -0.5791
2025-05-29 16:34:59.407757: Pseudo dice [0.9053, 0.7389, 0.4204, 0.6198, 0.1558, 0.9136, 0.6157, 0.6787]
2025-05-29 16:34:59.407858: Epoch time: 159.27 s
2025-05-29 16:35:00.804917: 
2025-05-29 16:35:00.805301: Epoch 256
2025-05-29 16:35:00.805403: Current learning rate: 0.00178
2025-05-29 16:37:37.335933: train_loss -1.2954
2025-05-29 16:37:37.336209: val_loss -0.5727
2025-05-29 16:37:37.336328: Pseudo dice [0.9175, 0.704, 0.427, 0.6552, 0.1934, 0.9312, 0.6036, 0.6576]
2025-05-29 16:37:37.336428: Epoch time: 156.53 s
2025-05-29 16:37:38.678410: 
2025-05-29 16:37:38.678693: Epoch 257
2025-05-29 16:37:38.678792: Current learning rate: 0.00174
2025-05-29 17:03:48.042631: train_loss -1.264
2025-05-29 17:03:48.042899: val_loss -0.5958
2025-05-29 17:03:48.043009: Pseudo dice [0.9034, 0.7177, 0.4178, 0.6611, 0.1329, 0.9403, 0.5728, 0.6537]
2025-05-29 17:03:48.043093: Epoch time: 1569.37 s
2025-05-29 17:03:49.408781: 
2025-05-29 17:03:49.409118: Epoch 258
2025-05-29 17:03:49.409257: Current learning rate: 0.0017
2025-05-29 17:11:01.898531: train_loss -1.275
2025-05-29 17:11:01.898756: val_loss -0.6271
2025-05-29 17:11:01.898872: Pseudo dice [0.9222, 0.7142, 0.4402, 0.658, 0.1498, 0.9302, 0.5968, 0.7302]
2025-05-29 17:11:01.898962: Epoch time: 432.49 s
2025-05-29 17:11:03.285775: 
2025-05-29 17:11:03.286215: Epoch 259
2025-05-29 17:11:03.286319: Current learning rate: 0.00167
2025-05-29 17:11:34.724386: train_loss -1.2838
2025-05-29 17:11:34.724638: val_loss -0.4753
2025-05-29 17:11:34.724756: Pseudo dice [0.9016, 0.6775, 0.467, 0.4981, 0.2406, 0.8931, 0.5793, 0.6928]
2025-05-29 17:11:34.724840: Epoch time: 31.44 s
2025-05-29 17:11:36.162548: 
2025-05-29 17:11:36.162844: Epoch 260
2025-05-29 17:11:36.163017: Current learning rate: 0.00163
2025-05-29 17:14:54.981548: train_loss -1.2867
2025-05-29 17:14:54.981788: val_loss -0.5387
2025-05-29 17:14:54.981902: Pseudo dice [0.9098, 0.7069, 0.4044, 0.6267, 0.1228, 0.9359, 0.5736, 0.6318]
2025-05-29 17:14:54.981990: Epoch time: 198.82 s
2025-05-29 17:14:56.357780: 
2025-05-29 17:14:56.358094: Epoch 261
2025-05-29 17:14:56.358240: Current learning rate: 0.00159
2025-05-29 17:19:09.718401: train_loss -1.2976
2025-05-29 17:19:09.718689: val_loss -0.5648
2025-05-29 17:19:09.718815: Epoch 90
2025-05-29 15:51:19.712874: Current learning rate: 0.00725
2025-05-29 15:52:46.972281: train_loss -0.9093
2025-05-29 15:52:46.972633: val_loss -0.688
2025-05-29 15:52:46.972748: Pseudo dice [0.8932, 0.5929, 0.397, 0.7535, 0.0751, 0.7748, 0.4842, 0.7539]
2025-05-29 15:52:46.972842: Epoch time: 87.26 s
2025-05-29 15:52:46.972890: Yayy! New best EMA pseudo Dice: 0.5595
2025-05-29 15:52:49.544249: 
2025-05-29 15:52:49.544445: Epoch 91
2025-05-29 15:52:49.544572: Current learning rate: 0.00722
2025-05-29 15:54:15.099667: train_loss -0.9509
2025-05-29 15:54:15.100461: val_loss -0.552
2025-05-29 15:54:15.100630: Pseudo dice [0.8971, 0.6151, 0.4033, 0.5465, 0.043, 0.8114, 0.4847, 0.8223]
2025-05-29 15:54:15.100802: Epoch time: 85.56 s
2025-05-29 15:54:15.100938: Yayy! New best EMA pseudo Dice: 0.5614
2025-05-29 15:54:17.629569: 
2025-05-29 15:54:17.630365: Epoch 92
2025-05-29 15:54:17.630990: Current learning rate: 0.00719
2025-05-29 15:57:16.110224: train_loss -0.9686
2025-05-29 15:57:16.110584: val_loss -0.649
2025-05-29 15:57:16.110799: Pseudo dice [0.9146, 0.6601, 0.4117, 0.6859, 0.0517, 0.8358, 0.4496, 0.7807]
2025-05-29 15:57:16.110885: Epoch time: 178.48 s
2025-05-29 15:57:16.110934: Yayy! New best EMA pseudo Dice: 0.5651
2025-05-29 15:57:18.826001: 
2025-05-29 15:57:18.826367: Epoch 93
2025-05-29 15:57:18.826484: Current learning rate: 0.00716
2025-05-29 16:03:13.735712: train_loss -0.972
2025-05-29 16:03:13.735936: val_loss -0.616
2025-05-29 16:03:13.736053: Pseudo dice [0.9062, 0.5933, 0.3922, 0.6106, 0.0823, 0.8357, 0.4962, 0.7939]
2025-05-29 16:03:13.736197: Epoch time: 354.91 s
2025-05-29 16:03:13.736288: Yayy! New best EMA pseudo Dice: 0.5675
2025-05-29 16:03:16.546849: 
2025-05-29 16:03:16.547169: Epoch 94
2025-05-29 16:03:16.547295: Current learning rate: 0.00713
2025-05-29 16:09:19.269824: train_loss -0.9883
2025-05-29 16:09:19.270062: val_loss -0.7073
2025-05-29 16:09:19.270183: Pseudo dice [0.8959, 0.6474, 0.4527, 0.6925, 0.0684, 0.8017, 0.5165, 0.7655]
2025-05-29 16:09:19.270285: Epoch time: 362.72 s
2025-05-29 16:09:19.270344: Yayy! New best EMA pseudo Dice: 0.5713
2025-05-29 16:09:22.108387: 
2025-05-29 16:09:22.108657: Epoch 95
2025-05-29 16:09:22.108830: Current learning rate: 0.0071
2025-05-29 16:15:15.977341: train_loss -0.9997
2025-05-29 16:15:15.977687: val_loss -0.6698
2025-05-29 16:15:15.977843: Pseudo dice [0.9009, 0.607, 0.406, 0.716, 0.074, 0.781, 0.495, 0.7295]
2025-05-29 16:15:15.977996: Epoch time: 353.87 s
2025-05-29 16:15:15.978087: Yayy! New best EMA pseudo Dice: 0.573
2025-05-29 16:15:18.812365: 
2025-05-29 16:15:18.812753: Epoch 96
2025-05-29 16:15:18.812977: Current learning rate: 0.00707
2025-05-29 16:21:13.181593: train_loss -0.9887
2025-05-29 16:21:13.181812: val_loss -0.4896
2025-05-29 16:21:13.181926: Pseudo dice [0.8802, 0.569, 0.4209, 0.4977, 0.0432, 0.8503, 0.4566, 0.7328]
2025-05-29 16:21:13.182018: Epoch time: 354.37 s
2025-05-29 16:21:14.547961: 
2025-05-29 16:21:14.548238: Epoch 97
2025-05-29 16:21:14.548499: Current learning rate: 0.00704
2025-05-29 16:27:59.754108: train_loss -0.9871
2025-05-29 16:27:59.754322: val_loss -0.6261
2025-05-29 16:27:59.754435: Pseudo dice [0.8975, 0.5923, 0.4133, 0.64, 0.0542, 0.8452, 0.5046, 0.7423]
2025-05-29 16:27:59.754532: Epoch time: 405.21 s
2025-05-29 16:28:01.083533: 
2025-05-29 16:28:01.083822: Epoch 98
2025-05-29 16:28:01.083912: Current learning rate: 0.007
2025-05-29 16:33:32.186093: train_loss -0.936
2025-05-29 16:33:32.186377: val_loss -0.6836
2025-05-29 16:33:32.186523: Pseudo dice [0.8781, 0.5956, 0.3629, 0.718, 0.0695, 0.8211, 0.545, 0.6944]
2025-05-29 16:33:32.186630: Epoch time: 331.1 s
2025-05-29 16:33:32.186682: Yayy! New best EMA pseudo Dice: 0.5741
2025-05-29 16:33:35.224166: 
2025-05-29 16:33:35.224588: Epoch 99
2025-05-29 16:33:35.224694: Current learning rate: 0.00697
2025-05-29 16:37:56.674468: train_loss -0.9335
2025-05-29 16:37:56.674743: val_loss -0.6715
2025-05-29 16:37:56.674860: Pseudo dice [0.896, 0.6153, 0.3755, 0.7039, 0.0211, 0.8352, 0.4788, 0.7865]
2025-05-29 16:37:56.674947: Epoch time: 261.45 s
2025-05-29 16:37:58.151219: Yayy! New best EMA pseudo Dice: 0.5756
2025-05-29 16:38:00.880119: 
2025-05-29 16:38:00.880485: Epoch 100
2025-05-29 16:38:00.880625: Current learning rate: 0.00694
2025-05-29 17:10:50.847296: train_loss -0.9615
2025-05-29 17:10:50.847589: val_loss -0.6567
2025-05-29 17:10:50.847714: Pseudo dice [0.8913, 0.6285, 0.4033, 0.7036, 0.0696, 0.8469, 0.4716, 0.7216]
2025-05-29 17:10:50.847814: Epoch time: 1969.97 s
2025-05-29 17:10:50.847865: Yayy! New best EMA pseudo Dice: 0.5772
2025-05-29 17:10:53.598124: 
2025-05-29 17:10:53.598425: Epoch 101
2025-05-29 17:10:53.598574: Current learning rate: 0.00691
2025-05-29 17:15:20.002937: train_loss -0.9878
2025-05-29 17:15:20.003171: val_loss -0.6655
2025-05-29 17:15:20.003291: Pseudo dice [0.8988, 0.6556, 0.4414, 0.652, 0.0467, 0.8457, 0.4414, 0.7849]
2025-05-29 17:15:20.003391: Epoch time: 266.41 s
2025-05-29 17:15:20.003477: Yayy! New best EMA pseudo Dice: 0.5791
2025-05-29 17:15:22.934125: 
2025-05-29 17:15:22.934370: Epoch 102
2025-05-29 17:15:22.934608: Current learning rate: 0.00688
2025-05-29 17:20:22.714332: train_loss -0.9684
2025-05-29 17:20:22.714658: val_loss -0.6076
2025-05-29 17:20:22.714895: Pseudo dice [0.8938, 0.6267, 0.3876, 0.6212, 0.0278, 0.8568, 0.3771, 0.8047]
2025-05-29 17:20:22.714975: Epoch time: 299.78 s
2025-05-29 17:20:24.066533: 
2025-05-29 17:20:24.066944: Epoch 103
2025-05-29 17:20:24.067175: Current learning rate: 0.00685
2025-05-29 17:25:25.296556: train_loss -1.0049
2025-05-29 17:25:25.296832: val_loss -0.6702
2025-05-29 17:25:25.296948: Pseudo dice [0.8996, 0.6237, 0.4624, 0.716, 0.0712, 0.8438, 0.4795, 0.7707]
2025-05-29 17:25:25.297036: Epoch time: 301.23 s
2025-05-29 17:25:25.297137: Yayy! New best EMA pseudo Dice: 0.5816
2025-05-29 17:25:28.051355: 
2025-05-29 17:25:28.051585: Epoch 104
2025-05-29 17:25:28.051694: Current learning rate: 0.00682
2025-05-29 17:26:58.060816: train_loss -1.0038
2025-05-29 17:26:58.061049: val_loss -0.7212
2025-05-29 17:26:58.061168: Pseudo dice [0.9148, 0.5985, 0.4539, 0.7642, 0.1215, 0.8506, 0.4359, 0.8018]
2025-05-29 17:26:58.061260: Epoch time: 90.01 s
2025-05-29 17:26:58.061312: Yayy! New best EMA pseudo Dice: 0.5852
2025-05-29 17:27:00.869498: 
2025-05-29 17:27:00.869880: Epoch 105
2025-05-29 17:27:00.869988: Current learning rate: 0.00679
2025-05-29 17:28:35.851323: train_loss -1.0118
2025-05-29 17:28:35.852444: val_loss -0.5974
2025-05-29 17:28:35.852667: Pseudo dice [0.8899, 0.5573, 0.4541, 0.6518, 0.0228, 0.8483, 0.4544, 0.7475]
2025-05-29 17:28:35.852953: Epoch time: 94.98 s
2025-05-29 17:28:37.307273: 
2025-05-29 17:28:37.307848: Epoch 106
2025-05-29 17:28:37.308036: Current learning rate: 0.00675
2025-05-29 17:30:05.674032: train_loss -1.0024
2025-05-29 17:30:05.674805: val_loss -0.6823
2025-05-29 17:30:05.675054: Pseudo dice [0.8989, 0.6356, 0.4099, 0.693, 0.0257, 0.8528, 0.5051, 0.7695]
2025-05-29 17:30:05.675357: Epoch time: 88.37 s
2025-05-29 17:30:05.675422: Yayy! New best EMA pseudo Dice: 0.5859
2025-05-29 17:30:08.655589: 
2025-05-29 17:30:08.655780: Epoch 107
2025-05-29 17:30:08.655878: Current learning rate: 0.00672
2025-05-29 17:32:00.730782: train_loss -0.9793
2025-05-29 17:32:00.731267: val_loss -0.5745
2025-05-29 17:32:00.731378: Pseudo dice [0.8788, 0.6344, 0.4177, 0.5995, 0.0138, 0.8333, 0.5191, 0.7568]
2025-05-29 17:32:00.731475: Epoch time: 112.08 s
2025-05-29 17:32:02.181873: 
2025-05-29 17:32:02.182240: Epoch 108
2025-05-29 17:32:02.182342: Current learning rate: 0.00669
2025-05-29 17:33:22.417383: train_loss -1.008
2025-05-29 17:33:22.417773: val_loss -0.7142
2025-05-29 17:33:22.417893: Pseudo dice [0.8913, 0.6406, 0.4222, 0.7547, 0.0516, 0.8758, 0.4733, 0.7531]
2025-05-29 17:33:22.417996: Epoch time: 80.24 s
2025-05-29 17:33:22.418045: Yayy! New best EMA pseudo Dice: 0.5877
2025-05-29 17:33:25.292981: 
2025-05-29 17:33:25.293319: Epoch 109
2025-05-29 17:33:25.293500: Current learning rate: 0.00666
2025-05-29 17:34:52.997692: train_loss -1.0327
2025-05-29 17:34:52.998057: val_loss -0.7033
2025-05-29 17:34:52.998193: Pseudo dice [0.8928, 0.6275, 0.4442, 0.709, 0.1193, 0.8633, 0.501, 0.7812]
2025-05-29 15:59:47.499573: Epoch time: 283.9 s
2025-05-29 15:59:47.499641: Yayy! New best EMA pseudo Dice: 0.6287
2025-05-29 15:59:50.015909: 
2025-05-29 15:59:50.016260: Epoch 110
2025-05-29 15:59:50.016387: Current learning rate: 0.00663
2025-05-29 16:04:05.934428: train_loss -1.1036
2025-05-29 16:04:05.934703: val_loss -0.6434
2025-05-29 16:04:05.934860: Pseudo dice [0.9218, 0.7076, 0.4271, 0.5998, 0.1684, 0.9244, 0.5405, 0.7727]
2025-05-29 16:04:05.934947: Epoch time: 255.92 s
2025-05-29 16:04:05.935009: Yayy! New best EMA pseudo Dice: 0.6291
2025-05-29 16:04:08.573628: 
2025-05-29 16:04:08.573950: Epoch 111
2025-05-29 16:04:08.574050: Current learning rate: 0.0066
2025-05-29 16:09:05.343234: train_loss -1.0869
2025-05-29 16:09:05.343463: val_loss -0.6017
2025-05-29 16:09:05.343653: Pseudo dice [0.9138, 0.7094, 0.3588, 0.5038, 0.2076, 0.9176, 0.5498, 0.7102]
2025-05-29 16:09:05.343753: Epoch time: 296.77 s
2025-05-29 16:09:06.718633: 
2025-05-29 16:09:06.718927: Epoch 112
2025-05-29 16:09:06.719069: Current learning rate: 0.00657
2025-05-29 16:13:25.461126: train_loss -1.0846
2025-05-29 16:13:25.461459: val_loss -0.6395
2025-05-29 16:13:25.461663: Pseudo dice [0.9208, 0.7003, 0.4689, 0.5961, 0.122, 0.9315, 0.5508, 0.7205]
2025-05-29 16:13:25.461751: Epoch time: 258.74 s
2025-05-29 16:13:26.817314: 
2025-05-29 16:13:26.817612: Epoch 113
2025-05-29 16:13:26.817851: Current learning rate: 0.00654
2025-05-29 16:17:58.117575: train_loss -1.0653
2025-05-29 16:17:58.117860: val_loss -0.7418
2025-05-29 16:17:58.117979: Pseudo dice [0.9102, 0.71, 0.4081, 0.7529, 0.1869, 0.9236, 0.5742, 0.6982]
2025-05-29 16:17:58.118062: Epoch time: 271.3 s
2025-05-29 16:17:59.507871: 
2025-05-29 16:17:59.508141: Epoch 114
2025-05-29 16:17:59.508268: Current learning rate: 0.0065
2025-05-29 16:23:07.265602: train_loss -1.0768
2025-05-29 16:23:07.265801: val_loss -0.6434
2025-05-29 16:23:07.265927: Pseudo dice [0.9044, 0.6766, 0.4224, 0.6766, 0.1481, 0.9328, 0.5331, 0.741]
2025-05-29 16:23:07.266015: Epoch time: 307.76 s
2025-05-29 16:23:08.634516: 
2025-05-29 16:23:08.634809: Epoch 115
2025-05-29 16:23:08.634912: Current learning rate: 0.00647
2025-05-29 16:28:18.642552: train_loss -1.0596
2025-05-29 16:28:18.642788: val_loss -0.5899
2025-05-29 16:28:18.642991: Pseudo dice [0.9114, 0.6946, 0.4315, 0.5959, 0.1255, 0.9177, 0.5926, 0.7013]
2025-05-29 16:28:18.643096: Epoch time: 310.01 s
2025-05-29 16:28:20.053347: 
2025-05-29 16:28:20.053622: Epoch 116
2025-05-29 16:28:20.053736: Current learning rate: 0.00644
2025-05-29 16:33:06.820218: train_loss -1.0641
2025-05-29 16:33:06.820391: val_loss -0.6143
2025-05-29 16:33:06.820514: Pseudo dice [0.9111, 0.7275, 0.3835, 0.5931, 0.2431, 0.9244, 0.5668, 0.712]
2025-05-29 16:33:06.820604: Epoch time: 286.77 s
2025-05-29 16:33:08.897730: 
2025-05-29 16:33:08.897944: Epoch 117
2025-05-29 16:33:08.898062: Current learning rate: 0.00641
2025-05-29 16:37:18.073655: train_loss -1.0758
2025-05-29 16:37:18.073874: val_loss -0.673
2025-05-29 16:37:18.074067: Pseudo dice [0.9191, 0.7477, 0.4477, 0.6762, 0.1727, 0.9146, 0.4615, 0.7071]
2025-05-29 16:37:18.074179: Epoch time: 249.18 s
2025-05-29 16:37:19.447527: 
2025-05-29 16:37:19.447946: Epoch 118
2025-05-29 16:37:19.448042: Current learning rate: 0.00638
2025-05-29 16:53:19.885739: train_loss -1.0945
2025-05-29 16:53:19.886084: val_loss -0.6427
2025-05-29 16:53:19.886245: Pseudo dice [0.9227, 0.7293, 0.4049, 0.5963, 0.1109, 0.926, 0.4639, 0.7271]
2025-05-29 16:53:19.886402: Epoch time: 960.44 s
2025-05-29 16:53:21.260293: 
2025-05-29 16:53:21.260540: Epoch 119
2025-05-29 16:53:21.260684: Current learning rate: 0.00635
2025-05-29 17:11:20.619520: train_loss -1.0938
2025-05-29 17:11:20.619841: val_loss -0.6499
2025-05-29 17:11:20.619958: Pseudo dice [0.8951, 0.7014, 0.4198, 0.6794, 0.068, 0.9494, 0.5527, 0.6898]
2025-05-29 17:11:20.620059: Epoch time: 1079.36 s
2025-05-29 17:11:22.126930: 
2025-05-29 17:11:22.127199: Epoch 120
2025-05-29 17:11:22.127306: Current learning rate: 0.00631
2025-05-29 17:16:12.578999: train_loss -1.0858
2025-05-29 17:16:12.579332: val_loss -0.6758
2025-05-29 17:16:12.579468: Pseudo dice [0.9285, 0.7007, 0.4342, 0.6905, 0.1227, 0.9476, 0.5967, 0.698]
2025-05-29 17:16:12.579564: Epoch time: 290.45 s
2025-05-29 17:16:13.982034: 
2025-05-29 17:16:13.982379: Epoch 121
2025-05-29 17:16:13.982563: Current learning rate: 0.00628
2025-05-29 17:19:59.924912: train_loss -1.1115
2025-05-29 17:19:59.925181: val_loss -0.6754
2025-05-29 17:19:59.925350: Pseudo dice [0.9129, 0.7307, 0.4526, 0.676, 0.2247, 0.9345, 0.5948, 0.7227]
2025-05-29 17:19:59.925459: Epoch time: 225.94 s
2025-05-29 17:19:59.925515: Yayy! New best EMA pseudo Dice: 0.6304
2025-05-29 17:20:02.610573: 
2025-05-29 17:20:02.610831: Epoch 122
2025-05-29 17:20:02.610963: Current learning rate: 0.00625
2025-05-29 17:25:01.931805: train_loss -1.1115
2025-05-29 17:25:01.932051: val_loss -0.5695
2025-05-29 17:25:01.932329: Pseudo dice [0.9134, 0.703, 0.4541, 0.513, 0.2201, 0.9336, 0.5783, 0.7065]
2025-05-29 17:25:01.932441: Epoch time: 299.32 s
2025-05-29 17:25:03.343139: 
2025-05-29 17:25:03.343457: Epoch 123
2025-05-29 17:25:03.343560: Current learning rate: 0.00622
2025-05-29 17:26:15.960969: train_loss -1.12
2025-05-29 17:26:15.961195: val_loss -0.6458
2025-05-29 17:26:15.961309: Pseudo dice [0.9249, 0.7499, 0.4083, 0.6205, 0.1191, 0.9341, 0.5577, 0.7136]
2025-05-29 17:26:15.961392: Epoch time: 72.62 s
2025-05-29 17:26:17.394688: 
2025-05-29 17:26:17.395031: Epoch 124
2025-05-29 17:26:17.395135: Current learning rate: 0.00619
2025-05-29 17:27:38.244325: train_loss -1.1435
2025-05-29 17:27:38.244643: val_loss -0.613
2025-05-29 17:27:38.244861: Pseudo dice [0.9239, 0.7325, 0.4604, 0.5651, 0.0928, 0.9286, 0.587, 0.7843]
2025-05-29 17:27:38.245102: Epoch time: 80.85 s
2025-05-29 17:27:39.745561: 
2025-05-29 17:27:39.745915: Epoch 125
2025-05-29 17:27:39.746011: Current learning rate: 0.00616
2025-05-29 17:28:52.205352: train_loss -1.1304
2025-05-29 17:28:52.205631: val_loss -0.633
2025-05-29 17:28:52.205747: Pseudo dice [0.9179, 0.7174, 0.3798, 0.5925, 0.1647, 0.9322, 0.5763, 0.6766]
2025-05-29 17:28:52.205834: Epoch time: 72.46 s
2025-05-29 17:28:53.727611: 
2025-05-29 17:28:53.728060: Epoch 126
2025-05-29 17:28:53.728161: Current learning rate: 0.00612
2025-05-29 17:30:06.616752: train_loss -1.1002
2025-05-29 17:30:06.617101: val_loss -0.7019
2025-05-29 17:30:06.617215: Pseudo dice [0.9311, 0.7225, 0.3973, 0.6747, 0.2143, 0.9204, 0.5718, 0.7291]
2025-05-29 17:30:06.617305: Epoch time: 72.89 s
2025-05-29 17:30:06.617356: Yayy! New best EMA pseudo Dice: 0.6309
2025-05-29 17:30:09.405972: 
2025-05-29 17:30:09.406259: Epoch 127
2025-05-29 17:30:09.406510: Current learning rate: 0.00609
2025-05-29 17:31:50.842586: train_loss -1.1212
2025-05-29 17:31:50.843063: val_loss -0.705
2025-05-29 17:31:50.843204: Pseudo dice [0.9201, 0.7346, 0.4436, 0.6768, 0.2642, 0.9322, 0.5789, 0.7096]
2025-05-29 17:31:50.843282: Epoch time: 101.44 s
2025-05-29 17:31:50.843334: Yayy! New best EMA pseudo Dice: 0.6336
2025-05-29 17:31:54.188950: 
2025-05-29 17:31:54.189371: Epoch 128
2025-05-29 17:31:54.189486: Current learning rate: 0.00606
2025-05-29 17:33:07.790445: train_loss -1.1396
2025-05-29 17:33:07.790828: val_loss -0.7814
2025-05-29 17:33:07.790970: Pseudo dice [0.9282, 0.7467, 0.4637, 0.7272, 0.1949, 0.9423, 0.5344, 0.7506]
2025-05-29 17:33:07.791051: Epoch time: 73.6 s
2025-05-29 17:33:07.791099: Yayy! New best EMA pseudo Dice: 0.6363
2025-05-29 17:33:10.405889: 
2025-05-29 17:33:10.406219: Epoch 129
2025-05-29 17:33:10.406354: Current learning rate: 0.00603
2025-05-29 17:34:25.300659: train_loss -1.1532
2025-05-29 17:34:25.300976: val_loss -0.6923
2025-05-29 17:34:25.301096: Pseudo dice [0.9146, 0.7448, 0.4246, 0.6963, 0.2414, 0.9229, 0.5333, 0.7023]
2025-05-29 17:34:25.301218: Epoch time: 74.9 s
2025-05-29 17:34:25.301312: Yayy! New best EMA pseudo Dice: 0.6375
2025-05-29 17:34:27.906456: 
2025-05-29 17:34:27.906833: Epoch 130
2025-05-29 17:34:27.906937: Current learning rate: 0.006
2025-05-29 17:35:42.099668: train_loss -1.1416
2025-05-29 17:35:42.099941: val_loss -0.603
2025-05-29 17:35:42.100064: Pseudo dice [0.921, 0.7493, 0.4388, 0.4725, 0.2012, 0.9182, 0.5756, 0.6508] Pseudo dice [0.9183, 0.6892, 0.4271, 0.6051, 0.0935, 0.9466, 0.5615, 0.6673]
2025-05-29 17:19:09.719329: Epoch time: 253.36 s
2025-05-29 17:19:11.120074: 
2025-05-29 17:19:11.120409: Epoch 262
2025-05-29 17:19:11.120532: Current learning rate: 0.00156
2025-05-29 17:19:52.630097: train_loss -1.2768
2025-05-29 17:19:52.630280: val_loss -0.6136
2025-05-29 17:19:52.630394: Pseudo dice [0.9059, 0.6861, 0.4108, 0.6407, 0.1763, 0.9337, 0.5838, 0.6954]
2025-05-29 17:19:52.630501: Epoch time: 41.51 s
2025-05-29 17:19:54.005545: 
2025-05-29 17:19:54.005870: Epoch 263
2025-05-29 17:19:54.006048: Current learning rate: 0.00152
2025-05-29 17:22:28.941023: train_loss -1.2809
2025-05-29 17:22:28.941263: val_loss -0.5351
2025-05-29 17:22:28.941377: Pseudo dice [0.9134, 0.706, 0.4127, 0.5695, 0.3007, 0.9169, 0.5428, 0.6553]
2025-05-29 17:22:28.941526: Epoch time: 154.94 s
2025-05-29 17:22:30.363938: 
2025-05-29 17:22:30.364251: Epoch 264
2025-05-29 17:22:30.364349: Current learning rate: 0.00148
2025-05-29 17:25:06.554384: train_loss -1.2742
2025-05-29 17:25:06.554627: val_loss -0.5876
2025-05-29 17:25:06.554745: Pseudo dice [0.909, 0.7387, 0.4063, 0.6155, 0.1213, 0.9172, 0.571, 0.6621]
2025-05-29 17:25:06.554842: Epoch time: 156.19 s
2025-05-29 17:25:07.916851: 
2025-05-29 17:25:07.917167: Epoch 265
2025-05-29 17:25:07.917258: Current learning rate: 0.00145
2025-05-29 17:25:38.559671: train_loss -1.2924
2025-05-29 17:25:38.559939: val_loss -0.5774
2025-05-29 17:25:38.560054: Pseudo dice [0.9092, 0.7512, 0.3942, 0.6217, 0.152, 0.9221, 0.601, 0.6584]
2025-05-29 17:25:38.560203: Epoch time: 30.64 s
2025-05-29 17:25:39.938278: 
2025-05-29 17:25:39.938515: Epoch 266
2025-05-29 17:25:39.938768: Current learning rate: 0.00141
2025-05-29 17:26:10.695319: train_loss -1.2912
2025-05-29 17:26:10.695579: val_loss -0.5727
2025-05-29 17:26:10.695729: Pseudo dice [0.9086, 0.7176, 0.403, 0.659, 0.1867, 0.934, 0.5979, 0.6626]
2025-05-29 17:26:10.695821: Epoch time: 30.76 s
2025-05-29 17:26:12.061149: 
2025-05-29 17:26:12.061413: Epoch 267
2025-05-29 17:26:12.061558: Current learning rate: 0.00137
2025-05-29 17:26:42.891431: train_loss -1.2942
2025-05-29 17:26:42.891670: val_loss -0.526
2025-05-29 17:26:42.891784: Pseudo dice [0.9077, 0.6944, 0.4671, 0.5604, 0.1424, 0.9402, 0.5689, 0.7107]
2025-05-29 17:26:42.891865: Epoch time: 30.83 s
2025-05-29 17:26:44.271162: 
2025-05-29 17:26:44.271421: Epoch 268
2025-05-29 17:26:44.271584: Current learning rate: 0.00133
2025-05-29 17:27:15.801387: train_loss -1.2908
2025-05-29 17:27:15.801620: val_loss -0.4973
2025-05-29 17:27:15.801847: Pseudo dice [0.9045, 0.7019, 0.4329, 0.5557, 0.1765, 0.9231, 0.5597, 0.6243]
2025-05-29 17:27:15.801948: Epoch time: 31.53 s
2025-05-29 17:27:17.183196: 
2025-05-29 17:27:17.183491: Epoch 269
2025-05-29 17:27:17.183601: Current learning rate: 0.0013
2025-05-29 17:27:56.813396: train_loss -1.2951
2025-05-29 17:27:56.813627: val_loss -0.5241
2025-05-29 17:27:56.813749: Pseudo dice [0.9066, 0.6951, 0.3885, 0.6404, 0.0845, 0.9406, 0.5722, 0.5916]
2025-05-29 17:27:56.813858: Epoch time: 39.63 s
2025-05-29 17:27:58.215510: 
2025-05-29 17:27:58.215779: Epoch 270
2025-05-29 17:27:58.215961: Current learning rate: 0.00126
2025-05-29 17:28:29.125588: train_loss -1.3011
2025-05-29 17:28:29.125845: val_loss -0.6151
2025-05-29 17:28:29.125960: Pseudo dice [0.9077, 0.7038, 0.4283, 0.657, 0.1644, 0.9451, 0.5751, 0.6925]
2025-05-29 17:28:29.126047: Epoch time: 30.91 s
2025-05-29 17:28:30.565952: 
2025-05-29 17:28:30.566347: Epoch 271
2025-05-29 17:28:30.566461: Current learning rate: 0.00122
2025-05-29 17:29:01.261482: train_loss -1.2916
2025-05-29 17:29:01.261710: val_loss -0.5559
2025-05-29 17:29:01.261825: Pseudo dice [0.9067, 0.7132, 0.3733, 0.6207, 0.0905, 0.9354, 0.5673, 0.6176]
2025-05-29 17:29:01.261913: Epoch time: 30.7 s
2025-05-29 17:29:02.624648: 
2025-05-29 17:29:02.624909: Epoch 272
2025-05-29 17:29:02.625011: Current learning rate: 0.00118
2025-05-29 17:29:33.622990: train_loss -1.288
2025-05-29 17:29:33.623212: val_loss -0.5268
2025-05-29 17:29:33.623328: Pseudo dice [0.9069, 0.7307, 0.4175, 0.5556, 0.0609, 0.9364, 0.6049, 0.6766]
2025-05-29 17:29:33.623413: Epoch time: 31.0 s
2025-05-29 17:29:35.001060: 
2025-05-29 17:29:35.001359: Epoch 273
2025-05-29 17:29:35.001487: Current learning rate: 0.00115
2025-05-29 17:30:05.849023: train_loss -1.2858
2025-05-29 17:30:05.849241: val_loss -0.4938
2025-05-29 17:30:05.849372: Pseudo dice [0.8932, 0.7147, 0.4144, 0.5963, 0.1169, 0.9236, 0.5695, 0.6298]
2025-05-29 17:30:05.849469: Epoch time: 30.85 s
2025-05-29 17:30:07.316742: 
2025-05-29 17:30:07.317053: Epoch 274
2025-05-29 17:30:07.317150: Current learning rate: 0.00111
2025-05-29 17:31:16.383743: train_loss -1.2958
2025-05-29 17:31:16.383957: val_loss -0.5649
2025-05-29 17:31:16.384062: Pseudo dice [0.9167, 0.7148, 0.3934, 0.6074, 0.1576, 0.9211, 0.5429, 0.6825]
2025-05-29 17:31:16.384144: Epoch time: 69.07 s
2025-05-29 17:31:17.750352: 
2025-05-29 17:31:17.750778: Epoch 275
2025-05-29 17:31:17.750929: Current learning rate: 0.00107
2025-05-29 17:32:03.314403: train_loss -1.304
2025-05-29 17:32:03.314980: val_loss -0.5305
2025-05-29 17:32:03.315095: Pseudo dice [0.9056, 0.728, 0.4428, 0.5866, 0.1351, 0.9324, 0.5854, 0.5867]
2025-05-29 17:32:03.315219: Epoch time: 45.57 s
2025-05-29 17:32:04.713420: 
2025-05-29 17:32:04.713717: Epoch 276
2025-05-29 17:32:04.713866: Current learning rate: 0.00103
2025-05-29 17:32:35.829528: train_loss -1.2946
2025-05-29 17:32:35.829979: val_loss -0.6021
2025-05-29 17:32:35.830164: Pseudo dice [0.9128, 0.7365, 0.439, 0.6189, 0.1398, 0.9371, 0.5769, 0.6921]
2025-05-29 17:32:35.830273: Epoch time: 31.12 s
2025-05-29 17:32:37.287677: 
2025-05-29 17:32:37.288008: Epoch 277
2025-05-29 17:32:37.288117: Current learning rate: 0.00099
2025-05-29 17:33:08.065602: train_loss -1.2995
2025-05-29 17:33:08.065994: val_loss -0.5554
2025-05-29 17:33:08.066199: Pseudo dice [0.9108, 0.7201, 0.4156, 0.6041, 0.1529, 0.9442, 0.5762, 0.6639]
2025-05-29 17:33:08.066279: Epoch time: 30.78 s
2025-05-29 17:33:09.475474: 
2025-05-29 17:33:09.475765: Epoch 278
2025-05-29 17:33:09.475897: Current learning rate: 0.00095
2025-05-29 17:33:40.319811: train_loss -1.3024
2025-05-29 17:33:40.320014: val_loss -0.555
2025-05-29 17:33:40.320125: Pseudo dice [0.9079, 0.7306, 0.4145, 0.5984, 0.1918, 0.9391, 0.5846, 0.6531]
2025-05-29 17:33:40.320206: Epoch time: 30.85 s
2025-05-29 17:33:41.704330: 
2025-05-29 17:33:41.704643: Epoch 279
2025-05-29 17:33:41.704844: Current learning rate: 0.00091
2025-05-29 17:34:12.492948: train_loss -1.2958
2025-05-29 17:34:12.493138: val_loss -0.5967
2025-05-29 17:34:12.493250: Pseudo dice [0.9124, 0.7174, 0.4178, 0.6557, 0.1147, 0.9341, 0.5895, 0.6472]
2025-05-29 17:34:12.493331: Epoch time: 30.79 s
2025-05-29 17:34:14.507326: 
2025-05-29 17:34:14.507680: Epoch 280
2025-05-29 17:34:14.507780: Current learning rate: 0.00087
2025-05-29 17:34:45.026762: train_loss -1.294
2025-05-29 17:34:45.027070: val_loss -0.5305
2025-05-29 17:34:45.027174: Pseudo dice [0.8993, 0.6934, 0.3955, 0.6582, 0.0728, 0.9231, 0.5209, 0.5875]
2025-05-29 17:34:45.027272: Epoch time: 30.52 s
2025-05-29 17:34:46.410735: 
2025-05-29 17:34:46.410971: Epoch 281
2025-05-29 17:34:46.411066: Current learning rate: 0.00083
2025-05-29 17:35:17.062441: train_loss -1.2868
2025-05-29 17:35:17.062676: val_loss -0.5357
2025-05-29 17:35:17.062888: Pseudo dice [0.9014, 0.6903, 0.4185, 0.6079, 0.1353, 0.9217, 0.5694, 0.6272]
2025-05-29 17:35:17.062975: Epoch time: 30.65 s
2025-05-29 17:35:18.449162: 
2025-05-29 17:35:18.449549: Epoch 282
2025-05-29 17:35:18.449687: Current learning rate: 0.00079
2025-05-29 17:35:49.037535: train_loss -1.3051
2025-05-29 17:35:49.037749: val_loss -0.5022
2025-05-29 17:35:49.037904: Pseudo dice [0.9045, 0.7027, 0.4188, 0.5641, 0.0712, 0.9387, 0.567, 0.649]
2025-05-29 17:35:49.037999: Epoch time: 30.59 s
2025-05-29 17:35:50.436286: 
2025-05-29 17:35:50.436700: Epoch 283
2025-05-29 17:35:50.436810: Current learning rate: 0.00076
2025-05-29 17:36:21.131575: train_loss -1.2933
2025-05-29 17:36:21.131845: val_loss -0.5728
2025-05-29 17:36:21.131963: Pseudo dice [0.9024, 0.7018, 0.4189, 0.6501, 0.1327, 0.9438, 0.5801, 0.6288]
2025-05-29 16:31:11.223511: val_loss -0.6182
2025-05-29 16:31:11.223641: Pseudo dice [0.9154, 0.7018, 0.4085, 0.6128, 0.0971, 0.884, 0.6203, 0.6398]
2025-05-29 16:31:11.223726: Epoch time: 305.75 s
2025-05-29 16:31:12.651641: 
2025-05-29 16:31:12.651955: Epoch 110
2025-05-29 16:31:12.652062: Current learning rate: 0.00663
2025-05-29 16:35:35.089182: train_loss -0.988
2025-05-29 16:35:35.089631: val_loss -0.6005
2025-05-29 16:35:35.089835: Pseudo dice [0.9004, 0.6806, 0.4455, 0.5471, 0.201, 0.9133, 0.5754, 0.6133]
2025-05-29 16:35:35.089926: Epoch time: 262.44 s
2025-05-29 16:35:36.546673: 
2025-05-29 16:35:36.547071: Epoch 111
2025-05-29 16:35:36.547365: Current learning rate: 0.0066
2025-05-29 16:40:42.317760: train_loss -1.0235
2025-05-29 16:40:42.318082: val_loss -0.5614
2025-05-29 16:40:42.318225: Pseudo dice [0.9234, 0.6793, 0.4566, 0.5203, 0.248, 0.9151, 0.5822, 0.7027]
2025-05-29 16:40:42.318319: Epoch time: 305.77 s
2025-05-29 16:40:43.727820: 
2025-05-29 16:40:43.728186: Epoch 112
2025-05-29 16:40:43.728342: Current learning rate: 0.00657
2025-05-29 17:10:50.412321: train_loss -1.0549
2025-05-29 17:10:50.412599: val_loss -0.7113
2025-05-29 17:10:50.412729: Pseudo dice [0.9192, 0.7047, 0.4575, 0.6456, 0.2313, 0.9178, 0.5941, 0.7579]
2025-05-29 17:10:50.412819: Epoch time: 1806.69 s
2025-05-29 17:10:51.872922: 
2025-05-29 17:10:51.873410: Epoch 113
2025-05-29 17:10:51.873598: Current learning rate: 0.00654
2025-05-29 17:14:05.451479: train_loss -1.049
2025-05-29 17:14:05.451770: val_loss -0.5817
2025-05-29 17:14:05.451893: Pseudo dice [0.926, 0.6743, 0.3864, 0.5661, 0.2279, 0.9083, 0.613, 0.7245]
2025-05-29 17:14:05.451993: Epoch time: 193.58 s
2025-05-29 17:14:06.857603: 
2025-05-29 17:14:06.857996: Epoch 114
2025-05-29 17:14:06.858140: Current learning rate: 0.0065
2025-05-29 17:19:31.898982: train_loss -1.023
2025-05-29 17:19:31.899228: val_loss -0.6427
2025-05-29 17:19:31.899347: Pseudo dice [0.9105, 0.6986, 0.4494, 0.6355, 0.2208, 0.885, 0.6321, 0.6443]
2025-05-29 17:19:31.899432: Epoch time: 325.04 s
2025-05-29 17:19:34.012636: 
2025-05-29 17:19:34.012925: Epoch 115
2025-05-29 17:19:34.013054: Current learning rate: 0.00647
2025-05-29 17:23:09.983409: train_loss -0.973
2025-05-29 17:23:09.983898: val_loss -0.6159
2025-05-29 17:23:09.984069: Pseudo dice [0.8928, 0.6653, 0.4024, 0.5808, 0.3047, 0.8729, 0.6063, 0.6746]
2025-05-29 17:23:09.984153: Epoch time: 215.97 s
2025-05-29 17:23:11.344272: 
2025-05-29 17:23:11.344593: Epoch 116
2025-05-29 17:23:11.344693: Current learning rate: 0.00644
2025-05-29 17:25:52.677920: train_loss -1.0088
2025-05-29 17:25:52.678179: val_loss -0.6585
2025-05-29 17:25:52.678295: Pseudo dice [0.9252, 0.6726, 0.4617, 0.6921, 0.2936, 0.9126, 0.57, 0.7421]
2025-05-29 17:25:52.678385: Epoch time: 161.33 s
2025-05-29 17:25:52.678460: Yayy! New best EMA pseudo Dice: 0.6317
2025-05-29 17:25:55.547389: 
2025-05-29 17:25:55.547849: Epoch 117
2025-05-29 17:25:55.547957: Current learning rate: 0.00641
2025-05-29 17:27:13.070074: train_loss -1.0565
2025-05-29 17:27:13.070350: val_loss -0.677
2025-05-29 17:27:13.070481: Pseudo dice [0.9236, 0.7019, 0.4458, 0.6108, 0.1195, 0.9089, 0.6004, 0.6992]
2025-05-29 17:27:13.070574: Epoch time: 77.52 s
2025-05-29 17:27:14.481756: 
2025-05-29 17:27:14.482171: Epoch 118
2025-05-29 17:27:14.482321: Current learning rate: 0.00638
2025-05-29 17:28:35.733359: train_loss -1.0481
2025-05-29 17:28:35.733599: val_loss -0.6409
2025-05-29 17:28:35.733715: Pseudo dice [0.9229, 0.7002, 0.4249, 0.5721, 0.3361, 0.8912, 0.6245, 0.7031]
2025-05-29 17:28:35.733804: Epoch time: 81.25 s
2025-05-29 17:28:35.733936: Yayy! New best EMA pseudo Dice: 0.6327
2025-05-29 17:28:38.568525: 
2025-05-29 17:28:38.568690: Epoch 119
2025-05-29 17:28:38.568798: Current learning rate: 0.00635
2025-05-29 17:29:55.023481: train_loss -1.0146
2025-05-29 17:29:55.023798: val_loss -0.6855
2025-05-29 17:29:55.023925: Pseudo dice [0.9229, 0.6214, 0.427, 0.6491, 0.365, 0.8792, 0.6094, 0.6693]
2025-05-29 17:29:55.024026: Epoch time: 76.46 s
2025-05-29 17:29:55.024074: Yayy! New best EMA pseudo Dice: 0.6338
2025-05-29 17:29:57.860533: 
2025-05-29 17:29:57.860921: Epoch 120
2025-05-29 17:29:57.861071: Current learning rate: 0.00631
2025-05-29 17:31:42.191853: train_loss -0.9913
2025-05-29 17:31:42.192093: val_loss -0.7307
2025-05-29 17:31:42.192216: Pseudo dice [0.9176, 0.6674, 0.4201, 0.6996, 0.2512, 0.9169, 0.6054, 0.7234]
2025-05-29 17:31:42.192306: Epoch time: 104.33 s
2025-05-29 17:31:42.192372: Yayy! New best EMA pseudo Dice: 0.6354
2025-05-29 17:31:46.418002: 
2025-05-29 17:31:46.418273: Epoch 121
2025-05-29 17:31:46.418374: Current learning rate: 0.00628
2025-05-29 17:33:00.766054: train_loss -1.0495
2025-05-29 17:33:00.766280: val_loss -0.7728
2025-05-29 17:33:00.766397: Pseudo dice [0.933, 0.7189, 0.4333, 0.7265, 0.3334, 0.9256, 0.5609, 0.7993]
2025-05-29 17:33:00.766593: Epoch time: 74.35 s
2025-05-29 17:33:00.766756: Yayy! New best EMA pseudo Dice: 0.6397
2025-05-29 17:33:03.536225: 
2025-05-29 17:33:03.536441: Epoch 122
2025-05-29 17:33:03.536552: Current learning rate: 0.00625
2025-05-29 17:34:17.720784: train_loss -1.0567
2025-05-29 17:34:17.721109: val_loss -0.5123
2025-05-29 17:34:17.721234: Pseudo dice [0.9077, 0.5117, 0.4446, 0.4432, 0.2057, 0.9071, 0.589, 0.6407]
2025-05-29 17:34:17.721334: Epoch time: 74.19 s
2025-05-29 17:34:19.120346: 
2025-05-29 17:34:19.120673: Epoch 123
2025-05-29 17:34:19.120804: Current learning rate: 0.00622
2025-05-29 17:35:32.288745: train_loss -0.9806
2025-05-29 17:35:32.289075: val_loss -0.714
2025-05-29 17:35:32.289193: Pseudo dice [0.9216, 0.6582, 0.4312, 0.6723, 0.2478, 0.8979, 0.6094, 0.7431]
2025-05-29 17:35:32.289294: Epoch time: 73.17 s
2025-05-29 17:35:33.688632: 
2025-05-29 17:35:33.688933: Epoch 124
2025-05-29 17:35:33.689044: Current learning rate: 0.00619
2025-05-29 17:36:50.186144: train_loss -1.0453
2025-05-29 17:36:50.186466: val_loss -0.6643
2025-05-29 17:36:50.186679: Pseudo dice [0.9198, 0.6486, 0.4284, 0.6559, 0.2887, 0.9057, 0.5872, 0.7157]
2025-05-29 17:36:50.186833: Epoch time: 76.5 s
2025-05-29 17:36:51.681285: 
2025-05-29 17:36:51.681724: Epoch 125
2025-05-29 17:36:51.681830: Current learning rate: 0.00616
2025-05-29 17:38:07.897760: train_loss -1.0549
2025-05-29 17:38:07.898016: val_loss -0.66
2025-05-29 17:38:07.898193: Pseudo dice [0.9048, 0.7102, 0.4025, 0.6853, 0.208, 0.9168, 0.6145, 0.6851]
2025-05-29 17:38:07.898296: Epoch time: 76.22 s
2025-05-29 17:38:10.051067: 
2025-05-29 17:38:10.051433: Epoch 126
2025-05-29 17:38:10.051666: Current learning rate: 0.00612
2025-05-29 17:39:26.673210: train_loss -1.0683
2025-05-29 17:39:26.673672: val_loss -0.5744
2025-05-29 17:39:26.673829: Pseudo dice [0.9019, 0.7288, 0.4242, 0.568, 0.2293, 0.8734, 0.6297, 0.6622]
2025-05-29 17:39:26.673920: Epoch time: 76.62 s
2025-05-29 17:39:28.094149: 
2025-05-29 17:39:28.094486: Epoch 127
2025-05-29 17:39:28.094636: Current learning rate: 0.00609
2025-05-29 17:40:43.292071: train_loss -1.0734
2025-05-29 17:40:43.292424: val_loss -0.6707
2025-05-29 17:40:43.292628: Pseudo dice [0.9285, 0.6779, 0.3439, 0.7151, 0.2288, 0.9065, 0.6226, 0.6626]
2025-05-29 17:40:43.292761: Epoch time: 75.2 s
2025-05-29 17:40:44.702652: 
2025-05-29 17:40:44.702944: Epoch 128
2025-05-29 17:40:44.703082: Current learning rate: 0.00606
2025-05-29 17:42:00.826607: train_loss -1.0753
2025-05-29 17:42:00.827193: val_loss -0.7431
2025-05-29 17:42:00.827315: Pseudo dice [0.9118, 0.7271, 0.4622, 0.7508, 0.2387, 0.925, 0.606, 0.6653]
2025-05-29 17:42:00.827403: Epoch time: 76.13 s
2025-05-29 17:42:02.243819: 
2025-05-29 17:42:02.244078: Epoch 129
2025-05-29 17:42:02.244223: Current learning rate: 0.00603
2025-05-29 17:43:20.502111: train_loss -1.0991
2025-05-29 17:43:20.502666: val_loss -0.7452
2025-05-29 17:43:20.502782: Pseudo dice [0.9323, 0.7391, 0.4361, 0.7273, 0.2389, 0.9256, 0.6382, 0.713]
2025-05-29 17:43:20.502863: Epoch time: 78.26 s
2025-05-29 17:43:20.502911: Yayy! New best EMA pseudo Dice: 0.6412
2025-05-29 17:43:23.288059: 
2025-05-29 17:43:23.288328: Epoch 130
2025-05-29 17:43:23.288430: Current learning rate: 0.006
2025-05-29 17:44:41.534650: train_loss -1.0689
2025-05-29 17:44:41.534930:
2025-05-29 17:36:21.132570: Epoch time: 30.7 s
2025-05-29 17:36:22.486152: 
2025-05-29 17:36:22.486535: Epoch 284
2025-05-29 17:36:22.486635: Current learning rate: 0.00071
2025-05-29 17:36:53.174575: train_loss -1.2887
2025-05-29 17:36:53.174901: val_loss -0.537
2025-05-29 17:36:53.175081: Pseudo dice [0.9034, 0.7345, 0.4044, 0.6174, 0.061, 0.9316, 0.5972, 0.6428]
2025-05-29 17:36:53.175179: Epoch time: 30.69 s
2025-05-29 17:36:54.544598: 
2025-05-29 17:36:54.544902: Epoch 285
2025-05-29 17:36:54.545029: Current learning rate: 0.00067
2025-05-29 17:37:25.311029: train_loss -1.2984
2025-05-29 17:37:25.311212: val_loss -0.5642
2025-05-29 17:37:25.311324: Pseudo dice [0.9156, 0.6951, 0.4258, 0.6025, 0.1316, 0.9359, 0.5665, 0.7048]
2025-05-29 17:37:25.311421: Epoch time: 30.77 s
2025-05-29 17:37:26.669727: 
2025-05-29 17:37:26.670057: Epoch 286
2025-05-29 17:37:26.670226: Current learning rate: 0.00063
2025-05-29 17:37:57.292716: train_loss -1.3089
2025-05-29 17:37:57.293028: val_loss -0.5642
2025-05-29 17:37:57.293151: Pseudo dice [0.9114, 0.7458, 0.405, 0.6146, 0.092, 0.928, 0.5785, 0.6678]
2025-05-29 17:37:57.293239: Epoch time: 30.62 s
2025-05-29 17:37:58.683088: 
2025-05-29 17:37:58.683299: Epoch 287
2025-05-29 17:37:58.683399: Current learning rate: 0.00059
2025-05-29 17:38:29.342506: train_loss -1.2929
2025-05-29 17:38:29.342758: val_loss -0.5307
2025-05-29 17:38:29.342882: Pseudo dice [0.8934, 0.695, 0.4019, 0.5724, 0.1317, 0.913, 0.5841, 0.6672]
2025-05-29 17:38:29.342964: Epoch time: 30.66 s
2025-05-29 17:38:30.798850: 
2025-05-29 17:38:30.799173: Epoch 288
2025-05-29 17:38:30.799311: Current learning rate: 0.00055
2025-05-29 17:39:01.648232: train_loss -1.3003
2025-05-29 17:39:01.648437: val_loss -0.5718
2025-05-29 17:39:01.648570: Pseudo dice [0.9076, 0.714, 0.4006, 0.6372, 0.113, 0.9336, 0.5717, 0.7022]
2025-05-29 17:39:01.648650: Epoch time: 30.85 s
2025-05-29 17:39:03.029773: 
2025-05-29 17:39:03.030131: Epoch 289
2025-05-29 17:39:03.030224: Current learning rate: 0.00051
2025-05-29 17:39:33.713746: train_loss -1.2948
2025-05-29 17:39:33.714182: val_loss -0.6101
2025-05-29 17:39:33.714320: Pseudo dice [0.9163, 0.6927, 0.3863, 0.6666, 0.1345, 0.9342, 0.552, 0.6658]
2025-05-29 17:39:33.714403: Epoch time: 30.69 s
2025-05-29 17:39:35.805067: 
2025-05-29 17:39:35.805486: Epoch 290
2025-05-29 17:39:35.805588: Current learning rate: 0.00047
2025-05-29 17:40:06.671836: train_loss -1.3066
2025-05-29 17:40:06.672035: val_loss -0.5007
2025-05-29 17:40:06.672154: Pseudo dice [0.9026, 0.7153, 0.3675, 0.5573, 0.0835, 0.9233, 0.5577, 0.6568]
2025-05-29 17:40:06.672242: Epoch time: 30.87 s
2025-05-29 17:40:08.048216: 
2025-05-29 17:40:08.048392: Epoch 291
2025-05-29 17:40:08.048647: Current learning rate: 0.00043
2025-05-29 17:40:38.867465: train_loss -1.3123
2025-05-29 17:40:38.868395: val_loss -0.4704
2025-05-29 17:40:38.868524: Pseudo dice [0.9027, 0.6831, 0.3754, 0.5116, 0.1107, 0.9195, 0.534, 0.6258]
2025-05-29 17:40:38.868708: Epoch time: 30.82 s
2025-05-29 17:40:40.336812: 
2025-05-29 17:40:40.337209: Epoch 292
2025-05-29 17:40:40.337350: Current learning rate: 0.00038
2025-05-29 17:41:11.169368: train_loss -1.2994
2025-05-29 17:41:11.170054: val_loss -0.5927
2025-05-29 17:41:11.170247: Pseudo dice [0.9039, 0.7169, 0.4049, 0.6187, 0.0862, 0.9398, 0.6099, 0.6395]
2025-05-29 17:41:11.170441: Epoch time: 30.83 s
2025-05-29 17:41:12.573719: 
2025-05-29 17:41:12.574059: Epoch 293
2025-05-29 17:41:12.574181: Current learning rate: 0.00034
2025-05-29 17:41:43.594936: train_loss -1.3009
2025-05-29 17:41:43.595380: val_loss -0.5068
2025-05-29 17:41:43.595515: Pseudo dice [0.8992, 0.7264, 0.399, 0.5579, 0.0844, 0.9228, 0.5687, 0.6492]
2025-05-29 17:41:43.595608: Epoch time: 31.02 s
2025-05-29 17:41:45.034612: 
2025-05-29 17:41:45.034946: Epoch 294
2025-05-29 17:41:45.035131: Current learning rate: 0.0003
2025-05-29 17:42:16.939077: train_loss -1.2872
2025-05-29 17:42:16.939528: val_loss -0.5231
2025-05-29 17:42:16.939686: Pseudo dice [0.898, 0.7045, 0.3828, 0.6128, 0.1177, 0.9346, 0.5702, 0.6386]
2025-05-29 17:42:16.939776: Epoch time: 31.91 s
2025-05-29 17:42:18.381274: 
2025-05-29 17:42:18.381565: Epoch 295
2025-05-29 17:42:18.381768: Current learning rate: 0.00025
2025-05-29 17:42:49.432963: train_loss -1.2848
2025-05-29 17:42:49.433219: val_loss -0.5347
2025-05-29 17:42:49.433375: Pseudo dice [0.9049, 0.7045, 0.4149, 0.5639, 0.0895, 0.932, 0.5615, 0.6542]
2025-05-29 17:42:49.433484: Epoch time: 31.05 s
2025-05-29 17:42:50.812229: 
2025-05-29 17:42:50.812501: Epoch 296
2025-05-29 17:42:50.812653: Current learning rate: 0.00021
2025-05-29 17:43:21.772818: train_loss -1.315
2025-05-29 17:43:21.773242: val_loss -0.5729
2025-05-29 17:43:21.773374: Pseudo dice [0.8976, 0.7143, 0.4053, 0.6268, 0.1236, 0.9217, 0.549, 0.6796]
2025-05-29 17:43:21.773514: Epoch time: 30.96 s
2025-05-29 17:43:23.206823: 
2025-05-29 17:43:23.207180: Epoch 297
2025-05-29 17:43:23.207292: Current learning rate: 0.00016
2025-05-29 17:43:54.203159: train_loss -1.3077
2025-05-29 17:43:54.203472: val_loss -0.5008
2025-05-29 17:43:54.203592: Pseudo dice [0.9008, 0.7171, 0.3857, 0.5457, 0.0563, 0.9144, 0.5655, 0.6913]
2025-05-29 17:43:54.203672: Epoch time: 31.0 s
2025-05-29 17:43:55.593887: 
2025-05-29 17:43:55.594171: Epoch 298
2025-05-29 17:43:55.594381: Current learning rate: 0.00011
2025-05-29 17:44:26.602913: train_loss -1.3052
2025-05-29 17:44:26.603122: val_loss -0.5382
2025-05-29 17:44:26.603241: Pseudo dice [0.8995, 0.7467, 0.3949, 0.6005, 0.1079, 0.9288, 0.5735, 0.6712]
2025-05-29 17:44:26.603322: Epoch time: 31.01 s
2025-05-29 17:44:28.028572: 
2025-05-29 17:44:28.028835: Epoch 299
2025-05-29 17:44:28.029004: Current learning rate: 6e-05
2025-05-29 17:44:58.735155: train_loss -1.305
2025-05-29 17:44:58.735607: val_loss -0.5682
2025-05-29 17:44:58.735739: Pseudo dice [0.9095, 0.6837, 0.4339, 0.6136, 0.1189, 0.9266, 0.5677, 0.6447]
2025-05-29 17:44:58.735826: Epoch time: 30.71 s
2025-05-29 17:45:00.777089: Training done.
2025-05-29 17:45:00.797964: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 17:45:00.798527: The split file contains 5 splits.
2025-05-29 17:45:00.798583: Desired fold for training: 2
2025-05-29 17:45:00.798615: This split has 506 training and 127 validation cases.
2025-05-29 17:45:00.799704: predicting ct14-17
2025-05-29 17:45:00.804145: ct14-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.088224: predicting ct14-20
2025-05-29 17:45:26.093165: ct14-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.132483: predicting ct14-22
2025-05-29 17:45:26.136321: ct14-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.176998: predicting ct14-24
2025-05-29 17:45:26.180821: ct14-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.216684: predicting ct14-27
2025-05-29 17:45:26.220432: ct14-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.255574: predicting ct14-37
2025-05-29 17:45:26.259227: ct14-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.296065: predicting ct14-44
2025-05-29 17:45:26.300306: ct14-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.344759: predicting ct14-47
2025-05-29 17:45:26.348391: ct14-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.381557: predicting ct14-50
2025-05-29 17:45:26.385165: ct14-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.432280: predicting ct14-52
2025-05-29 17:45:26.439155: ct14-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.487965: predicting ct14-55
2025-05-29 17:45:26.492465: ct14-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.528868: predicting ct14-56
2025-05-29 17:45:26.534382: ct14-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.589548: predicting ct14-7
2025-05-29 17:45:26.593677: ct14-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.631502: predicting ct15-10
2025-05-29 17:45:26.635113: ct15-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.670662: predicting ct15-17
2025-05-29 17:45:26.674105: ct15-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.707659: predicting ct15-19
2025-05-29 17:45:26.711323: ct15-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.747539: predicting ct15-25
2025-05-29 17:45:26.751576: ct15-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.806907: predicting ct15-32
2025-05-29 17:45:26.811067: ct15-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.848588: predicting ct15-45
2025-05-29 17:45:26.852392: ct15-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.886511: predicting ct15-46
2025-05-29 17:45:26.890412: ct15-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.925097: predicting ct2-1
2025-05-29 17:45:26.928874: ct2-1, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:26.964655: predicting ct2-10
2025-05-29 17:45:26.968554: ct2-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.004725: predicting ct2-23
2025-05-29 17:45:27.008501: ct2-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.042190: predicting ct2-27
2025-05-29 17:45:27.045897: ct2-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.084255: predicting ct2-31
2025-05-29 17:45:27.087944: ct2-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.129339: predicting ct2-5
2025-05-29 17:45:27.133118: ct2-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.167317: predicting ct2-52
2025-05-29 17:45:27.171530: ct2-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.206021: predicting ct2-53
2025-05-29 17:45:27.209626: ct2-53, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.242675: predicting ct2-60
2025-05-29 17:45:27.246469: ct2-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.283438: predicting ct2-72
2025-05-29 17:45:27.287193: ct2-72, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.324873: predicting ct3-11
2025-05-29 17:45:27.328657: ct3-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.361654: predicting ct3-22
2025-05-29 17:45:27.364937: ct3-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.397845: predicting ct3-25
2025-05-29 17:45:27.401329: ct3-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.441834: predicting ct3-28
2025-05-29 17:45:27.445637: ct3-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.481968: predicting ct3-31
2025-05-29 17:45:27.485672: ct3-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.520712: predicting ct3-35
2025-05-29 17:45:27.524630: ct3-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.558396: predicting ct3-37
2025-05-29 17:45:27.562100: ct3-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.597974: predicting ct3-39
2025-05-29 17:45:27.602142: ct3-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.635624: predicting ct3-48
2025-05-29 17:45:27.639380: ct3-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.682891: predicting ct3-49
2025-05-29 17:45:27.687430: ct3-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.727920: predicting ct3-52
2025-05-29 17:45:27.731745: ct3-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.766690: predicting ct3-55
2025-05-29 17:45:27.770596: ct3-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.803542: predicting ct3-63
2025-05-29 17:45:27.807127: ct3-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.848041: predicting ct3-64
2025-05-29 17:45:27.852292: ct3-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.886566: predicting ct3-7
2025-05-29 17:45:27.890270: ct3-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.923265: predicting ct3-9
2025-05-29 17:45:27.927827: ct3-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:27.967152: predicting ct4-16
2025-05-29 17:45:27.971674: ct4-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.005349: predicting ct4-18
2025-05-29 17:45:28.009039: ct4-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.049904: predicting ct4-27
2025-05-29 17:45:28.053916: ct4-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.084741: predicting ct4-29
2025-05-29 17:45:28.087707: ct4-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.124455: predicting ct4-30
2025-05-29 17:45:28.127995: ct4-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.161818: predicting ct4-31
2025-05-29 17:45:28.165924: ct4-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.198927: predicting ct4-32
2025-05-29 17:45:28.202387: ct4-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.236476: predicting ct4-36
2025-05-29 17:45:28.239715: ct4-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.274484: predicting ct4-42
2025-05-29 17:45:28.277681: ct4-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.311801: predicting ct4-43
2025-05-29 17:45:28.315226: ct4-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.349592: predicting ct4-48
2025-05-29 17:45:28.353250: ct4-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.385313: predicting ct4-58
2025-05-29 17:45:28.388835: ct4-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.423623: predicting ct4-64
2025-05-29 17:45:28.427173: ct4-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.461965: predicting ct4-68
2025-05-29 17:45:28.465818: ct4-68, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.500096: predicting ct4-73
2025-05-29 17:45:28.503947: ct4-73, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.536964: predicting ct4-78
2025-05-29 17:45:28.563737: ct4-78, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.598126: predicting ct4-80
2025-05-29 17:45:28.601946: ct4-80, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.635656: predicting ct4-87
2025-05-29 17:45:28.639804: ct4-87, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.674275: predicting ct4-88
2025-05-29 17:45:28.677853: ct4-88, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.712582: predicting ct4-90
2025-05-29 17:45:28.716027: ct4-90, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.750772: predicting ct5-15
2025-05-29 17:45:28.754813: ct5-15, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.789662: predicting ct5-18
2025-05-29 17:45:28.794094: ct5-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.826264: predicting ct5-23
2025-05-29 17:45:28.830158: ct5-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.863048: predicting ct5-24
2025-05-29 17:45:28.866774: ct5-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.908760: predicting ct5-3
2025-05-29 17:45:28.912661: ct5-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.949373: predicting ct5-30
2025-05-29 17:45:28.953465: ct5-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:28.988319: predicting ct5-32
2025-05-29 17:45:28.992400: ct5-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.027113: predicting ct5-43
2025-05-29 17:45:29.030742: ct5-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.063870: predicting ct5-44
2025-05-29 17:45:29.067729: ct5-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.101429: predicting ct5-47
2025-05-29 17:45:29.104859: ct5-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.139538: predicting ct5-49
2025-05-29 17:45:29.143825: ct5-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.179300: predicting ct5-52
2025-05-29 17:45:29.182589: ct5-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.214923: predicting ct5-56
2025-05-29 17:45:29.218374: ct5-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.253048: predicting ct5-60
2025-05-29 17:45:29.256621: ct5-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.287203: predicting ct5-62
2025-05-29 17:45:29.290707: ct5-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.325762: predicting ct5-64
2025-05-29 17:45:29.329673: ct5-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.373272: predicting ct5-69
2025-05-29 17:45:29.377941: ct5-69, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.419167: predicting ct5-73
2025-05-29 17:45:29.423080: ct5-73, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.458550: predicting ct5-80
2025-05-29 17:45:29.462459: ct5-80, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.494025: predicting ct5-9
2025-05-29 17:45:29.497917: ct5-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.532625: predicting ct7-18
2025-05-29 17:45:29.536711: ct7-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.571538: predicting ct7-20
2025-05-29 17:45:29.574991: ct7-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.609595: predicting ct7-21
2025-05-29 17:45:29.613693: ct7-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.648885: predicting ct7-22
2025-05-29 17:45:29.652657: ct7-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.685260: predicting ct7-3
2025-05-29 17:45:29.689150: ct7-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.724727: predicting ct7-30
2025-05-29 17:45:29.728583: ct7-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.764511: predicting ct7-36
2025-05-29 17:45:29.768812: ct7-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.805296: predicting ct7-37
2025-05-29 17:45:29.808927: ct7-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.845033: predicting ct7-46
2025-05-29 17:45:29.849322: ct7-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.888126: predicting ct7-49
2025-05-29 17:45:29.892483: ct7-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.927575: predicting ct7-52
2025-05-29 17:45:29.931182: ct7-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:29.967679: predicting ct8-10
2025-05-29 17:45:29.971664: ct8-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.005116: predicting ct8-14
2025-05-29 17:45:30.008868: ct8-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.044523: predicting ct8-22
2025-05-29 17:45:30.048243: ct8-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.082223: predicting ct8-24
2025-05-29 17:45:30.086670: ct8-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.125468: predicting ct8-31
2025-05-29 17:45:30.129976: ct8-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.163372: predicting ct8-4
2025-05-29 17:45:30.167074: ct8-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.201084: predicting ct8-49
2025-05-29 17:45:30.204887: ct8-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.239944: predicting ct8-60
2025-05-29 17:45:30.243858: ct8-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.282880: predicting ct8-63
2025-05-29 17:45:30.286992: ct8-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.322262: predicting ct8-66
2025-05-29 17:45:30.326265: ct8-66, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.361061: predicting ct8-70
2025-05-29 17:45:30.365152: ct8-70, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.397246: predicting ct8-71
2025-05-29 17:45:30.401244: ct8-71, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.439508: predicting ct8-9
2025-05-29 17:45:30.443666: ct8-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.478773: predicting ct9-10
2025-05-29 17:45:30.482803: ct9-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.516187: predicting ct9-13
2025-05-29 17:45:30.520043: ct9-13, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.554392: predicting ct9-19
2025-05-29 17:45:30.558230: ct9-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.592515: predicting ct9-27
2025-05-29 17:45:30.596179: ct9-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.628479: predicting ct9-3
2025-05-29 17:45:30.632089: ct9-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.664385: predicting ct9-30
2025-05-29 17:45:30.667922: ct9-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.700477: predicting ct9-4
2025-05-29 17:45:30.704151: ct9-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.736790: predicting ct9-40
2025-05-29 17:45:30.740461: ct9-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.774402: predicting ct9-42
2025-05-29 17:45:30.778310: ct9-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.815315: predicting ct9-48
2025-05-29 17:45:30.819968: ct9-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.852742: predicting ct9-51
2025-05-29 17:45:30.856443: ct9-51, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.887295: predicting ct9-55
2025-05-29 17:45:30.890770: ct9-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.924498: predicting ct9-58
2025-05-29 17:45:30.927795: ct9-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.959203: predicting ct9-65
2025-05-29 17:45:30.962312: ct9-65, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:30.994210: predicting ct9-66
2025-05-29 17:45:30.999204: ct9-66, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:31.034213: predicting ct9-73
2025-05-29 17:45:31.037119: ct9-73, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:31.068556: predicting ct9-76
2025-05-29 17:45:31.072247: ct9-76, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 17:45:36.161609: Validation complete
2025-05-29 17:45:36.161728: Mean Validation Dice:  0.4647348331607955

2025-05-29 17:35:42.100995: Epoch time: 74.19 s
2025-05-29 17:35:43.611522: 
2025-05-29 17:35:43.611804: Epoch 131
2025-05-29 17:35:43.611926: Current learning rate: 0.00597
2025-05-29 17:36:59.190515: train_loss -1.115
2025-05-29 17:36:59.190746: val_loss -0.6627
2025-05-29 17:36:59.190862: Pseudo dice [0.921, 0.7343, 0.4273, 0.6538, 0.0802, 0.927, 0.5426, 0.7176]
2025-05-29 17:36:59.190953: Epoch time: 75.58 s
2025-05-29 17:37:00.587993: 
2025-05-29 17:37:00.588269: Epoch 132
2025-05-29 17:37:00.588373: Current learning rate: 0.00593
2025-05-29 17:38:14.382274: train_loss -1.0998
2025-05-29 17:38:14.382558: val_loss -0.5741
2025-05-29 17:38:14.382676: Pseudo dice [0.9102, 0.6747, 0.4416, 0.5587, 0.0962, 0.9377, 0.5772, 0.7244]
2025-05-29 17:38:14.382762: Epoch time: 73.8 s
2025-05-29 17:38:15.795663: 
2025-05-29 17:38:15.795910: Epoch 133
2025-05-29 17:38:15.796011: Current learning rate: 0.0059
2025-05-29 17:39:31.094543: train_loss -1.1218
2025-05-29 17:39:31.094951: val_loss -0.7013
2025-05-29 17:39:31.095143: Pseudo dice [0.9241, 0.7246, 0.4063, 0.6468, 0.1504, 0.9213, 0.6004, 0.7369]
2025-05-29 17:39:31.095234: Epoch time: 75.3 s
2025-05-29 17:39:32.467479: 
2025-05-29 17:39:32.467764: Epoch 134
2025-05-29 17:39:32.467904: Current learning rate: 0.00587
2025-05-29 17:40:46.799799: train_loss -1.1374
2025-05-29 17:40:46.800120: val_loss -0.6865
2025-05-29 17:40:46.800310: Pseudo dice [0.9159, 0.7285, 0.4412, 0.6927, 0.1601, 0.9087, 0.5269, 0.6891]
2025-05-29 17:40:46.800431: Epoch time: 74.33 s
2025-05-29 17:40:48.219512: 
2025-05-29 17:40:48.219862: Epoch 135
2025-05-29 17:40:48.220032: Current learning rate: 0.00584
2025-05-29 17:42:03.462795: train_loss -1.1108
2025-05-29 17:42:03.463028: val_loss -0.5903
2025-05-29 17:42:03.463143: Pseudo dice [0.9151, 0.6761, 0.3657, 0.5711, 0.1664, 0.8993, 0.5469, 0.7405]
2025-05-29 17:42:03.463227: Epoch time: 75.24 s
2025-05-29 17:42:04.846534: 
2025-05-29 17:42:04.846693: Epoch 136
2025-05-29 17:42:04.846918: Current learning rate: 0.00581
2025-05-29 17:43:21.709378: train_loss -1.1473
2025-05-29 17:43:21.709590: val_loss -0.6766
2025-05-29 17:43:21.709695: Pseudo dice [0.9234, 0.7306, 0.4921, 0.6278, 0.2528, 0.9377, 0.5796, 0.6659]
2025-05-29 17:43:21.709782: Epoch time: 76.86 s
2025-05-29 17:43:23.103711: 
2025-05-29 17:43:23.104042: Epoch 137
2025-05-29 17:43:23.104188: Current learning rate: 0.00578
2025-05-29 17:44:40.843384: train_loss -1.1287
2025-05-29 17:44:40.843631: val_loss -0.6885
2025-05-29 17:44:40.843849: Pseudo dice [0.9304, 0.7411, 0.371, 0.6394, 0.1502, 0.8938, 0.6203, 0.7458]
2025-05-29 17:44:40.843977: Epoch time: 77.74 s
2025-05-29 17:44:42.231376: 
2025-05-29 17:44:42.231693: Epoch 138
2025-05-29 17:44:42.231792: Current learning rate: 0.00574
2025-05-29 17:45:55.586372: train_loss -1.1186
2025-05-29 17:45:55.586698: val_loss -0.6206
2025-05-29 17:45:55.586874: Pseudo dice [0.936, 0.7247, 0.4159, 0.5655, 0.1505, 0.9277, 0.5645, 0.7456]
2025-05-29 17:45:55.586993: Epoch time: 73.36 s
2025-05-29 17:45:57.074105: 
2025-05-29 17:45:57.074375: Epoch 139
2025-05-29 17:45:57.074485: Current learning rate: 0.00571
2025-05-29 17:47:12.465474: train_loss -1.127
2025-05-29 17:47:12.465773: val_loss -0.702
2025-05-29 17:47:12.465907: Pseudo dice [0.9236, 0.7318, 0.3959, 0.6695, 0.1788, 0.9107, 0.535, 0.7255]
2025-05-29 17:47:12.466010: Epoch time: 75.39 s
2025-05-29 17:47:13.893424: 
2025-05-29 17:47:13.893887: Epoch 140
2025-05-29 17:47:13.893980: Current learning rate: 0.00568
2025-05-29 17:48:26.774429: train_loss -1.1515
2025-05-29 17:48:26.774714: val_loss -0.6665
2025-05-29 17:48:26.774837: Pseudo dice [0.9222, 0.7183, 0.4268, 0.5969, 0.1171, 0.9346, 0.5569, 0.7818]
2025-05-29 17:48:26.774934: Epoch time: 72.88 s
2025-05-29 17:48:28.135940: 
2025-05-29 17:48:28.136263: Epoch 141
2025-05-29 17:48:28.136472: Current learning rate: 0.00565
2025-05-29 17:49:40.168820: train_loss -1.1487
2025-05-29 17:49:40.169084: val_loss -0.6493
2025-05-29 17:49:40.169205: Pseudo dice [0.9204, 0.744, 0.5185, 0.5994, 0.2146, 0.9029, 0.5944, 0.685]
2025-05-29 17:49:40.169292: Epoch time: 72.03 s
2025-05-29 17:49:41.578616: 
2025-05-29 17:49:41.578809: Epoch 142
2025-05-29 17:49:41.578905: Current learning rate: 0.00562
2025-05-29 17:50:54.035329: train_loss -1.16
2025-05-29 17:50:54.035567: val_loss -0.6471
2025-05-29 17:50:54.035686: Pseudo dice [0.9271, 0.7457, 0.5027, 0.5563, 0.2064, 0.927, 0.5425, 0.7618]
2025-05-29 17:50:54.035771: Epoch time: 72.46 s
2025-05-29 17:50:55.408438: 
2025-05-29 17:50:55.408821: Epoch 143
2025-05-29 17:50:55.408918: Current learning rate: 0.00558
2025-05-29 17:52:09.525281: train_loss -1.148
2025-05-29 17:52:09.525556: val_loss -0.6665
2025-05-29 17:52:09.525709: Pseudo dice [0.9104, 0.7541, 0.4229, 0.5987, 0.3937, 0.9355, 0.5326, 0.7124]
2025-05-29 17:52:09.525796: Epoch time: 74.12 s
2025-05-29 17:52:09.525863: Yayy! New best EMA pseudo Dice: 0.6376
2025-05-29 17:52:12.508091: 
2025-05-29 17:52:12.508369: Epoch 144
2025-05-29 17:52:12.508475: Current learning rate: 0.00555
2025-05-29 17:53:24.790578: train_loss -1.1813
2025-05-29 17:53:24.790817: val_loss -0.6427
2025-05-29 17:53:24.790941: Pseudo dice [0.9244, 0.7219, 0.4195, 0.6159, 0.3451, 0.9476, 0.5539, 0.7441]
2025-05-29 17:53:24.791018: Epoch time: 72.28 s
2025-05-29 17:53:24.791070: Yayy! New best EMA pseudo Dice: 0.6398
2025-05-29 17:53:27.596752: 
2025-05-29 17:53:27.597071: Epoch 145
2025-05-29 17:53:27.597183: Current learning rate: 0.00552
2025-05-29 17:54:40.478231: train_loss -1.1545
2025-05-29 17:54:40.478632: val_loss -0.6316
2025-05-29 17:54:40.478815: Pseudo dice [0.9039, 0.6892, 0.398, 0.6261, 0.2043, 0.9061, 0.5618, 0.708]
2025-05-29 17:54:40.478945: Epoch time: 72.88 s
2025-05-29 17:54:41.907483: 
2025-05-29 17:54:41.907768: Epoch 146
2025-05-29 17:54:41.907881: Current learning rate: 0.00549
2025-05-29 17:55:54.700586: train_loss -1.1329
2025-05-29 17:55:54.701638: val_loss -0.6866
2025-05-29 17:55:54.701796: Pseudo dice [0.9281, 0.7352, 0.4324, 0.6341, 0.2859, 0.9141, 0.5333, 0.7397]
2025-05-29 17:55:54.702159: Epoch time: 72.79 s
2025-05-29 17:55:56.163606: 
2025-05-29 17:55:56.163928: Epoch 147
2025-05-29 17:55:56.164087: Current learning rate: 0.00546
2025-05-29 17:57:08.775247: train_loss -1.1447
2025-05-29 17:57:08.775565: val_loss -0.6395
2025-05-29 17:57:08.775692: Pseudo dice [0.9128, 0.7058, 0.3822, 0.5971, 0.1597, 0.925, 0.5634, 0.7502]
2025-05-29 17:57:08.775787: Epoch time: 72.61 s
2025-05-29 17:57:10.168286: 
2025-05-29 17:57:10.168631: Epoch 148
2025-05-29 17:57:10.168736: Current learning rate: 0.00542
2025-05-29 17:58:22.428015: train_loss -1.1677
2025-05-29 17:58:22.428285: val_loss -0.6951
2025-05-29 17:58:22.428399: Pseudo dice [0.9268, 0.7339, 0.3703, 0.69, 0.2315, 0.9468, 0.5372, 0.7209]
2025-05-29 17:58:22.428507: Epoch time: 72.26 s
2025-05-29 17:58:23.808945: 
2025-05-29 17:58:23.809201: Epoch 149
2025-05-29 17:58:23.809348: Current learning rate: 0.00539
2025-05-29 17:59:39.345502: train_loss -1.1513
2025-05-29 17:59:39.345722: val_loss -0.5541
2025-05-29 17:59:39.345841: Pseudo dice [0.9246, 0.6658, 0.4107, 0.5099, 0.109, 0.9001, 0.5549, 0.7015]
2025-05-29 17:59:39.345930: Epoch time: 75.54 s
2025-05-29 17:59:43.310023: 
2025-05-29 17:59:43.310318: Epoch 150
2025-05-29 17:59:43.310487: Current learning rate: 0.00536
2025-05-29 18:00:58.776510: train_loss -1.1255
2025-05-29 18:00:58.776730: val_loss -0.6747
2025-05-29 18:00:58.776844: Pseudo dice [0.9233, 0.7224, 0.4497, 0.6299, 0.1983, 0.9119, 0.5684, 0.7039]
2025-05-29 18:00:58.776923: Epoch time: 75.47 s
2025-05-29 18:01:00.146348: 
2025-05-29 18:01:00.146610: Epoch 151
2025-05-29 18:01:00.146740: Current learning rate: 0.00533
2025-05-29 18:02:15.023012: train_loss -1.1533
2025-05-29 18:02:15.023332: val_loss -0.6503
2025-05-29 18:02:15.023459: Pseudo dice [0.9118, 0.7286, 0.4358, 0.6115, 0.0781, 0.938, 0.5922, 0.6779]
2025-05-29 18:02:15.023563: Epoch time: 74.88 s
2025-05-29 18:02:16.415289: 
2025-05-29 18:02:16.415624: Epoch 152
2025-05-29 18:02:16.415842: Current learning rate: 0.00529
2025-05-29 18:03:31.294317: train_loss -1.179
2025-05-29 18:03:31.294658: val_loss -0.7345
2025-05-29 18:03:31.294840:
2025-05-29 17:34:52.998721: Epoch time: 87.71 s
2025-05-29 17:34:52.998785: Yayy! New best EMA pseudo Dice: 0.5907
2025-05-29 17:34:55.779069: 
2025-05-29 17:34:55.779195: Epoch 110
2025-05-29 17:34:55.779285: Current learning rate: 0.00663
2025-05-29 17:36:24.098767: train_loss -1.0396
2025-05-29 17:36:24.098990: val_loss -0.6632
2025-05-29 17:36:24.099102: Pseudo dice [0.8897, 0.6107, 0.4682, 0.7255, 0.0002, 0.8241, 0.5021, 0.7017]
2025-05-29 17:36:24.099189: Epoch time: 88.32 s
2025-05-29 17:36:25.496912: 
2025-05-29 17:36:25.497246: Epoch 111
2025-05-29 17:36:25.497383: Current learning rate: 0.0066
2025-05-29 17:37:54.693630: train_loss -1.0593
2025-05-29 17:37:54.693889: val_loss -0.7522
2025-05-29 17:37:54.694023: Pseudo dice [0.9001, 0.6687, 0.4369, 0.7755, 0.0273, 0.8762, 0.4768, 0.77]
2025-05-29 17:37:54.694129: Epoch time: 89.2 s
2025-05-29 17:37:54.694179: Yayy! New best EMA pseudo Dice: 0.5932
2025-05-29 17:37:57.410087: 
2025-05-29 17:37:57.410491: Epoch 112
2025-05-29 17:37:57.410623: Current learning rate: 0.00657
2025-05-29 17:39:25.217365: train_loss -1.0504
2025-05-29 17:39:25.217684: val_loss -0.7072
2025-05-29 17:39:25.217812: Pseudo dice [0.8845, 0.5912, 0.4545, 0.6968, 0.0636, 0.8845, 0.4819, 0.8046]
2025-05-29 17:39:25.217952: Epoch time: 87.81 s
2025-05-29 17:39:25.218063: Yayy! New best EMA pseudo Dice: 0.5947
2025-05-29 17:39:28.289289: 
2025-05-29 17:39:28.289585: Epoch 113
2025-05-29 17:39:28.289747: Current learning rate: 0.00654
2025-05-29 17:40:53.981035: train_loss -1.0388
2025-05-29 17:40:53.981299: val_loss -0.5918
2025-05-29 17:40:53.981511: Pseudo dice [0.8977, 0.6495, 0.3826, 0.5917, 0.1614, 0.8227, 0.4539, 0.7823]
2025-05-29 17:40:53.981655: Epoch time: 85.69 s
2025-05-29 17:40:55.456533: 
2025-05-29 17:40:55.456869: Epoch 114
2025-05-29 17:40:55.457093: Current learning rate: 0.0065
2025-05-29 17:42:24.927075: train_loss -0.9968
2025-05-29 17:42:24.927393: val_loss -0.7121
2025-05-29 17:42:24.927525: Pseudo dice [0.8957, 0.651, 0.3715, 0.7534, 0.0907, 0.8453, 0.5109, 0.7615]
2025-05-29 17:42:24.927630: Epoch time: 89.47 s
2025-05-29 17:42:24.927678: Yayy! New best EMA pseudo Dice: 0.596
2025-05-29 17:42:27.597607: 
2025-05-29 17:42:27.598062: Epoch 115
2025-05-29 17:42:27.598373: Current learning rate: 0.00647
2025-05-29 17:43:58.033006: train_loss -1.0209
2025-05-29 17:43:58.033241: val_loss -0.5436
2025-05-29 17:43:58.033357: Pseudo dice [0.8936, 0.5955, 0.4232, 0.5204, 0.0362, 0.847, 0.4767, 0.8104]
2025-05-29 17:43:58.033462: Epoch time: 90.44 s
2025-05-29 17:44:00.063121: 
2025-05-29 17:44:00.063503: Epoch 116
2025-05-29 17:44:00.063632: Current learning rate: 0.00644
2025-05-29 17:45:30.075868: train_loss -1.0388
2025-05-29 17:45:30.076229: val_loss -0.6884
2025-05-29 17:45:30.076379: Pseudo dice [0.8887, 0.6544, 0.4206, 0.71, 0.0788, 0.8947, 0.5223, 0.7872]
2025-05-29 17:45:30.076483: Epoch time: 90.01 s
2025-05-29 17:45:30.076537: Yayy! New best EMA pseudo Dice: 0.5965
2025-05-29 17:45:32.863626: 
2025-05-29 17:45:32.864111: Epoch 117
2025-05-29 17:45:32.864457: Current learning rate: 0.00641
2025-05-29 17:46:57.977491: train_loss -1.0424
2025-05-29 17:46:57.977715: val_loss -0.6541
2025-05-29 17:46:57.977829: Pseudo dice [0.8875, 0.631, 0.3977, 0.6858, 0.0911, 0.8387, 0.4627, 0.7126]
2025-05-29 17:46:57.977925: Epoch time: 85.12 s
2025-05-29 17:46:59.353600: 
2025-05-29 17:46:59.353971: Epoch 118
2025-05-29 17:46:59.354071: Current learning rate: 0.00638
2025-05-29 17:48:22.109745: train_loss -0.991
2025-05-29 17:48:22.109965: val_loss -0.6564
2025-05-29 17:48:22.110077: Pseudo dice [0.895, 0.6563, 0.4021, 0.662, 0.0518, 0.8766, 0.5251, 0.816]
2025-05-29 17:48:22.110167: Epoch time: 82.76 s
2025-05-29 17:48:22.110219: Yayy! New best EMA pseudo Dice: 0.5972
2025-05-29 17:48:25.005044: 
2025-05-29 17:48:25.005285: Epoch 119
2025-05-29 17:48:25.005391: Current learning rate: 0.00635
2025-05-29 17:49:53.479032: train_loss -1.0377
2025-05-29 17:49:53.479267: val_loss -0.6827
2025-05-29 17:49:53.479385: Pseudo dice [0.9114, 0.6105, 0.444, 0.7132, 0.0618, 0.8459, 0.5136, 0.7733]
2025-05-29 17:49:53.479586: Epoch time: 88.48 s
2025-05-29 17:49:53.479642: Yayy! New best EMA pseudo Dice: 0.5984
2025-05-29 17:49:55.925586: 
2025-05-29 17:49:55.925987: Epoch 120
2025-05-29 17:49:55.926131: Current learning rate: 0.00631
2025-05-29 17:51:24.966815: train_loss -1.0346
2025-05-29 17:51:24.967113: val_loss -0.6581
2025-05-29 17:51:24.967232: Pseudo dice [0.9082, 0.6765, 0.4312, 0.6753, 0.0263, 0.8233, 0.5279, 0.765]
2025-05-29 17:51:24.967394: Epoch time: 89.04 s
2025-05-29 17:51:24.967495: Yayy! New best EMA pseudo Dice: 0.599
2025-05-29 17:51:27.575303: 
2025-05-29 17:51:27.575523: Epoch 121
2025-05-29 17:51:27.575660: Current learning rate: 0.00628
2025-05-29 17:52:57.459009: train_loss -1.0338
2025-05-29 17:52:57.459280: val_loss -0.4755
2025-05-29 17:52:57.459492: Pseudo dice [0.8823, 0.5896, 0.396, 0.5352, 0.024, 0.8308, 0.4316, 0.7338]
2025-05-29 17:52:57.459597: Epoch time: 89.88 s
2025-05-29 17:52:58.825953: 
2025-05-29 17:52:58.826291: Epoch 122
2025-05-29 17:52:58.826385: Current learning rate: 0.00625
2025-05-29 17:54:28.350216: train_loss -1.0402
2025-05-29 17:54:28.350432: val_loss -0.5922
2025-05-29 17:54:28.350560: Pseudo dice [0.8718, 0.6257, 0.428, 0.6777, 0.0028, 0.87, 0.3539, 0.715]
2025-05-29 17:54:28.350648: Epoch time: 89.53 s
2025-05-29 17:54:29.735059: 
2025-05-29 17:54:29.735375: Epoch 123
2025-05-29 17:54:29.735575: Current learning rate: 0.00622
2025-05-29 17:55:57.929619: train_loss -1.056
2025-05-29 17:55:57.929898: val_loss -0.6804
2025-05-29 17:55:57.930089: Pseudo dice [0.9098, 0.6064, 0.3912, 0.6776, 0.0358, 0.9048, 0.4894, 0.772]
2025-05-29 17:55:57.930196: Epoch time: 88.2 s
2025-05-29 17:55:59.296125: 
2025-05-29 17:55:59.296490: Epoch 124
2025-05-29 17:55:59.296590: Current learning rate: 0.00619
2025-05-29 17:57:27.839887: train_loss -1.0157
2025-05-29 17:57:27.840236: val_loss -0.5295
2025-05-29 17:57:27.840358: Pseudo dice [0.8741, 0.5905, 0.4466, 0.5457, 0.1042, 0.8485, 0.4487, 0.7271]
2025-05-29 17:57:27.840471: Epoch time: 88.55 s
2025-05-29 17:57:29.228498: 
2025-05-29 17:57:29.228857: Epoch 125
2025-05-29 17:57:29.228987: Current learning rate: 0.00616
2025-05-29 17:58:59.144437: train_loss -1.0146
2025-05-29 17:58:59.144673: val_loss -0.5489
2025-05-29 17:58:59.144866: Pseudo dice [0.9078, 0.575, 0.4464, 0.577, 0.0552, 0.8666, 0.4302, 0.7732]
2025-05-29 17:58:59.144999: Epoch time: 89.92 s
2025-05-29 17:59:00.519842: 
2025-05-29 17:59:00.519969: Epoch 126
2025-05-29 17:59:00.520068: Current learning rate: 0.00612
2025-05-29 18:00:25.732722: train_loss -1.0331
2025-05-29 18:00:25.732961: val_loss -0.6562
2025-05-29 18:00:25.733074: Pseudo dice [0.8945, 0.6174, 0.4109, 0.6722, 0.0281, 0.8335, 0.4563, 0.7516]
2025-05-29 18:00:25.733162: Epoch time: 85.21 s
2025-05-29 18:00:27.744297: 
2025-05-29 18:00:27.744510: Epoch 127
2025-05-29 18:00:27.744614: Current learning rate: 0.00609
2025-05-29 18:01:53.863307: train_loss -1.0542
2025-05-29 18:01:53.863597: val_loss -0.624
2025-05-29 18:01:53.863712: Pseudo dice [0.9092, 0.6073, 0.437, 0.5889, 0.002, 0.8433, 0.4903, 0.8045]
2025-05-29 18:01:53.863791: Epoch time: 86.12 s
2025-05-29 18:01:55.285992: 
2025-05-29 18:01:55.286269: Epoch 128
2025-05-29 18:01:55.286413: Current learning rate: 0.00606
2025-05-29 18:03:20.245229: train_loss -1.0716
2025-05-29 18:03:20.245456: val_loss -0.6182
2025-05-29 18:03:20.245572: Pseudo dice [0.9164, 0.5856, 0.4839, 0.6168, 0.0378, 0.8408, 0.4916, 0.7903]
2025-05-29 18:03:20.245648: Epoch time: 84.96 s
2025-05-29 18:03:21.638851: 
2025-05-29 18:03:21.639136: Epoch 129
2025-05-29 18:03:21.639277: Current learning rate: 0.00603
2025-05-29 18:04:41.904037: train_loss -1.0895
2025-05-29 18:04:41.904251: val_loss -0.664
2025-05-29 18:04:41.904362: Pseudo dice [0.903, 0.6075, 0.4576, 0.6492, 0.088, 0.8863, 0.4562, 0.7941]
2025-05-29 18:04:41.904466: Epoch time: 80.27 s
2025-05-29 18:04:43.398265: 
2025-05-29 18:04:43.398674: Epoch 130
2025-05-29 18:04:43.398777: Current learning rate: 0.006
2025-05-29 18:06:13.104718: train_loss -1.0826
2025-05-29 18:06:13.104923: val_loss -0.641
2025-05-29 18:06:13.105034: val_loss -0.6637
2025-05-29 17:44:41.535886: Pseudo dice [0.928, 0.7419, 0.4502, 0.63, 0.2914, 0.9227, 0.6118, 0.7485]
2025-05-29 17:44:41.536092: Epoch time: 78.25 s
2025-05-29 17:44:41.536262: Yayy! New best EMA pseudo Dice: 0.6437
2025-05-29 17:44:44.592336: 
2025-05-29 17:44:44.592689: Epoch 131
2025-05-29 17:44:44.592868: Current learning rate: 0.00597
2025-05-29 17:46:00.741245: train_loss -1.1035
2025-05-29 17:46:00.741543: val_loss -0.7488
2025-05-29 17:46:00.741659: Pseudo dice [0.9282, 0.6347, 0.4395, 0.7318, 0.1821, 0.9237, 0.6154, 0.6883]
2025-05-29 17:46:00.741750: Epoch time: 76.15 s
2025-05-29 17:46:02.172597: 
2025-05-29 17:46:02.172832: Epoch 132
2025-05-29 17:46:02.172932: Current learning rate: 0.00593
2025-05-29 17:47:17.723286: train_loss -1.0821
2025-05-29 17:47:17.723636: val_loss -0.7313
2025-05-29 17:47:17.723759: Pseudo dice [0.9165, 0.6611, 0.4587, 0.7404, 0.1889, 0.925, 0.6103, 0.6591]
2025-05-29 17:47:17.723845: Epoch time: 75.55 s
2025-05-29 17:47:17.723897: Yayy! New best EMA pseudo Dice: 0.6437
2025-05-29 17:47:20.587143: 
2025-05-29 17:47:20.587584: Epoch 133
2025-05-29 17:47:20.587697: Current learning rate: 0.0059
2025-05-29 17:48:37.071155: train_loss -1.0951
2025-05-29 17:48:37.072083: val_loss -0.7146
2025-05-29 17:48:37.072390: Pseudo dice [0.9292, 0.7046, 0.4294, 0.6973, 0.139, 0.8967, 0.6101, 0.7478]
2025-05-29 17:48:37.072621: Epoch time: 76.49 s
2025-05-29 17:48:37.072711: Yayy! New best EMA pseudo Dice: 0.6438
2025-05-29 17:48:39.990806: 
2025-05-29 17:48:39.991259: Epoch 134
2025-05-29 17:48:39.991381: Current learning rate: 0.00587
2025-05-29 17:49:56.679986: train_loss -1.0687
2025-05-29 17:49:56.680596: val_loss -0.7164
2025-05-29 17:49:56.680721: Pseudo dice [0.9126, 0.7084, 0.4546, 0.6796, 0.2208, 0.9223, 0.5589, 0.7377]
2025-05-29 17:49:56.680832: Epoch time: 76.69 s
2025-05-29 17:49:56.680881: Yayy! New best EMA pseudo Dice: 0.6444
2025-05-29 17:49:59.504980: 
2025-05-29 17:49:59.505417: Epoch 135
2025-05-29 17:49:59.505583: Current learning rate: 0.00584
2025-05-29 17:51:16.202514: train_loss -1.0637
2025-05-29 17:51:16.202959: val_loss -0.6688
2025-05-29 17:51:16.203105: Pseudo dice [0.9189, 0.6735, 0.4279, 0.6335, 0.3013, 0.9158, 0.5717, 0.7002]
2025-05-29 17:51:16.203184: Epoch time: 76.7 s
2025-05-29 17:51:18.164805: 
2025-05-29 17:51:18.165139: Epoch 136
2025-05-29 17:51:18.165294: Current learning rate: 0.00581
2025-05-29 17:52:32.051954: train_loss -1.1013
2025-05-29 17:52:32.052265: val_loss -0.7058
2025-05-29 17:52:32.052425: Pseudo dice [0.9328, 0.73, 0.4091, 0.6731, 0.2324, 0.9225, 0.6102, 0.7687]
2025-05-29 17:52:32.052533: Epoch time: 73.89 s
2025-05-29 17:52:32.052588: Yayy! New best EMA pseudo Dice: 0.6458
2025-05-29 17:52:34.838262: 
2025-05-29 17:52:34.838409: Epoch 137
2025-05-29 17:52:34.838516: Current learning rate: 0.00578
2025-05-29 17:53:49.313770: train_loss -1.1057
2025-05-29 17:53:49.314050: val_loss -0.7541
2025-05-29 17:53:49.314170: Pseudo dice [0.9183, 0.7262, 0.418, 0.7744, 0.1766, 0.9156, 0.5962, 0.7741]
2025-05-29 17:53:49.314276: Epoch time: 74.48 s
2025-05-29 17:53:49.314340: Yayy! New best EMA pseudo Dice: 0.6474
2025-05-29 17:53:52.210068: 
2025-05-29 17:53:52.210439: Epoch 138
2025-05-29 17:53:52.210714: Current learning rate: 0.00574
2025-05-29 17:55:08.442371: train_loss -1.0626
2025-05-29 17:55:08.442665: val_loss -0.6841
2025-05-29 17:55:08.442824: Pseudo dice [0.9248, 0.68, 0.4826, 0.6363, 0.2698, 0.8941, 0.5648, 0.7298]
2025-05-29 17:55:08.442949: Epoch time: 76.23 s
2025-05-29 17:55:08.443063: Yayy! New best EMA pseudo Dice: 0.6475
2025-05-29 17:55:11.146900: 
2025-05-29 17:55:11.147214: Epoch 139
2025-05-29 17:55:11.147312: Current learning rate: 0.00571
2025-05-29 17:56:27.839944: train_loss -1.1104
2025-05-29 17:56:27.840175: val_loss -0.7629
2025-05-29 17:56:27.840373: Pseudo dice [0.9165, 0.7144, 0.4479, 0.7642, 0.3491, 0.9208, 0.5908, 0.6923]
2025-05-29 17:56:27.840677: Epoch time: 76.69 s
2025-05-29 17:56:27.840929: Yayy! New best EMA pseudo Dice: 0.6502
2025-05-29 17:56:31.029805: 
2025-05-29 17:56:31.030343: Epoch 140
2025-05-29 17:56:31.030504: Current learning rate: 0.00568
2025-05-29 17:57:48.172163: train_loss -1.1057
2025-05-29 17:57:48.172906: val_loss -0.7771
2025-05-29 17:57:48.173163: Pseudo dice [0.9206, 0.7358, 0.4636, 0.808, 0.2171, 0.9199, 0.6023, 0.719]
2025-05-29 17:57:48.173292: Epoch time: 77.14 s
2025-05-29 17:57:48.173409: Yayy! New best EMA pseudo Dice: 0.6525
2025-05-29 17:57:50.967892: 
2025-05-29 17:57:50.968413: Epoch 141
2025-05-29 17:57:50.968530: Current learning rate: 0.00565
2025-05-29 17:59:08.650049: train_loss -1.1132
2025-05-29 17:59:08.650573: val_loss -0.714
2025-05-29 17:59:08.650741: Pseudo dice [0.921, 0.7172, 0.4119, 0.7274, 0.1496, 0.9082, 0.6286, 0.7122]
2025-05-29 17:59:08.650830: Epoch time: 77.68 s
2025-05-29 17:59:10.069965: 
2025-05-29 17:59:10.070416: Epoch 142
2025-05-29 17:59:10.070532: Current learning rate: 0.00562
2025-05-29 18:00:22.571193: train_loss -1.1327
2025-05-29 18:00:22.571501: val_loss -0.7647
2025-05-29 18:00:22.571630: Pseudo dice [0.9056, 0.7308, 0.4418, 0.7341, 0.1765, 0.9183, 0.6168, 0.6885]
2025-05-29 18:00:22.571718: Epoch time: 72.5 s
2025-05-29 18:00:23.976776: 
2025-05-29 18:00:23.977118: Epoch 143
2025-05-29 18:00:23.977274: Current learning rate: 0.00558
2025-05-29 18:01:41.272288: train_loss -1.0826
2025-05-29 18:01:41.272773: val_loss -0.6266
2025-05-29 18:01:41.272906: Pseudo dice [0.9219, 0.6707, 0.4341, 0.5644, 0.325, 0.9015, 0.5718, 0.7032]
2025-05-29 18:01:41.272985: Epoch time: 77.3 s
2025-05-29 18:01:42.675110: 
2025-05-29 18:01:42.675467: Epoch 144
2025-05-29 18:01:42.675617: Current learning rate: 0.00555
2025-05-29 18:02:59.015638: train_loss -1.1238
2025-05-29 18:02:59.015866: val_loss -0.6709
2025-05-29 18:02:59.015980: Pseudo dice [0.9159, 0.6687, 0.4547, 0.6975, 0.2012, 0.9206, 0.5756, 0.6372]
2025-05-29 18:02:59.016110: Epoch time: 76.34 s
2025-05-29 18:03:00.482722: 
2025-05-29 18:03:00.483032: Epoch 145
2025-05-29 18:03:00.483173: Current learning rate: 0.00552
2025-05-29 18:04:15.753237: train_loss -1.1103
2025-05-29 18:04:15.753465: val_loss -0.7408
2025-05-29 18:04:15.753601: Pseudo dice [0.9302, 0.7019, 0.4348, 0.7462, 0.1028, 0.911, 0.6043, 0.7193]
2025-05-29 18:04:15.753679: Epoch time: 75.27 s
2025-05-29 18:04:17.271166: 
2025-05-29 18:04:17.271549: Epoch 146
2025-05-29 18:04:17.271696: Current learning rate: 0.00549
2025-05-29 18:05:33.849927: train_loss -1.1022
2025-05-29 18:05:33.850163: val_loss -0.7153
2025-05-29 18:05:33.850353: Pseudo dice [0.9362, 0.6777, 0.3999, 0.7029, 0.2459, 0.9069, 0.607, 0.7335]
2025-05-29 18:05:33.850459: Epoch time: 76.58 s
2025-05-29 18:05:36.188582: 
2025-05-29 18:05:36.188819: Epoch 147
2025-05-29 18:05:36.188965: Current learning rate: 0.00546
2025-05-29 18:06:52.377719: train_loss -1.1229
2025-05-29 18:06:52.378006: val_loss -0.7254
2025-05-29 18:06:52.378165: Pseudo dice [0.9171, 0.7278, 0.4634, 0.7216, 0.2097, 0.9085, 0.6133, 0.6606]
2025-05-29 18:06:52.378284: Epoch time: 76.19 s
2025-05-29 18:06:53.746793: 
2025-05-29 18:06:53.747100: Epoch 148
2025-05-29 18:06:53.747235: Current learning rate: 0.00542
2025-05-29 18:08:07.783224: train_loss -1.1513
2025-05-29 18:08:07.783398: val_loss -0.732
2025-05-29 18:08:07.783524: Pseudo dice [0.9268, 0.7013, 0.3962, 0.7233, 0.1419, 0.8939, 0.5825, 0.6967]
2025-05-29 18:08:07.783602: Epoch time: 74.04 s
2025-05-29 18:08:09.190969: 
2025-05-29 18:08:09.191377: Epoch 149
2025-05-29 18:08:09.191574: Current learning rate: 0.00539
2025-05-29 18:09:23.660838: train_loss -1.1303
2025-05-29 18:09:23.661150: val_loss -0.7684
2025-05-29 18:09:23.661274: Pseudo dice [0.91, 0.6923, 0.4329, 0.7867, 0.2018, 0.8961, 0.6495, 0.6254]
2025-05-29 18:09:23.661426: Epoch time: 74.47 s
2025-05-29 18:09:26.378214: 
2025-05-29 18:09:26.378526: Epoch 150
2025-05-29 18:09:26.378669: Current learning rate: 0.00536
2025-05-29 18:10:40.835152: train_loss -1.1263
2025-05-29 18:10:40.835439: val_loss -0.7232
2025-05-29 18:10:40.835583: Pseudo dice [0.9343, 0.6608, 0.4034, 0.6948, 0.2052, 0.9102, 0.6282, 0.7102]
2025-05-29 18:10:40.835685: Epoch time: 74.46 s
2025-05-29 18:10:42.263539: Pseudo dice [0.9254, 0.7382, 0.4554, 0.7122, 0.0886, 0.9478, 0.5674, 0.7488]
2025-05-29 18:03:31.295531: Epoch time: 74.88 s
2025-05-29 18:03:32.932786: 
2025-05-29 18:03:32.933202: Epoch 153
2025-05-29 18:03:32.933358: Current learning rate: 0.00526
2025-05-29 18:04:47.476555: train_loss -1.1834
2025-05-29 18:04:47.476800: val_loss -0.7462
2025-05-29 18:04:47.476918: Pseudo dice [0.9343, 0.7718, 0.4227, 0.6948, 0.1937, 0.9454, 0.5807, 0.7516]
2025-05-29 18:04:47.477007: Epoch time: 74.55 s
2025-05-29 18:04:48.932320: 
2025-05-29 18:04:48.932752: Epoch 154
2025-05-29 18:04:48.932888: Current learning rate: 0.00523
2025-05-29 18:06:03.137502: train_loss -1.1552
2025-05-29 18:06:03.137726: val_loss -0.6705
2025-05-29 18:06:03.138020: Pseudo dice [0.9146, 0.7857, 0.4378, 0.6964, 0.1814, 0.917, 0.5709, 0.6773]
2025-05-29 18:06:03.138138: Epoch time: 74.21 s
2025-05-29 18:06:04.533998: 
2025-05-29 18:06:04.534355: Epoch 155
2025-05-29 18:06:04.534460: Current learning rate: 0.0052
2025-05-29 18:07:19.527331: train_loss -1.1657
2025-05-29 18:07:19.527575: val_loss -0.7341
2025-05-29 18:07:19.527716: Pseudo dice [0.9294, 0.743, 0.4605, 0.7446, 0.2998, 0.9128, 0.5288, 0.7298]
2025-05-29 18:07:19.528032: Epoch time: 74.99 s
2025-05-29 18:07:19.528203: Yayy! New best EMA pseudo Dice: 0.6417
2025-05-29 18:07:22.506658: 
2025-05-29 18:07:22.506967: Epoch 156
2025-05-29 18:07:22.507070: Current learning rate: 0.00517
2025-05-29 18:08:38.303120: train_loss -1.1705
2025-05-29 18:08:38.303337: val_loss -0.6946
2025-05-29 18:08:38.303485: Pseudo dice [0.9247, 0.7519, 0.451, 0.6693, 0.1982, 0.934, 0.5885, 0.759]
2025-05-29 18:08:38.303580: Epoch time: 75.8 s
2025-05-29 18:08:38.303646: Yayy! New best EMA pseudo Dice: 0.6435
2025-05-29 18:08:41.024315: 
2025-05-29 18:08:41.024687: Epoch 157
2025-05-29 18:08:41.024809: Current learning rate: 0.00513
2025-05-29 18:09:54.258862: train_loss -1.1893
2025-05-29 18:09:54.259247: val_loss -0.6707
2025-05-29 18:09:54.259486: Pseudo dice [0.9285, 0.741, 0.4537, 0.6921, 0.2694, 0.9398, 0.5446, 0.7261]
2025-05-29 18:09:54.259619: Epoch time: 73.24 s
2025-05-29 18:09:54.259677: Yayy! New best EMA pseudo Dice: 0.6453
2025-05-29 18:09:56.931379: 
2025-05-29 18:09:56.931756: Epoch 158
2025-05-29 18:09:56.931905: Current learning rate: 0.0051
2025-05-29 18:11:12.905730: train_loss -1.1898
2025-05-29 18:11:12.905944: val_loss -0.6726
2025-05-29 18:11:12.906059: Pseudo dice [0.9191, 0.7354, 0.4368, 0.6855, 0.0358, 0.9438, 0.5577, 0.7223]
2025-05-29 18:11:12.906149: Epoch time: 75.98 s
2025-05-29 18:11:14.303082: 
2025-05-29 18:11:14.303336: Epoch 159
2025-05-29 18:11:14.303435: Current learning rate: 0.00507
2025-05-29 18:12:29.182943: train_loss -1.1876
2025-05-29 18:12:29.183157: val_loss -0.6496
2025-05-29 18:12:29.183273: Pseudo dice [0.9188, 0.713, 0.4331, 0.6243, 0.1131, 0.9206, 0.5467, 0.7369]
2025-05-29 18:12:29.183358: Epoch time: 74.88 s
2025-05-29 18:12:30.571644: 
2025-05-29 18:12:30.571879: Epoch 160
2025-05-29 18:12:30.572035: Current learning rate: 0.00504
2025-05-29 18:13:45.867359: train_loss -1.1873
2025-05-29 18:13:45.867659: val_loss -0.732
2025-05-29 18:13:45.867779: Pseudo dice [0.9413, 0.7817, 0.4831, 0.625, 0.1486, 0.9365, 0.5886, 0.8269]
2025-05-29 18:13:45.867867: Epoch time: 75.3 s
2025-05-29 18:13:47.953851: 
2025-05-29 18:13:47.954221: Epoch 161
2025-05-29 18:13:47.954390: Current learning rate: 0.005
2025-05-29 18:15:02.975034: train_loss -1.1949
2025-05-29 18:15:02.975240: val_loss -0.7356
2025-05-29 18:15:02.975352: Pseudo dice [0.9382, 0.7803, 0.429, 0.7045, 0.2506, 0.9566, 0.5883, 0.755]
2025-05-29 18:15:02.975494: Epoch time: 75.02 s
2025-05-29 18:15:02.975654: Yayy! New best EMA pseudo Dice: 0.6475
2025-05-29 18:15:05.907024: 
2025-05-29 18:15:05.907364: Epoch 162
2025-05-29 18:15:05.907503: Current learning rate: 0.00497
2025-05-29 18:16:20.213442: train_loss -1.1924
2025-05-29 18:16:20.213667: val_loss -0.681
2025-05-29 18:16:20.232383: Pseudo dice [0.9376, 0.7738, 0.4609, 0.6134, 0.3704, 0.9556, 0.5795, 0.7457]
2025-05-29 18:16:20.232528: Epoch time: 74.31 s
2025-05-29 18:16:20.232587: Yayy! New best EMA pseudo Dice: 0.6507
2025-05-29 18:16:23.384903: 
2025-05-29 18:16:23.385318: Epoch 163
2025-05-29 18:16:23.385419: Current learning rate: 0.00494
2025-05-29 18:17:35.741353: train_loss -1.2031
2025-05-29 18:17:35.741610: val_loss -0.6955
2025-05-29 18:17:35.741726: Pseudo dice [0.923, 0.7823, 0.3762, 0.716, 0.1674, 0.9512, 0.5147, 0.6868]
2025-05-29 18:17:35.741806: Epoch time: 72.36 s
2025-05-29 18:17:37.171695: 
2025-05-29 18:17:37.171929: Epoch 164
2025-05-29 18:17:37.172214: Current learning rate: 0.00491
2025-05-29 18:18:49.809681: train_loss -1.1782
2025-05-29 18:18:49.809942: val_loss -0.6394
2025-05-29 18:18:49.810060: Pseudo dice [0.9167, 0.7437, 0.4567, 0.5908, 0.0414, 0.938, 0.5836, 0.7275]
2025-05-29 18:18:49.810144: Epoch time: 72.64 s
2025-05-29 18:18:51.170010: 
2025-05-29 18:18:51.170429: Epoch 165
2025-05-29 18:18:51.170539: Current learning rate: 0.00487
2025-05-29 18:20:06.307986: train_loss -1.1641
2025-05-29 18:20:06.308198: val_loss -0.6634
2025-05-29 18:20:06.308317: Pseudo dice [0.9182, 0.753, 0.4421, 0.6262, 0.2919, 0.9461, 0.5842, 0.6898]
2025-05-29 18:20:06.308399: Epoch time: 75.14 s
2025-05-29 18:20:07.722608: 
2025-05-29 18:20:07.722850: Epoch 166
2025-05-29 18:20:07.722952: Current learning rate: 0.00484
2025-05-29 18:21:20.987815: train_loss -1.2001
2025-05-29 18:21:20.988082: val_loss -0.6774
2025-05-29 18:21:20.988198: Pseudo dice [0.9295, 0.7662, 0.4096, 0.6354, 0.0756, 0.9501, 0.5308, 0.7322]
2025-05-29 18:21:20.988278: Epoch time: 73.27 s
2025-05-29 18:21:22.395150: 
2025-05-29 18:21:22.395295: Epoch 167
2025-05-29 18:21:22.395465: Current learning rate: 0.00481
2025-05-29 18:22:37.479920: train_loss -1.1799
2025-05-29 18:22:37.480166: val_loss -0.6541
2025-05-29 18:22:37.480375: Pseudo dice [0.9125, 0.7295, 0.4386, 0.648, 0.0865, 0.9334, 0.5203, 0.6739]
2025-05-29 18:22:37.480478: Epoch time: 75.09 s
2025-05-29 18:22:38.889310: 
2025-05-29 18:22:38.889603: Epoch 168
2025-05-29 18:22:38.889704: Current learning rate: 0.00478
2025-05-29 18:23:51.998033: train_loss -1.1579
2025-05-29 18:23:51.998242: val_loss -0.6603
2025-05-29 18:23:51.998353: Pseudo dice [0.9101, 0.7303, 0.4522, 0.5834, 0.2101, 0.9263, 0.5238, 0.7402]
2025-05-29 18:23:51.998430: Epoch time: 73.11 s
2025-05-29 18:23:53.456608: 
2025-05-29 18:23:53.456799: Epoch 169
2025-05-29 18:23:53.456898: Current learning rate: 0.00474
2025-05-29 18:25:06.007747: train_loss -1.1843
2025-05-29 18:25:06.007971: val_loss -0.671
2025-05-29 18:25:06.008087: Pseudo dice [0.9165, 0.7111, 0.4008, 0.6828, 0.0825, 0.9341, 0.5447, 0.7494]
2025-05-29 18:25:06.008166: Epoch time: 72.55 s
2025-05-29 18:25:07.395976: 
2025-05-29 18:25:07.396311: Epoch 170
2025-05-29 18:25:07.396413: Current learning rate: 0.00471
2025-05-29 18:26:20.699654: train_loss -1.1559
2025-05-29 18:26:20.699967: val_loss -0.6562
2025-05-29 18:26:20.700096: Pseudo dice [0.9106, 0.7169, 0.4303, 0.6755, 0.1412, 0.9238, 0.5711, 0.7303]
2025-05-29 18:26:20.700170: Epoch time: 73.31 s
2025-05-29 18:26:22.698147: 
2025-05-29 18:26:22.698361: Epoch 171
2025-05-29 18:26:22.698478: Current learning rate: 0.00468
2025-05-29 18:27:38.300335: train_loss -1.1448
2025-05-29 18:27:38.300603: val_loss -0.5668
2025-05-29 18:27:38.300714: Pseudo dice [0.9256, 0.7501, 0.4266, 0.4885, 0.2259, 0.9586, 0.5432, 0.8158]
2025-05-29 18:27:38.300790: Epoch time: 75.6 s
2025-05-29 18:27:39.671802: 
2025-05-29 18:27:39.672138: Epoch 172
2025-05-29 18:27:39.672333: Current learning rate: 0.00465
2025-05-29 18:28:55.416826: train_loss -1.147
2025-05-29 18:28:55.417237: val_loss -0.635
2025-05-29 18:28:55.417365: Pseudo dice [0.9214, 0.7367, 0.3258, 0.5972, 0.1194, 0.9329, 0.5381, 0.7396]
2025-05-29 18:28:55.417443: Epoch time: 75.75 s
2025-05-29 18:28:56.798439: 
2025-05-29 18:28:56.798815: Epoch 173
2025-05-29 18:28:56.798955: Current learning rate: 0.00461
2025-05-29 18:30:13.439012: train_loss -1.1562
2025-05-29 18:30:13.439338: val_loss -0.597
2025-05-29 18:30:13.439461: Pseudo dice [0.896, 0.6662, 0.4619, 0.6395, 0.255, 0.9484, 0.5459, 0.6871]
2025-05-29 18:30:13.439550: Pseudo dice [0.9012, 0.5623, 0.4445, 0.7024, 0.0112, 0.8652, 0.4788, 0.7787]
2025-05-29 18:06:13.105415: Epoch time: 89.71 s
2025-05-29 18:06:14.484007: 
2025-05-29 18:06:14.484400: Epoch 131
2025-05-29 18:06:14.484533: Current learning rate: 0.00597
2025-05-29 18:07:44.344826: train_loss -1.0092
2025-05-29 18:07:44.345027: val_loss -0.6924
2025-05-29 18:07:44.345144: Pseudo dice [0.8972, 0.589, 0.4262, 0.7141, 0.1676, 0.8752, 0.5343, 0.74]
2025-05-29 18:07:44.345328: Epoch time: 89.86 s
2025-05-29 18:07:45.716545: 
2025-05-29 18:07:45.716875: Epoch 132
2025-05-29 18:07:45.716972: Current learning rate: 0.00593
2025-05-29 18:09:14.994846: train_loss -1.0727
2025-05-29 18:09:14.995148: val_loss -0.6883
2025-05-29 18:09:14.995270: Pseudo dice [0.9011, 0.673, 0.4336, 0.6773, 0.0838, 0.8787, 0.4782, 0.8336]
2025-05-29 18:09:14.995364: Epoch time: 89.28 s
2025-05-29 18:09:16.380816: 
2025-05-29 18:09:16.381019: Epoch 133
2025-05-29 18:09:16.381129: Current learning rate: 0.0059
2025-05-29 18:10:45.512623: train_loss -1.0875
2025-05-29 18:10:45.512891: val_loss -0.7011
2025-05-29 18:10:45.513014: Pseudo dice [0.9041, 0.6481, 0.4837, 0.6696, 0.1445, 0.8803, 0.4869, 0.8159]
2025-05-29 18:10:45.513101: Epoch time: 89.13 s
2025-05-29 18:10:45.513165: Yayy! New best EMA pseudo Dice: 0.5995
2025-05-29 18:10:48.132261: 
2025-05-29 18:10:48.132669: Epoch 134
2025-05-29 18:10:48.132779: Current learning rate: 0.00587
2025-05-29 18:12:18.811522: train_loss -1.086
2025-05-29 18:12:18.811805: val_loss -0.6556
2025-05-29 18:12:18.811924: Pseudo dice [0.8977, 0.5566, 0.4431, 0.678, 0.1069, 0.8796, 0.5066, 0.7592]
2025-05-29 18:12:18.812024: Epoch time: 90.68 s
2025-05-29 18:12:18.812087: Yayy! New best EMA pseudo Dice: 0.5999
2025-05-29 18:12:21.704690: 
2025-05-29 18:12:21.704929: Epoch 135
2025-05-29 18:12:21.705144: Current learning rate: 0.00584
2025-05-29 18:13:51.031121: train_loss -1.104
2025-05-29 18:13:51.031408: val_loss -0.6587
2025-05-29 18:13:51.031537: Pseudo dice [0.9077, 0.6385, 0.4597, 0.6789, 0.0509, 0.874, 0.518, 0.8078]
2025-05-29 18:13:51.031622: Epoch time: 89.33 s
2025-05-29 18:13:51.031680: Yayy! New best EMA pseudo Dice: 0.6016
2025-05-29 18:13:54.021601: 
2025-05-29 18:13:54.021973: Epoch 136
2025-05-29 18:13:54.022075: Current learning rate: 0.00581
2025-05-29 18:15:23.851517: train_loss -1.0235
2025-05-29 18:15:23.851752: val_loss -0.5936
2025-05-29 18:15:23.851905: Pseudo dice [0.9005, 0.5739, 0.4224, 0.6006, 0.0775, 0.7859, 0.4151, 0.7944]
2025-05-29 18:15:23.851996: Epoch time: 89.83 s
2025-05-29 18:15:26.032315: 
2025-05-29 18:15:26.032590: Epoch 137
2025-05-29 18:15:26.032703: Current learning rate: 0.00578
2025-05-29 18:16:54.421840: train_loss -0.9812
2025-05-29 18:16:54.422116: val_loss -0.6694
2025-05-29 18:16:54.422233: Pseudo dice [0.8956, 0.5591, 0.4346, 0.6941, 0.1247, 0.8924, 0.4196, 0.7267]
2025-05-29 18:16:54.422320: Epoch time: 88.39 s
2025-05-29 18:16:55.811763: 
2025-05-29 18:16:55.811911: Epoch 138
2025-05-29 18:16:55.812004: Current learning rate: 0.00574
2025-05-29 18:18:21.428399: train_loss -1.0045
2025-05-29 18:18:21.428730: val_loss -0.6578
2025-05-29 18:18:21.428859: Pseudo dice [0.8994, 0.6043, 0.4743, 0.7012, 0.085, 0.9003, 0.4745, 0.7591]
2025-05-29 18:18:21.428936: Epoch time: 85.62 s
2025-05-29 18:18:22.820114: 
2025-05-29 18:18:22.820294: Epoch 139
2025-05-29 18:18:22.820484: Current learning rate: 0.00571
2025-05-29 18:19:45.574023: train_loss -1.0403
2025-05-29 18:19:45.574704: val_loss -0.6008
2025-05-29 18:19:45.574824: Pseudo dice [0.8837, 0.4994, 0.4117, 0.6716, 0.1037, 0.8842, 0.5035, 0.756]
2025-05-29 18:19:45.574909: Epoch time: 82.76 s
2025-05-29 18:19:47.257740: 
2025-05-29 18:19:47.258086: Epoch 140
2025-05-29 18:19:47.258281: Current learning rate: 0.00568
2025-05-29 18:21:17.002941: train_loss -1.0089
2025-05-29 18:21:17.003309: val_loss -0.6273
2025-05-29 18:21:17.003486: Pseudo dice [0.8976, 0.5296, 0.4021, 0.7123, 0.1013, 0.815, 0.5387, 0.769]
2025-05-29 18:21:17.003619: Epoch time: 89.75 s
2025-05-29 18:21:18.417124: 
2025-05-29 18:21:18.417491: Epoch 141
2025-05-29 18:21:18.417655: Current learning rate: 0.00565
2025-05-29 18:22:48.311825: train_loss -1.069
2025-05-29 18:22:48.312066: val_loss -0.663
2025-05-29 18:22:48.312178: Pseudo dice [0.9082, 0.6251, 0.4675, 0.6792, 0.0774, 0.8452, 0.5125, 0.7982]
2025-05-29 18:22:48.312265: Epoch time: 89.9 s
2025-05-29 18:22:49.684027: 
2025-05-29 18:22:49.684157: Epoch 142
2025-05-29 18:22:49.684249: Current learning rate: 0.00562
2025-05-29 18:24:19.882314: train_loss -1.0869
2025-05-29 18:24:19.882658: val_loss -0.7016
2025-05-29 18:24:19.882779: Pseudo dice [0.9072, 0.6074, 0.4515, 0.682, 0.1726, 0.8635, 0.5104, 0.7778]
2025-05-29 18:24:19.882881: Epoch time: 90.2 s
2025-05-29 18:24:19.882938: Yayy! New best EMA pseudo Dice: 0.602
2025-05-29 18:24:22.534024: 
2025-05-29 18:24:22.534348: Epoch 143
2025-05-29 18:24:22.534477: Current learning rate: 0.00558
2025-05-29 18:25:51.976162: train_loss -1.0747
2025-05-29 18:25:51.976372: val_loss -0.5301
2025-05-29 18:25:51.976502: Pseudo dice [0.8644, 0.5831, 0.4096, 0.5601, 0.0108, 0.8835, 0.4291, 0.7238]
2025-05-29 18:25:51.976583: Epoch time: 89.44 s
2025-05-29 18:25:53.339500: 
2025-05-29 18:25:53.339835: Epoch 144
2025-05-29 18:25:53.339981: Current learning rate: 0.00555
2025-05-29 18:27:22.439996: train_loss -1.0389
2025-05-29 18:27:22.440280: val_loss -0.6645
2025-05-29 18:27:22.440392: Pseudo dice [0.8947, 0.5976, 0.4124, 0.7515, 0.0183, 0.8694, 0.4943, 0.7514]
2025-05-29 18:27:22.440481: Epoch time: 89.1 s
2025-05-29 18:27:23.804380: 
2025-05-29 18:27:23.804730: Epoch 145
2025-05-29 18:27:23.804843: Current learning rate: 0.00552
2025-05-29 18:28:53.808563: train_loss -1.1013
2025-05-29 18:28:53.808773: val_loss -0.5975
2025-05-29 18:28:53.808903: Pseudo dice [0.9037, 0.6881, 0.4634, 0.5531, 0.0574, 0.8438, 0.5287, 0.7773]
2025-05-29 18:28:53.808985: Epoch time: 90.01 s
2025-05-29 18:28:55.179955: 
2025-05-29 18:28:55.180290: Epoch 146
2025-05-29 18:28:55.180385: Current learning rate: 0.00549
2025-05-29 18:30:25.420859: train_loss -1.0953
2025-05-29 18:30:25.421064: val_loss -0.7358
2025-05-29 18:30:25.421175: Pseudo dice [0.9133, 0.6615, 0.4113, 0.7344, 0.0509, 0.8739, 0.4688, 0.8158]
2025-05-29 18:30:25.421253: Epoch time: 90.24 s
2025-05-29 18:30:26.770875: 
2025-05-29 18:30:26.771023: Epoch 147
2025-05-29 18:30:26.771112: Current learning rate: 0.00546
2025-05-29 18:31:57.784940: train_loss -1.1076
2025-05-29 18:31:57.785163: val_loss -0.7191
2025-05-29 18:31:57.785283: Pseudo dice [0.9164, 0.5859, 0.4402, 0.7207, 0.0477, 0.9136, 0.5305, 0.7788]
2025-05-29 18:31:57.785365: Epoch time: 91.02 s
2025-05-29 18:31:59.801511: 
2025-05-29 18:31:59.801731: Epoch 148
2025-05-29 18:31:59.801830: Current learning rate: 0.00542
2025-05-29 18:33:25.547720: train_loss -1.0908
2025-05-29 18:33:25.547962: val_loss -0.6211
2025-05-29 18:33:25.548078: Pseudo dice [0.9092, 0.6412, 0.5106, 0.5936, 0.0208, 0.8877, 0.5068, 0.7854]
2025-05-29 18:33:25.548167: Epoch time: 85.75 s
2025-05-29 18:33:25.548227: Yayy! New best EMA pseudo Dice: 0.6021
2025-05-29 18:33:28.275591: 
2025-05-29 18:33:28.275876: Epoch 149
2025-05-29 18:33:28.276011: Current learning rate: 0.00539
2025-05-29 18:34:52.411660: train_loss -1.1122
2025-05-29 18:34:52.411948: val_loss -0.6863
2025-05-29 18:34:52.412067: Pseudo dice [0.9011, 0.5964, 0.4437, 0.7413, 0.0116, 0.8819, 0.5343, 0.7656]
2025-05-29 18:34:52.412153: Epoch time: 84.14 s
2025-05-29 18:34:53.596302: Yayy! New best EMA pseudo Dice: 0.6029
2025-05-29 18:34:56.074717: 
2025-05-29 18:34:56.075051: Epoch 150
2025-05-29 18:34:56.075145: Current learning rate: 0.00536
2025-05-29 18:36:24.126187: train_loss -1.1193
2025-05-29 18:36:24.126480: val_loss -0.6212
2025-05-29 18:36:24.126608: Pseudo dice [0.9087, 0.651, 0.4492, 0.6127, 0.1092, 0.8101, 0.517, 0.7719]
2025-05-29 18:36:24.126706: Epoch time: 88.05 s
2025-05-29 18:36:24.126756: Yayy! New best EMA pseudo Dice: 0.603
2025-05-29 18:36:26.846165: 
2025-05-29 18:36:26.846415: Epoch 151
2025-05-29 18:36:26.846537: Current learning rate: 0.00533
2025-05-29 18:37:56.106371: train_loss -1.1246
2025-05-29 18:37:56.106664:  
2025-05-29 18:10:42.264265: Epoch 151
2025-05-29 18:10:42.264377: Current learning rate: 0.00533
2025-05-29 18:11:58.912418: train_loss -1.1421
2025-05-29 18:11:58.912771: val_loss -0.7579
2025-05-29 18:11:58.912901: Pseudo dice [0.92, 0.7338, 0.4809, 0.8209, 0.2445, 0.9042, 0.5869, 0.6004]
2025-05-29 18:11:58.912990: Epoch time: 76.65 s
2025-05-29 18:12:00.293566: 
2025-05-29 18:12:00.293782: Epoch 152
2025-05-29 18:12:00.293902: Current learning rate: 0.00529
2025-05-29 18:13:16.863849: train_loss -1.1396
2025-05-29 18:13:16.864247: val_loss -0.7467
2025-05-29 18:13:16.864427: Pseudo dice [0.9214, 0.7093, 0.4387, 0.7782, 0.2545, 0.9069, 0.5793, 0.5904]
2025-05-29 18:13:16.864525: Epoch time: 76.57 s
2025-05-29 18:13:18.275798: 
2025-05-29 18:13:18.276204: Epoch 153
2025-05-29 18:13:18.276338: Current learning rate: 0.00526
2025-05-29 18:14:33.821208: train_loss -1.1537
2025-05-29 18:14:33.821495: val_loss -0.7445
2025-05-29 18:14:33.821616: Pseudo dice [0.9246, 0.7335, 0.3887, 0.7247, 0.3211, 0.9067, 0.5824, 0.6054]
2025-05-29 18:14:33.821699: Epoch time: 75.55 s
2025-05-29 18:14:35.487249: 
2025-05-29 18:14:35.487560: Epoch 154
2025-05-29 18:14:35.487712: Current learning rate: 0.00523
2025-05-29 18:15:49.275388: train_loss -1.1129
2025-05-29 18:15:49.275805: val_loss -0.8056
2025-05-29 18:15:49.275938: Pseudo dice [0.9382, 0.749, 0.446, 0.7823, 0.2577, 0.9195, 0.6146, 0.7255]
2025-05-29 18:15:49.276041: Epoch time: 73.79 s
2025-05-29 18:15:50.658289: 
2025-05-29 18:15:50.658638: Epoch 155
2025-05-29 18:15:50.658796: Current learning rate: 0.0052
2025-05-29 18:17:03.939813: train_loss -1.1195
2025-05-29 18:17:03.940085: val_loss -0.7727
2025-05-29 18:17:03.940204: Pseudo dice [0.9307, 0.7054, 0.4553, 0.739, 0.3214, 0.9178, 0.6374, 0.7592]
2025-05-29 18:17:03.940292: Epoch time: 73.28 s
2025-05-29 18:17:03.940357: Yayy! New best EMA pseudo Dice: 0.6547
2025-05-29 18:17:06.816404: 
2025-05-29 18:17:06.816816: Epoch 156
2025-05-29 18:17:06.816914: Current learning rate: 0.00517
2025-05-29 18:18:22.965018: train_loss -1.1244
2025-05-29 18:18:22.965373: val_loss -0.7202
2025-05-29 18:18:22.965493: Pseudo dice [0.9404, 0.6864, 0.4451, 0.7254, 0.233, 0.8806, 0.6101, 0.699]
2025-05-29 18:18:22.965579: Epoch time: 76.15 s
2025-05-29 18:18:25.713625: 
2025-05-29 18:18:25.714133: Epoch 157
2025-05-29 18:18:25.714266: Current learning rate: 0.00513
2025-05-29 18:19:42.539788: train_loss -1.1198
2025-05-29 18:19:42.540315: val_loss -0.7293
2025-05-29 18:19:42.540436: Pseudo dice [0.9167, 0.6995, 0.4199, 0.7471, 0.1861, 0.9124, 0.5746, 0.6726]
2025-05-29 18:19:42.540590: Epoch time: 76.83 s
2025-05-29 18:19:43.950152: 
2025-05-29 18:19:43.950486: Epoch 158
2025-05-29 18:19:43.950586: Current learning rate: 0.0051
2025-05-29 18:21:00.987662: train_loss -1.1551
2025-05-29 18:21:00.987982: val_loss -0.8142
2025-05-29 18:21:00.988194: Pseudo dice [0.9303, 0.7444, 0.4746, 0.7918, 0.2896, 0.9384, 0.6332, 0.7602]
2025-05-29 18:21:00.988283: Epoch time: 77.04 s
2025-05-29 18:21:00.988337: Yayy! New best EMA pseudo Dice: 0.6573
2025-05-29 18:21:03.729895: 
2025-05-29 18:21:03.730172: Epoch 159
2025-05-29 18:21:03.730269: Current learning rate: 0.00507
2025-05-29 18:22:19.975761: train_loss -1.159
2025-05-29 18:22:19.975989: val_loss -0.6665
2025-05-29 18:22:19.976104: Pseudo dice [0.9088, 0.6771, 0.416, 0.6744, 0.2625, 0.9189, 0.6067, 0.7003]
2025-05-29 18:22:19.976191: Epoch time: 76.25 s
2025-05-29 18:22:21.404737: 
2025-05-29 18:22:21.405081: Epoch 160
2025-05-29 18:22:21.405195: Current learning rate: 0.00504
2025-05-29 18:23:38.598651: train_loss -1.1607
2025-05-29 18:23:38.598876: val_loss -0.7671
2025-05-29 18:23:38.598993: Pseudo dice [0.9197, 0.7068, 0.4199, 0.7245, 0.319, 0.932, 0.6438, 0.7341]
2025-05-29 18:23:38.599071: Epoch time: 77.2 s
2025-05-29 18:23:38.599128: Yayy! New best EMA pseudo Dice: 0.658
2025-05-29 18:23:41.412339: 
2025-05-29 18:23:41.412714: Epoch 161
2025-05-29 18:23:41.412809: Current learning rate: 0.005
2025-05-29 18:24:56.964018: train_loss -1.1529
2025-05-29 18:24:56.964228: val_loss -0.7842
2025-05-29 18:24:56.964342: Pseudo dice [0.9375, 0.7631, 0.4717, 0.768, 0.3642, 0.9173, 0.6027, 0.7715]
2025-05-29 18:24:56.964424: Epoch time: 75.55 s
2025-05-29 18:24:56.964489: Yayy! New best EMA pseudo Dice: 0.6622
2025-05-29 18:24:59.684421: 
2025-05-29 18:24:59.684772: Epoch 162
2025-05-29 18:24:59.684870: Current learning rate: 0.00497
2025-05-29 18:26:16.434319: train_loss -1.1893
2025-05-29 18:26:16.434540: val_loss -0.7484
2025-05-29 18:26:16.434657: Pseudo dice [0.9318, 0.7194, 0.4773, 0.7399, 0.3529, 0.9129, 0.6338, 0.6524]
2025-05-29 18:26:16.434740: Epoch time: 76.75 s
2025-05-29 18:26:16.434792: Yayy! New best EMA pseudo Dice: 0.6637
2025-05-29 18:26:19.088741: 
2025-05-29 18:26:19.089028: Epoch 163
2025-05-29 18:26:19.089122: Current learning rate: 0.00494
2025-05-29 18:27:35.407676: train_loss -1.1652
2025-05-29 18:27:35.407992: val_loss -0.6331
2025-05-29 18:27:35.408121: Pseudo dice [0.9336, 0.7181, 0.3904, 0.6474, 0.2191, 0.9305, 0.6067, 0.6782]
2025-05-29 18:27:35.408218: Epoch time: 76.32 s
2025-05-29 18:27:36.798288: 
2025-05-29 18:27:36.798649: Epoch 164
2025-05-29 18:27:36.798800: Current learning rate: 0.00491
2025-05-29 18:28:53.672776: train_loss -1.1726
2025-05-29 18:28:53.673037: val_loss -0.7117
2025-05-29 18:28:53.673161: Pseudo dice [0.9217, 0.6721, 0.419, 0.7144, 0.3085, 0.9015, 0.6195, 0.6995]
2025-05-29 18:28:53.673248: Epoch time: 76.88 s
2025-05-29 18:28:55.045652: 
2025-05-29 18:28:55.045862: Epoch 165
2025-05-29 18:28:55.045994: Current learning rate: 0.00487
2025-05-29 18:30:12.402681: train_loss -1.1501
2025-05-29 18:30:12.402897: val_loss -0.8096
2025-05-29 18:30:12.403016: Pseudo dice [0.914, 0.7449, 0.4224, 0.7934, 0.2144, 0.9374, 0.611, 0.6936]
2025-05-29 18:30:12.403109: Epoch time: 77.36 s
2025-05-29 18:30:13.774151: 
2025-05-29 18:30:13.774389: Epoch 166
2025-05-29 18:30:13.774496: Current learning rate: 0.00484
2025-05-29 18:31:31.256635: train_loss -1.1331
2025-05-29 18:31:31.256861: val_loss -0.7908
2025-05-29 18:31:31.257020: Pseudo dice [0.9273, 0.7264, 0.4378, 0.7593, 0.308, 0.9268, 0.594, 0.7619]
2025-05-29 18:31:31.257176: Epoch time: 77.48 s
2025-05-29 18:31:32.616069: 
2025-05-29 18:31:32.616324: Epoch 167
2025-05-29 18:31:32.616424: Current learning rate: 0.00481
2025-05-29 18:32:51.744308: train_loss -1.1859
2025-05-29 18:32:51.744702: val_loss -0.7661
2025-05-29 18:32:51.745034: Pseudo dice [0.9408, 0.716, 0.4564, 0.7512, 0.3002, 0.9266, 0.5932, 0.7423]
2025-05-29 18:32:51.745217: Epoch time: 79.13 s
2025-05-29 18:32:51.745316: Yayy! New best EMA pseudo Dice: 0.6649
2025-05-29 18:32:54.324902: 
2025-05-29 18:32:54.325175: Epoch 168
2025-05-29 18:32:54.325286: Current learning rate: 0.00478
2025-05-29 18:34:10.646629: train_loss -1.1588
2025-05-29 18:34:10.646858: val_loss -0.6905
2025-05-29 18:34:10.646985: Pseudo dice [0.9228, 0.7407, 0.4126, 0.7037, 0.2421, 0.9321, 0.569, 0.6698]
2025-05-29 18:34:10.647079: Epoch time: 76.32 s
2025-05-29 18:34:12.029796: 
2025-05-29 18:34:12.030141: Epoch 169
2025-05-29 18:34:12.030262: Current learning rate: 0.00474
2025-05-29 18:35:29.725085: train_loss -1.1605
2025-05-29 18:35:29.725353: val_loss -0.7748
2025-05-29 18:35:29.725482: Pseudo dice [0.9393, 0.7158, 0.4517, 0.7734, 0.0887, 0.8983, 0.5469, 0.7283]
2025-05-29 18:35:29.725568: Epoch time: 77.7 s
2025-05-29 18:35:31.109938: 
2025-05-29 18:35:31.110132: Epoch 170
2025-05-29 18:35:31.110307: Current learning rate: 0.00471
2025-05-29 18:36:46.611649: train_loss -1.1816
2025-05-29 18:36:46.611864: val_loss -0.7546
2025-05-29 18:36:46.611978: Pseudo dice [0.9225, 0.7779, 0.4443, 0.7924, 0.2073, 0.9373, 0.636, 0.7091]
2025-05-29 18:36:46.612103: Epoch time: 75.5 s
2025-05-29 18:36:48.010237: 
2025-05-29 18:36:48.010378: Epoch 171
2025-05-29 18:36:48.010512: Current learning rate: 0.00468
2025-05-29 18:38:04.156554: train_loss -1.1677
2025-05-29 18:38:04.156780: val_loss -0.78
2025-05-29 18:38:04.156897: Pseudo dice [0.9188, 0.6899, 0.515, 0.8053, 0.3277, 0.9227, 0.624, 0.6502]
2025-05-29 18:38:04.157036: Epoch time: 76.15 s
2025-05-29 18:38:05.555306: 
2025-05-29 18:38:05.555594: Epoch 172 Epoch time: 76.64 s
2025-05-29 18:30:14.806740: 
2025-05-29 18:30:14.807099: Epoch 174
2025-05-29 18:30:14.807190: Current learning rate: 0.00458
2025-05-29 18:31:31.709260: train_loss -1.1775
2025-05-29 18:31:31.709484: val_loss -0.6978
2025-05-29 18:31:31.709604: Pseudo dice [0.917, 0.7568, 0.4463, 0.6675, 0.2381, 0.9407, 0.5598, 0.6838]
2025-05-29 18:31:31.709689: Epoch time: 76.9 s
2025-05-29 18:31:33.068004: 
2025-05-29 18:31:33.068375: Epoch 175
2025-05-29 18:31:33.068506: Current learning rate: 0.00455
2025-05-29 18:32:51.149088: train_loss -1.194
2025-05-29 18:32:51.149333: val_loss -0.7347
2025-05-29 18:32:51.149508: Pseudo dice [0.9334, 0.7585, 0.4292, 0.6917, 0.1244, 0.9422, 0.6189, 0.7839]
2025-05-29 18:32:51.149653: Epoch time: 78.08 s
2025-05-29 18:32:52.565017: 
2025-05-29 18:32:52.565387: Epoch 176
2025-05-29 18:32:52.565491: Current learning rate: 0.00452
2025-05-29 18:34:07.431850: train_loss -1.2067
2025-05-29 18:34:07.432053: val_loss -0.6897
2025-05-29 18:34:07.432162: Pseudo dice [0.9252, 0.7835, 0.4802, 0.6407, 0.2729, 0.9474, 0.5337, 0.7232]
2025-05-29 18:34:07.432242: Epoch time: 74.87 s
2025-05-29 18:34:08.822592: 
2025-05-29 18:34:08.822847: Epoch 177
2025-05-29 18:34:08.822998: Current learning rate: 0.00448
2025-05-29 18:35:25.090942: train_loss -1.2048
2025-05-29 18:35:25.091176: val_loss -0.6442
2025-05-29 18:35:25.091299: Pseudo dice [0.9148, 0.7639, 0.462, 0.6559, 0.1636, 0.9372, 0.5216, 0.7242]
2025-05-29 18:35:25.091385: Epoch time: 76.27 s
2025-05-29 18:35:26.469059: 
2025-05-29 18:35:26.469413: Epoch 178
2025-05-29 18:35:26.469517: Current learning rate: 0.00445
2025-05-29 18:36:41.143139: train_loss -1.176
2025-05-29 18:36:41.143347: val_loss -0.5959
2025-05-29 18:36:41.143468: Pseudo dice [0.9166, 0.7323, 0.4114, 0.5334, 0.0635, 0.9131, 0.5603, 0.7078]
2025-05-29 18:36:41.143555: Epoch time: 74.68 s
2025-05-29 18:36:42.577231: 
2025-05-29 18:36:42.577790: Epoch 179
2025-05-29 18:36:42.577980: Current learning rate: 0.00442
2025-05-29 18:37:57.844720: train_loss -1.1726
2025-05-29 18:37:57.845085: val_loss -0.6596
2025-05-29 18:37:57.845255: Pseudo dice [0.9256, 0.7324, 0.4205, 0.6561, 0.2632, 0.9554, 0.516, 0.7149]
2025-05-29 18:37:57.845348: Epoch time: 75.27 s
2025-05-29 18:37:59.236144: 
2025-05-29 18:37:59.236583: Epoch 180
2025-05-29 18:37:59.236713: Current learning rate: 0.00438
2025-05-29 18:39:15.693090: train_loss -1.2
2025-05-29 18:39:15.693408: val_loss -0.7394
2025-05-29 18:39:15.693537: Pseudo dice [0.9352, 0.7742, 0.4256, 0.709, 0.2206, 0.95, 0.5618, 0.7718]
2025-05-29 18:39:15.693633: Epoch time: 76.46 s
2025-05-29 18:39:17.071883: 
2025-05-29 18:39:17.072300: Epoch 181
2025-05-29 18:39:17.072429: Current learning rate: 0.00435
2025-05-29 18:40:30.202067: train_loss -1.2019
2025-05-29 18:40:30.202337: val_loss -0.6628
2025-05-29 18:40:30.202463: Pseudo dice [0.9201, 0.7004, 0.3859, 0.601, 0.2134, 0.8851, 0.5317, 0.6849]
2025-05-29 18:40:30.202553: Epoch time: 73.13 s
2025-05-29 18:40:32.258586: 
2025-05-29 18:40:32.258836: Epoch 182
2025-05-29 18:40:32.258929: Current learning rate: 0.00432
2025-05-29 18:41:45.113768: train_loss -1.2007
2025-05-29 18:41:45.113981: val_loss -0.7004
2025-05-29 18:41:45.114083: Pseudo dice [0.9273, 0.7328, 0.4684, 0.682, 0.2289, 0.9449, 0.6116, 0.6977]
2025-05-29 18:41:45.114160: Epoch time: 72.86 s
2025-05-29 18:41:46.493932: 
2025-05-29 18:41:46.494142: Epoch 183
2025-05-29 18:41:46.494295: Current learning rate: 0.00429
2025-05-29 18:42:59.116919: train_loss -1.2104
2025-05-29 18:42:59.117215: val_loss -0.6233
2025-05-29 18:42:59.117353: Pseudo dice [0.9139, 0.7383, 0.4049, 0.6637, 0.2398, 0.9276, 0.5464, 0.6388]
2025-05-29 18:42:59.117468: Epoch time: 72.62 s
2025-05-29 18:43:00.545499: 
2025-05-29 18:43:00.545940: Epoch 184
2025-05-29 18:43:00.546044: Current learning rate: 0.00425
2025-05-29 18:44:13.859557: train_loss -1.2229
2025-05-29 18:44:13.859884: val_loss -0.7348
2025-05-29 18:44:13.860012: Pseudo dice [0.9321, 0.7724, 0.4225, 0.6998, 0.2415, 0.9388, 0.5627, 0.7453]
2025-05-29 18:44:13.860116: Epoch time: 73.32 s
2025-05-29 18:44:15.316361: 
2025-05-29 18:44:15.316663: Epoch 185
2025-05-29 18:44:15.316983: Current learning rate: 0.00422
2025-05-29 18:45:27.970416: train_loss -1.229
2025-05-29 18:45:27.971328: val_loss -0.7041
2025-05-29 18:45:27.971548: Pseudo dice [0.924, 0.7764, 0.3983, 0.7154, 0.1769, 0.9363, 0.5953, 0.653]
2025-05-29 18:45:27.971700: Epoch time: 72.66 s
2025-05-29 18:45:29.415504: 
2025-05-29 18:45:29.416032: Epoch 186
2025-05-29 18:45:29.416172: Current learning rate: 0.00419
2025-05-29 18:46:44.679957: train_loss -1.2071
2025-05-29 18:46:44.680335: val_loss -0.7066
2025-05-29 18:46:44.680476: Pseudo dice [0.9274, 0.7625, 0.3819, 0.6374, 0.2225, 0.933, 0.5802, 0.7323]
2025-05-29 18:46:44.680576: Epoch time: 75.27 s
2025-05-29 18:46:46.083518: 
2025-05-29 18:46:46.083885: Epoch 187
2025-05-29 18:46:46.084008: Current learning rate: 0.00415
2025-05-29 18:48:01.546777: train_loss -1.2086
2025-05-29 18:48:01.547570: val_loss -0.6486
2025-05-29 18:48:01.547780: Pseudo dice [0.9184, 0.7872, 0.4288, 0.6457, 0.2043, 0.9353, 0.5531, 0.688]
2025-05-29 18:48:01.547950: Epoch time: 75.46 s
2025-05-29 18:48:03.035177: 
2025-05-29 18:48:03.035503: Epoch 188
2025-05-29 18:48:03.035667: Current learning rate: 0.00412
2025-05-29 18:49:16.197823: train_loss -1.2225
2025-05-29 18:49:16.198361: val_loss -0.7417
2025-05-29 18:49:16.198517: Pseudo dice [0.9271, 0.739, 0.4172, 0.723, 0.122, 0.9459, 0.6101, 0.7235]
2025-05-29 18:49:16.198690: Epoch time: 73.16 s
2025-05-29 18:49:17.631979: 
2025-05-29 18:49:17.632271: Epoch 189
2025-05-29 18:49:17.632445: Current learning rate: 0.00409
2025-05-29 18:50:30.733153: train_loss -1.2053
2025-05-29 18:50:30.733418: val_loss -0.67
2025-05-29 18:50:30.733545: Pseudo dice [0.9207, 0.7164, 0.448, 0.6207, 0.1364, 0.9381, 0.5836, 0.7037]
2025-05-29 18:50:30.733637: Epoch time: 73.1 s
2025-05-29 18:50:32.163258: 
2025-05-29 18:50:32.163611: Epoch 190
2025-05-29 18:50:32.163724: Current learning rate: 0.00405
2025-05-29 18:51:46.102157: train_loss -1.1994
2025-05-29 18:51:46.102389: val_loss -0.632
2025-05-29 18:51:46.102520: Pseudo dice [0.926, 0.7311, 0.4136, 0.5727, 0.241, 0.9159, 0.5481, 0.7511]
2025-05-29 18:51:46.102721: Epoch time: 73.94 s
2025-05-29 18:51:47.505995: 
2025-05-29 18:51:47.506335: Epoch 191
2025-05-29 18:51:47.506566: Current learning rate: 0.00402
2025-05-29 18:53:00.631547: train_loss -1.198
2025-05-29 18:53:00.631892: val_loss -0.7162
2025-05-29 18:53:00.632013: Pseudo dice [0.9203, 0.7349, 0.4668, 0.6986, 0.2088, 0.9501, 0.5786, 0.7839]
2025-05-29 18:53:00.632118: Epoch time: 73.13 s
2025-05-29 18:53:02.015247: 
2025-05-29 18:53:02.015560: Epoch 192
2025-05-29 18:53:02.015680: Current learning rate: 0.00399
2025-05-29 18:54:15.606758: train_loss -1.1911
2025-05-29 18:54:15.607026: val_loss -0.6763
2025-05-29 18:54:15.607169: Pseudo dice [0.907, 0.768, 0.4537, 0.6929, 0.2479, 0.9275, 0.5734, 0.7054]
2025-05-29 18:54:15.607259: Epoch time: 73.59 s
2025-05-29 18:54:17.977819: 
2025-05-29 18:54:17.978134: Epoch 193
2025-05-29 18:54:17.978234: Current learning rate: 0.00395
2025-05-29 18:55:32.831342: train_loss -1.1977
2025-05-29 18:55:32.831631: val_loss -0.661
2025-05-29 18:55:32.831760: Pseudo dice [0.924, 0.7734, 0.4319, 0.6437, 0.2886, 0.9293, 0.5376, 0.7084]
2025-05-29 18:55:32.831939: Epoch time: 74.85 s
2025-05-29 18:55:34.249311: 
2025-05-29 18:55:34.249749: Epoch 194
2025-05-29 18:55:34.249852: Current learning rate: 0.00392
2025-05-29 18:56:48.913513: train_loss -1.2013
2025-05-29 18:56:48.913785: val_loss -0.6434
2025-05-29 18:56:48.913895: Pseudo dice [0.9143, 0.711, 0.4262, 0.6741, 0.1952, 0.9382, 0.5746, 0.6786]
2025-05-29 18:56:48.913973: Epoch time: 74.67 s
2025-05-29 18:56:50.329750: 
2025-05-29 18:56:50.330257: Epoch 195
2025-05-29 18:56:50.330371: Current learning rate: 0.00389
2025-05-29 18:58:05.871312: train_loss -1.1829
2025-05-29 18:58:05.871607: val_loss -0.6854
2025-05-29 18:58:05.871750: Pseudo dice [0.9223, 0.7474, 0.4201, 0.7185, 0.1645, 0.9341, 0.5955, 0.6785]
2025-05-29 18:58:05.871839: Epoch time: 75.54 s
2025-05-29 18:58:07.262034: 
2025-05-29 18:58:07.262322:
2025-05-29 18:38:05.556051: Current learning rate: 0.00465
2025-05-29 18:39:22.653236: train_loss -1.1767
2025-05-29 18:39:22.653518: val_loss -0.7903
2025-05-29 18:39:22.653651: Pseudo dice [0.9226, 0.7637, 0.4449, 0.7875, 0.1268, 0.9235, 0.5992, 0.772]
2025-05-29 18:39:22.653754: Epoch time: 77.1 s
2025-05-29 18:39:22.653805: Yayy! New best EMA pseudo Dice: 0.6651
2025-05-29 18:39:25.292048: 
2025-05-29 18:39:25.292370: Epoch 173
2025-05-29 18:39:25.292510: Current learning rate: 0.00461
2025-05-29 18:40:40.751898: train_loss -1.1891
2025-05-29 18:40:40.752122: val_loss -0.7857
2025-05-29 18:40:40.752244: Pseudo dice [0.9242, 0.7277, 0.4923, 0.805, 0.3276, 0.9328, 0.6023, 0.658]
2025-05-29 18:40:40.752331: Epoch time: 75.46 s
2025-05-29 18:40:40.752385: Yayy! New best EMA pseudo Dice: 0.667
2025-05-29 18:40:43.725468: 
2025-05-29 18:40:43.725842: Epoch 174
2025-05-29 18:40:43.725942: Current learning rate: 0.00458
2025-05-29 18:42:00.456312: train_loss -1.1871
2025-05-29 18:42:00.456618: val_loss -0.8066
2025-05-29 18:42:00.456745: Pseudo dice [0.9295, 0.7338, 0.4188, 0.7893, 0.3194, 0.9256, 0.6114, 0.7523]
2025-05-29 18:42:00.456831: Epoch time: 76.73 s
2025-05-29 18:42:00.456886: Yayy! New best EMA pseudo Dice: 0.6688
2025-05-29 18:42:03.357992: 
2025-05-29 18:42:03.358399: Epoch 175
2025-05-29 18:42:03.358536: Current learning rate: 0.00455
2025-05-29 18:43:20.069405: train_loss -1.2061
2025-05-29 18:43:20.069629: val_loss -0.8283
2025-05-29 18:43:20.069742: Pseudo dice [0.9355, 0.7498, 0.4929, 0.8189, 0.3279, 0.914, 0.6207, 0.7695]
2025-05-29 18:43:20.069844: Epoch time: 76.71 s
2025-05-29 18:43:20.069903: Yayy! New best EMA pseudo Dice: 0.6723
2025-05-29 18:43:22.633785: 
2025-05-29 18:43:22.634099: Epoch 176
2025-05-29 18:43:22.634276: Current learning rate: 0.00452
2025-05-29 18:44:38.190510: train_loss -1.2035
2025-05-29 18:44:38.190724: val_loss -0.7846
2025-05-29 18:44:38.190840: Pseudo dice [0.9359, 0.7479, 0.4906, 0.7403, 0.3888, 0.9315, 0.6108, 0.7562]
2025-05-29 18:44:38.190931: Epoch time: 75.56 s
2025-05-29 18:44:38.191162: Yayy! New best EMA pseudo Dice: 0.6751
2025-05-29 18:44:41.297271: 
2025-05-29 18:44:41.297464: Epoch 177
2025-05-29 18:44:41.297567: Current learning rate: 0.00448
2025-05-29 18:45:57.831603: train_loss -1.2006
2025-05-29 18:45:57.831837: val_loss -0.7886
2025-05-29 18:45:57.831953: Pseudo dice [0.9362, 0.727, 0.4468, 0.792, 0.195, 0.9212, 0.606, 0.7076]
2025-05-29 18:45:57.832035: Epoch time: 76.54 s
2025-05-29 18:45:59.203741: 
2025-05-29 18:45:59.204010: Epoch 178
2025-05-29 18:45:59.204125: Current learning rate: 0.00445
2025-05-29 18:47:15.411642: train_loss -1.2055
2025-05-29 18:47:15.412149: val_loss -0.7872
2025-05-29 18:47:15.412362: Pseudo dice [0.9296, 0.7644, 0.4283, 0.8071, 0.2579, 0.9177, 0.5877, 0.7564]
2025-05-29 18:47:15.412444: Epoch time: 76.21 s
2025-05-29 18:47:16.831446: 
2025-05-29 18:47:16.831842: Epoch 179
2025-05-29 18:47:16.831977: Current learning rate: 0.00442
2025-05-29 18:48:34.091278: train_loss -1.1989
2025-05-29 18:48:34.091622: val_loss -0.7785
2025-05-29 18:48:34.091773: Pseudo dice [0.9203, 0.7289, 0.4362, 0.8051, 0.2465, 0.9304, 0.6315, 0.7618]
2025-05-29 18:48:34.091875: Epoch time: 77.26 s
2025-05-29 18:48:34.091968: Yayy! New best EMA pseudo Dice: 0.6757
2025-05-29 18:48:36.942178: 
2025-05-29 18:48:36.942437: Epoch 180
2025-05-29 18:48:36.942570: Current learning rate: 0.00438
2025-05-29 18:49:53.223994: train_loss -1.1965
2025-05-29 18:49:53.224254: val_loss -0.7844
2025-05-29 18:49:53.224444: Pseudo dice [0.9265, 0.7211, 0.4597, 0.8092, 0.2587, 0.9114, 0.607, 0.7166]
2025-05-29 18:49:53.224617: Epoch time: 76.28 s
2025-05-29 18:49:53.224686: Yayy! New best EMA pseudo Dice: 0.6757
2025-05-29 18:49:55.938650: 
2025-05-29 18:49:55.938949: Epoch 181
2025-05-29 18:49:55.939071: Current learning rate: 0.00435
2025-05-29 18:51:12.403258: train_loss -1.2196
2025-05-29 18:51:12.403481: val_loss -0.8113
2025-05-29 18:51:12.403597: Pseudo dice [0.9406, 0.7294, 0.5035, 0.8086, 0.1013, 0.9215, 0.6285, 0.7915]
2025-05-29 18:51:12.403677: Epoch time: 76.47 s
2025-05-29 18:51:12.403731: Yayy! New best EMA pseudo Dice: 0.676
2025-05-29 18:51:15.105068: 
2025-05-29 18:51:15.105406: Epoch 182
2025-05-29 18:51:15.105585: Current learning rate: 0.00432
2025-05-29 18:52:31.646616: train_loss -1.2152
2025-05-29 18:52:31.647091: val_loss -0.7642
2025-05-29 18:52:31.647252: Pseudo dice [0.9264, 0.7625, 0.4393, 0.7753, 0.3548, 0.917, 0.6262, 0.6695]
2025-05-29 18:52:31.647329: Epoch time: 76.54 s
2025-05-29 18:52:31.647383: Yayy! New best EMA pseudo Dice: 0.6768
2025-05-29 18:52:34.352969: 
2025-05-29 18:52:34.353172: Epoch 183
2025-05-29 18:52:34.353268: Current learning rate: 0.00429
2025-05-29 18:53:50.989151: train_loss -1.2048
2025-05-29 18:53:50.989351: val_loss -0.8153
2025-05-29 18:53:50.989476: Pseudo dice [0.9307, 0.7581, 0.4459, 0.7634, 0.3804, 0.9222, 0.6336, 0.7682]
2025-05-29 18:53:50.989564: Epoch time: 76.64 s
2025-05-29 18:53:50.989619: Yayy! New best EMA pseudo Dice: 0.6791
2025-05-29 18:53:53.704411: 
2025-05-29 18:53:53.704749: Epoch 184
2025-05-29 18:53:53.704906: Current learning rate: 0.00425
2025-05-29 18:55:08.208402: train_loss -1.2019
2025-05-29 18:55:08.208659: val_loss -0.7663
2025-05-29 18:55:08.208776: Pseudo dice [0.9432, 0.7155, 0.4303, 0.7411, 0.2993, 0.9083, 0.626, 0.758]
2025-05-29 18:55:08.208880: Epoch time: 74.51 s
2025-05-29 18:55:09.623666: 
2025-05-29 18:55:09.623842: Epoch 185
2025-05-29 18:55:09.623949: Current learning rate: 0.00422
2025-05-29 18:56:25.522516: train_loss -1.1844
2025-05-29 18:56:25.522811: val_loss -0.674
2025-05-29 18:56:25.522937: Pseudo dice [0.921, 0.6862, 0.4228, 0.6861, 0.128, 0.9171, 0.6052, 0.7395]
2025-05-29 18:56:25.523035: Epoch time: 75.9 s
2025-05-29 18:56:26.904106: 
2025-05-29 18:56:26.904391: Epoch 186
2025-05-29 18:56:26.904588: Current learning rate: 0.00419
2025-05-29 18:57:43.239861: train_loss -1.1856
2025-05-29 18:57:43.240143: val_loss -0.776
2025-05-29 18:57:43.240290: Pseudo dice [0.9363, 0.7273, 0.4563, 0.7615, 0.1784, 0.9044, 0.5911, 0.7132]
2025-05-29 18:57:43.240374: Epoch time: 76.34 s
2025-05-29 18:57:44.620725: 
2025-05-29 18:57:44.620991: Epoch 187
2025-05-29 18:57:44.621110: Current learning rate: 0.00415
2025-05-29 18:59:00.878312: train_loss -1.2173
2025-05-29 18:59:00.878598: val_loss -0.7907
2025-05-29 18:59:00.878718: Pseudo dice [0.9327, 0.7142, 0.4328, 0.8, 0.2748, 0.9124, 0.5654, 0.7097]
2025-05-29 18:59:00.878799: Epoch time: 76.26 s
2025-05-29 18:59:03.125178: 
2025-05-29 18:59:03.125414: Epoch 188
2025-05-29 18:59:03.125517: Current learning rate: 0.00412
2025-05-29 19:00:19.280882: train_loss -1.2048
2025-05-29 19:00:19.281114: val_loss -0.7425
2025-05-29 19:00:19.281231: Pseudo dice [0.9287, 0.7295, 0.4876, 0.7291, 0.2492, 0.9394, 0.5956, 0.6599]
2025-05-29 19:00:19.281316: Epoch time: 76.16 s
2025-05-29 19:00:20.675772: 
2025-05-29 19:00:20.676157: Epoch 189
2025-05-29 19:00:20.676301: Current learning rate: 0.00409
2025-05-29 19:01:37.139047: train_loss -1.2261
2025-05-29 19:01:37.139369: val_loss -0.7874
2025-05-29 19:01:37.139496: Pseudo dice [0.9358, 0.7619, 0.4861, 0.7689, 0.4103, 0.9165, 0.6332, 0.7144]
2025-05-29 19:01:37.139582: Epoch time: 76.46 s
2025-05-29 19:01:38.519834: 
2025-05-29 19:01:38.520059: Epoch 190
2025-05-29 19:01:38.520238: Current learning rate: 0.00405
2025-05-29 19:02:54.692906: train_loss -1.2142
2025-05-29 19:02:54.693117: val_loss -0.7414
2025-05-29 19:02:54.693234: Pseudo dice [0.9317, 0.7616, 0.4466, 0.7604, 0.1728, 0.9207, 0.6339, 0.6729]
2025-05-29 19:02:54.693325: Epoch time: 76.17 s
2025-05-29 19:02:56.072295: 
2025-05-29 19:02:56.072575: Epoch 191
2025-05-29 19:02:56.072693: Current learning rate: 0.00402
2025-05-29 19:04:10.543402: train_loss -1.2262
2025-05-29 19:04:10.543612: val_loss -0.8304
2025-05-29 19:04:10.543731: Pseudo dice [0.9364, 0.7551, 0.4289, 0.8145, 0.2643, 0.9178, 0.6223, 0.7657]
2025-05-29 19:04:10.543809: Epoch time: 74.47 s
2025-05-29 19:04:11.939043: 
2025-05-29 19:04:11.939456: Epoch 192
2025-05-29 19:04:11.939682: Current learning rate: 0.00399
2025-05-29 19:05:28.806815: train_loss -1.2395
2025-05-29 19:05:28.807109:val_loss -0.7263
2025-05-29 18:37:56.107070: Pseudo dice [0.9143, 0.6376, 0.4598, 0.7343, 0.1697, 0.9077, 0.5452, 0.7669]
2025-05-29 18:37:56.107157: Epoch time: 89.26 s
2025-05-29 18:37:56.107228: Yayy! New best EMA pseudo Dice: 0.6069
2025-05-29 18:37:58.974992: 
2025-05-29 18:37:58.975408: Epoch 152
2025-05-29 18:37:58.975574: Current learning rate: 0.00529
2025-05-29 18:39:30.084606: train_loss -1.1305
2025-05-29 18:39:30.085030: val_loss -0.6782
2025-05-29 18:39:30.085165: Pseudo dice [0.8879, 0.6136, 0.4166, 0.7101, 0.0823, 0.8201, 0.5232, 0.7584]
2025-05-29 18:39:30.085239: Epoch time: 91.11 s
2025-05-29 18:39:31.492862: 
2025-05-29 18:39:31.493196: Epoch 153
2025-05-29 18:39:31.493325: Current learning rate: 0.00526
2025-05-29 18:41:01.541248: train_loss -1.0539
2025-05-29 18:41:01.541530: val_loss -0.6585
2025-05-29 18:41:01.541647: Pseudo dice [0.8765, 0.6302, 0.4121, 0.6939, 0.0504, 0.8749, 0.5141, 0.7426]
2025-05-29 18:41:01.541735: Epoch time: 90.05 s
2025-05-29 18:41:02.920966: 
2025-05-29 18:41:02.921363: Epoch 154
2025-05-29 18:41:02.921580: Current learning rate: 0.00523
2025-05-29 18:42:31.949053: train_loss -1.0515
2025-05-29 18:42:31.949259: val_loss -0.513
2025-05-29 18:42:31.949371: Pseudo dice [0.8992, 0.6414, 0.4498, 0.5292, 0.0748, 0.8336, 0.4687, 0.8093]
2025-05-29 18:42:31.949559: Epoch time: 89.03 s
2025-05-29 18:42:33.377738: 
2025-05-29 18:42:33.378066: Epoch 155
2025-05-29 18:42:33.378214: Current learning rate: 0.0052
2025-05-29 18:44:01.567187: train_loss -1.1053
2025-05-29 18:44:01.567406: val_loss -0.7034
2025-05-29 18:44:01.567535: Pseudo dice [0.9104, 0.679, 0.3671, 0.7256, 0.123, 0.8727, 0.4775, 0.7206]
2025-05-29 18:44:01.567625: Epoch time: 88.19 s
2025-05-29 18:44:03.031465: 
2025-05-29 18:44:03.031806: Epoch 156
2025-05-29 18:44:03.031904: Current learning rate: 0.00517
2025-05-29 18:45:33.604156: train_loss -1.1248
2025-05-29 18:45:33.604428: val_loss -0.6761
2025-05-29 18:45:33.604563: Pseudo dice [0.8961, 0.6465, 0.487, 0.7081, 0.0923, 0.8736, 0.5115, 0.7808]
2025-05-29 18:45:33.604648: Epoch time: 90.57 s
2025-05-29 18:45:35.019439: 
2025-05-29 18:45:35.019729: Epoch 157
2025-05-29 18:45:35.019822: Current learning rate: 0.00513
2025-05-29 18:47:05.855174: train_loss -1.127
2025-05-29 18:47:05.855444: val_loss -0.6874
2025-05-29 18:47:05.855575: Pseudo dice [0.9235, 0.6615, 0.427, 0.6545, 0.0969, 0.8746, 0.5058, 0.7974]
2025-05-29 18:47:05.855657: Epoch time: 90.84 s
2025-05-29 18:47:05.855719: Yayy! New best EMA pseudo Dice: 0.6076
2025-05-29 18:47:09.312972: 
2025-05-29 18:47:09.313109: Epoch 158
2025-05-29 18:47:09.313208: Current learning rate: 0.0051
2025-05-29 18:48:33.632356: train_loss -1.1409
2025-05-29 18:48:33.632665: val_loss -0.6927
2025-05-29 18:48:33.632782: Pseudo dice [0.9137, 0.6924, 0.4458, 0.6736, 0.1509, 0.8885, 0.5094, 0.7943]
2025-05-29 18:48:33.632861: Epoch time: 84.32 s
2025-05-29 18:48:33.632921: Yayy! New best EMA pseudo Dice: 0.6102
2025-05-29 18:48:36.319530: 
2025-05-29 18:48:36.319925: Epoch 159
2025-05-29 18:48:36.320037: Current learning rate: 0.00507
2025-05-29 18:49:58.716162: train_loss -1.1202
2025-05-29 18:49:58.716464: val_loss -0.6597
2025-05-29 18:49:58.716641: Pseudo dice [0.9185, 0.6111, 0.4663, 0.6571, 0.1325, 0.9031, 0.4851, 0.7822]
2025-05-29 18:49:58.716745: Epoch time: 82.4 s
2025-05-29 18:49:58.716821: Yayy! New best EMA pseudo Dice: 0.6111
2025-05-29 18:50:01.310671: 
2025-05-29 18:50:01.310954: Epoch 160
2025-05-29 18:50:01.311059: Current learning rate: 0.00504
2025-05-29 18:51:27.674957: train_loss -1.1071
2025-05-29 18:51:27.675170: val_loss -0.687
2025-05-29 18:51:27.675282: Pseudo dice [0.9036, 0.6944, 0.4545, 0.7012, 0.0783, 0.8511, 0.4675, 0.7671]
2025-05-29 18:51:27.675359: Epoch time: 86.37 s
2025-05-29 18:51:27.675410: Yayy! New best EMA pseudo Dice: 0.6115
2025-05-29 18:51:30.401519: 
2025-05-29 18:51:30.401839: Epoch 161
2025-05-29 18:51:30.401986: Current learning rate: 0.005
2025-05-29 18:52:59.274430: train_loss -1.1023
2025-05-29 18:52:59.274695: val_loss -0.6886
2025-05-29 18:52:59.274826: Pseudo dice [0.9131, 0.6104, 0.502, 0.7048, 0.0725, 0.8589, 0.4844, 0.7563]
2025-05-29 18:52:59.274913: Epoch time: 88.87 s
2025-05-29 18:52:59.274999: Yayy! New best EMA pseudo Dice: 0.6116
2025-05-29 18:53:02.061300: 
2025-05-29 18:53:02.061457: Epoch 162
2025-05-29 18:53:02.061552: Current learning rate: 0.00497
2025-05-29 18:54:30.575976: train_loss -1.1285
2025-05-29 18:54:30.576180: val_loss -0.6997
2025-05-29 18:54:30.576294: Pseudo dice [0.909, 0.6105, 0.4241, 0.7274, 0.1206, 0.9042, 0.5401, 0.7401]
2025-05-29 18:54:30.576379: Epoch time: 88.52 s
2025-05-29 18:54:30.576430: Yayy! New best EMA pseudo Dice: 0.6126
2025-05-29 18:54:33.456283: 
2025-05-29 18:54:33.456735: Epoch 163
2025-05-29 18:54:33.456851: Current learning rate: 0.00494
2025-05-29 18:55:59.805893: train_loss -1.0944
2025-05-29 18:55:59.806134: val_loss -0.5951
2025-05-29 18:55:59.806247: Pseudo dice [0.9109, 0.6235, 0.456, 0.6379, 0.0722, 0.8982, 0.488, 0.8014]
2025-05-29 18:55:59.806345: Epoch time: 86.35 s
2025-05-29 18:56:01.185864: 
2025-05-29 18:56:01.186196: Epoch 164
2025-05-29 18:56:01.186421: Current learning rate: 0.00491
2025-05-29 18:57:30.767031: train_loss -1.144
2025-05-29 18:57:30.767242: val_loss -0.7998
2025-05-29 18:57:30.767352: Pseudo dice [0.9232, 0.656, 0.4643, 0.8049, 0.1688, 0.9101, 0.5439, 0.8129]
2025-05-29 18:57:30.767432: Epoch time: 89.58 s
2025-05-29 18:57:30.767521: Yayy! New best EMA pseudo Dice: 0.6173
2025-05-29 18:57:33.287418: 
2025-05-29 18:57:33.287803: Epoch 165
2025-05-29 18:57:33.287898: Current learning rate: 0.00487
2025-05-29 18:59:02.416081: train_loss -1.1687
2025-05-29 18:59:02.416313: val_loss -0.7754
2025-05-29 18:59:02.416423: Pseudo dice [0.927, 0.6581, 0.4726, 0.7914, 0.1029, 0.8414, 0.4837, 0.8637]
2025-05-29 18:59:02.416535: Epoch time: 89.13 s
2025-05-29 18:59:02.416612: Yayy! New best EMA pseudo Dice: 0.6198
2025-05-29 18:59:05.189374: 
2025-05-29 18:59:05.189638: Epoch 166
2025-05-29 18:59:05.189779: Current learning rate: 0.00484
2025-05-29 19:00:34.662478: train_loss -1.151
2025-05-29 19:00:34.662689: val_loss -0.7212
2025-05-29 19:00:34.662801: Pseudo dice [0.9152, 0.6515, 0.4467, 0.7444, 0.09, 0.8838, 0.5239, 0.7864]
2025-05-29 19:00:34.662881: Epoch time: 89.47 s
2025-05-29 19:00:34.662934: Yayy! New best EMA pseudo Dice: 0.6209
2025-05-29 19:00:37.402523: 
2025-05-29 19:00:37.402856: Epoch 167
2025-05-29 19:00:37.402949: Current learning rate: 0.00481
2025-05-29 19:02:06.439705: train_loss -1.1753
2025-05-29 19:02:06.439907: val_loss -0.7184
2025-05-29 19:02:06.440020: Pseudo dice [0.9203, 0.6176, 0.455, 0.7441, 0.1151, 0.8929, 0.5111, 0.7424]
2025-05-29 19:02:06.440100: Epoch time: 89.04 s
2025-05-29 19:02:06.440152: Yayy! New best EMA pseudo Dice: 0.6213
2025-05-29 19:02:09.846736: 
2025-05-29 19:02:09.847316: Epoch 168
2025-05-29 19:02:09.847471: Current learning rate: 0.00478
2025-05-29 19:03:35.413935: train_loss -1.1764
2025-05-29 19:03:35.414161: val_loss -0.6665
2025-05-29 19:03:35.414276: Pseudo dice [0.9145, 0.6669, 0.4464, 0.6542, 0.0714, 0.8967, 0.4744, 0.8027]
2025-05-29 19:03:35.414354: Epoch time: 85.57 s
2025-05-29 19:03:36.885654: 
2025-05-29 19:03:36.886002: Epoch 169
2025-05-29 19:03:36.886115: Current learning rate: 0.00474
2025-05-29 19:05:01.549286: train_loss -1.1821
2025-05-29 19:05:01.549529: val_loss -0.7231
2025-05-29 19:05:01.549645: Pseudo dice [0.9164, 0.64, 0.4266, 0.7706, 0.0441, 0.9026, 0.5302, 0.7737]
2025-05-29 19:05:01.549731: Epoch time: 84.66 s
2025-05-29 19:05:02.979585: 
2025-05-29 19:05:02.979774: Epoch 170
2025-05-29 19:05:02.979875: Current learning rate: 0.00471
2025-05-29 19:06:26.791555: train_loss -1.1678
2025-05-29 19:06:26.791789: val_loss -0.6808
2025-05-29 19:06:26.791917: Pseudo dice [0.908, 0.6477, 0.4445, 0.6732, 0.107, 0.8772, 0.4892, 0.8025]
2025-05-29 19:06:26.792052: Epoch time: 83.81 s
2025-05-29 19:06:28.259210: 
2025-05-29 19:06:28.259537: Epoch 171
2025-05-29 19:06:28.259683: Current learning rate: 0.00468
2025-05-29 19:07:52.040506: train_loss -1.1792
2025-05-29 19:07:52.040685: val_loss -0.6636
2025-05-29 19:07:52.040795: Pseudo dice [0.9181, 0.634, 0.409, 0.6488, 0.1595, 0.8888, 0.5311, 0.7596] Epoch 196
2025-05-29 18:58:07.262744: Current learning rate: 0.00385
2025-05-29 18:59:20.997036: train_loss -1.2014
2025-05-29 18:59:20.997319: val_loss -0.7372
2025-05-29 18:59:20.997446: Pseudo dice [0.9273, 0.7559, 0.461, 0.6919, 0.1479, 0.9394, 0.5946, 0.6993]
2025-05-29 18:59:20.997550: Epoch time: 73.74 s
2025-05-29 18:59:22.439567: 
2025-05-29 18:59:22.439837: Epoch 197
2025-05-29 18:59:22.439934: Current learning rate: 0.00382
2025-05-29 19:00:37.593469: train_loss -1.2299
2025-05-29 19:00:37.593879: val_loss -0.6624
2025-05-29 19:00:37.594042: Pseudo dice [0.9296, 0.742, 0.4062, 0.6579, 0.0738, 0.9304, 0.5769, 0.6651]
2025-05-29 19:00:37.594130: Epoch time: 75.16 s
2025-05-29 19:00:39.025120: 
2025-05-29 19:00:39.025414: Epoch 198
2025-05-29 19:00:39.025598: Current learning rate: 0.00379
2025-05-29 19:01:54.555542: train_loss -1.2345
2025-05-29 19:01:54.555952: val_loss -0.7323
2025-05-29 19:01:54.556089: Pseudo dice [0.9239, 0.7641, 0.4406, 0.7197, 0.0805, 0.9389, 0.5608, 0.7177]
2025-05-29 19:01:54.556187: Epoch time: 75.53 s
2025-05-29 19:01:55.965351: 
2025-05-29 19:01:55.965620: Epoch 199
2025-05-29 19:01:55.965734: Current learning rate: 0.00375
2025-05-29 19:03:11.747510: train_loss -1.232
2025-05-29 19:03:11.747735: val_loss -0.7182
2025-05-29 19:03:11.747857: Pseudo dice [0.9273, 0.7787, 0.4293, 0.711, 0.0653, 0.9314, 0.5272, 0.6959]
2025-05-29 19:03:11.747947: Epoch time: 75.78 s
2025-05-29 19:03:14.437379: 
2025-05-29 19:03:14.437664: Epoch 200
2025-05-29 19:03:14.437769: Current learning rate: 0.00372
2025-05-29 19:04:29.394428: train_loss -1.239
2025-05-29 19:04:29.394692: val_loss -0.6698
2025-05-29 19:04:29.394808: Pseudo dice [0.9309, 0.7818, 0.4195, 0.6782, 0.1566, 0.9403, 0.5726, 0.7256]
2025-05-29 19:04:29.394889: Epoch time: 74.96 s
2025-05-29 19:04:30.841247: 
2025-05-29 19:04:30.841679: Epoch 201
2025-05-29 19:04:30.841846: Current learning rate: 0.00369
2025-05-29 19:05:46.879932: train_loss -1.2507
2025-05-29 19:05:46.880489: val_loss -0.7475
2025-05-29 19:05:46.880606: Pseudo dice [0.925, 0.7842, 0.392, 0.7366, 0.2684, 0.9359, 0.6195, 0.7073]
2025-05-29 19:05:46.880728: Epoch time: 76.04 s
2025-05-29 19:05:48.290312: 
2025-05-29 19:05:48.290840: Epoch 202
2025-05-29 19:05:48.291158: Current learning rate: 0.00365
2025-05-29 19:07:03.568708: train_loss -1.2313
2025-05-29 19:07:03.569001: val_loss -0.7131
2025-05-29 19:07:03.569121: Pseudo dice [0.9219, 0.7532, 0.4887, 0.6632, 0.0908, 0.937, 0.5961, 0.7439]
2025-05-29 19:07:03.569216: Epoch time: 75.28 s
2025-05-29 19:07:05.821875: 
2025-05-29 19:07:05.822170: Epoch 203
2025-05-29 19:07:05.822268: Current learning rate: 0.00362
2025-05-29 19:08:21.030565: train_loss -1.2319
2025-05-29 19:08:21.030782: val_loss -0.7988
2025-05-29 19:08:21.030893: Pseudo dice [0.9321, 0.7691, 0.4679, 0.7672, 0.1984, 0.9568, 0.6301, 0.7569]
2025-05-29 19:08:21.030976: Epoch time: 75.21 s
2025-05-29 19:08:21.031030: Yayy! New best EMA pseudo Dice: 0.6511
2025-05-29 19:08:23.796515: 
2025-05-29 19:08:23.796748: Epoch 204
2025-05-29 19:08:23.796843: Current learning rate: 0.00359
2025-05-29 19:09:38.547772: train_loss -1.2498
2025-05-29 19:09:38.548223: val_loss -0.6604
2025-05-29 19:09:38.548358: Pseudo dice [0.9241, 0.7746, 0.47, 0.6356, 0.1513, 0.9269, 0.6193, 0.6732]
2025-05-29 19:09:38.548440: Epoch time: 74.75 s
2025-05-29 19:09:39.943059: 
2025-05-29 19:09:39.943398: Epoch 205
2025-05-29 19:09:39.943575: Current learning rate: 0.00355
2025-05-29 19:10:55.639643: train_loss -1.2458
2025-05-29 19:10:55.639918: val_loss -0.7154
2025-05-29 19:10:55.640042: Pseudo dice [0.9298, 0.7704, 0.4214, 0.7226, 0.1871, 0.9398, 0.6072, 0.7331]
2025-05-29 19:10:55.640131: Epoch time: 75.7 s
2025-05-29 19:10:55.640193: Yayy! New best EMA pseudo Dice: 0.652
2025-05-29 19:10:58.348250: 
2025-05-29 19:10:58.348478: Epoch 206
2025-05-29 19:10:58.348690: Current learning rate: 0.00352
2025-05-29 19:12:11.368968: train_loss -1.2428
2025-05-29 19:12:11.369243: val_loss -0.6313
2025-05-29 19:12:11.369388: Pseudo dice [0.9292, 0.7766, 0.3999, 0.6094, 0.2344, 0.9327, 0.553, 0.7421]
2025-05-29 19:12:11.369511: Epoch time: 73.02 s
2025-05-29 19:12:12.806498: 
2025-05-29 19:12:12.806885: Epoch 207
2025-05-29 19:12:12.806987: Current learning rate: 0.00349
2025-05-29 19:13:29.091024: train_loss -1.2477
2025-05-29 19:13:29.091300: val_loss -0.6517
2025-05-29 19:13:29.091424: Pseudo dice [0.938, 0.773, 0.4453, 0.6285, 0.1389, 0.9309, 0.6061, 0.6519]
2025-05-29 19:13:29.091524: Epoch time: 76.29 s
2025-05-29 19:13:30.432824: 
2025-05-29 19:13:30.433131: Epoch 208
2025-05-29 19:13:30.433233: Current learning rate: 0.00345
2025-05-29 19:14:42.930091: train_loss -1.2574
2025-05-29 19:14:42.930280: val_loss -0.743
2025-05-29 19:14:42.930391: Pseudo dice [0.9301, 0.7864, 0.4831, 0.7057, 0.0575, 0.9567, 0.6187, 0.7223]
2025-05-29 19:14:42.930484: Epoch time: 72.5 s
2025-05-29 19:14:44.311728: 
2025-05-29 19:14:44.312073: Epoch 209
2025-05-29 19:14:44.312181: Current learning rate: 0.00342
2025-05-29 19:15:59.227792: train_loss -1.2552
2025-05-29 19:15:59.228088: val_loss -0.6462
2025-05-29 19:15:59.228287: Pseudo dice [0.9388, 0.7381, 0.4388, 0.6502, 0.0529, 0.942, 0.5834, 0.7157]
2025-05-29 19:15:59.228376: Epoch time: 74.92 s
2025-05-29 19:16:00.564048: 
2025-05-29 19:16:00.564365: Epoch 210
2025-05-29 19:16:00.564497: Current learning rate: 0.00338
2025-05-29 19:17:15.368875: train_loss -1.2638
2025-05-29 19:17:15.369083: val_loss -0.6853
2025-05-29 19:17:15.369194: Pseudo dice [0.9297, 0.7695, 0.4218, 0.7063, 0.3874, 0.9441, 0.59, 0.7246]
2025-05-29 19:17:15.369275: Epoch time: 74.81 s
2025-05-29 19:17:15.369327: Yayy! New best EMA pseudo Dice: 0.6527
2025-05-29 19:17:18.053258: 
2025-05-29 19:17:18.053466: Epoch 211
2025-05-29 19:17:18.053576: Current learning rate: 0.00335
2025-05-29 19:18:33.116386: train_loss -1.2545
2025-05-29 19:18:33.116621: val_loss -0.6939
2025-05-29 19:18:33.116742: Pseudo dice [0.9285, 0.7678, 0.4693, 0.6829, 0.2607, 0.9407, 0.5471, 0.7047]
2025-05-29 19:18:33.116824: Epoch time: 75.06 s
2025-05-29 19:18:33.116878: Yayy! New best EMA pseudo Dice: 0.6537
2025-05-29 19:18:36.107545: 
2025-05-29 19:18:36.107904: Epoch 212
2025-05-29 19:18:36.108009: Current learning rate: 0.00332
2025-05-29 19:19:50.803625: train_loss -1.2487
2025-05-29 19:19:50.803885: val_loss -0.7245
2025-05-29 19:19:50.804005: Pseudo dice [0.935, 0.7762, 0.4563, 0.6845, 0.1474, 0.9419, 0.6262, 0.7494]
2025-05-29 19:19:50.804098: Epoch time: 74.7 s
2025-05-29 19:19:50.804214: Yayy! New best EMA pseudo Dice: 0.6548
2025-05-29 19:19:53.217923: 
2025-05-29 19:19:53.218089: Epoch 213
2025-05-29 19:19:53.218190: Current learning rate: 0.00328
2025-05-29 19:21:08.511325: train_loss -1.2524
2025-05-29 19:21:08.511499: val_loss -0.677
2025-05-29 19:21:08.511614: Pseudo dice [0.9277, 0.7811, 0.4735, 0.6975, 0.2494, 0.943, 0.5274, 0.7226]
2025-05-29 19:21:08.511689: Epoch time: 75.29 s
2025-05-29 19:21:08.511741: Yayy! New best EMA pseudo Dice: 0.6558
2025-05-29 19:21:11.846393: 
2025-05-29 19:21:11.846716: Epoch 214
2025-05-29 19:21:11.846826: Current learning rate: 0.00325
2025-05-29 19:22:27.146716: train_loss -1.2433
2025-05-29 19:22:27.146900: val_loss -0.7069
2025-05-29 19:22:27.147010: Pseudo dice [0.9342, 0.7805, 0.5, 0.7045, 0.1521, 0.9439, 0.5641, 0.7278]
2025-05-29 19:22:27.147164: Epoch time: 75.3 s
2025-05-29 19:22:27.147221: Yayy! New best EMA pseudo Dice: 0.6566
2025-05-29 19:22:30.121883: 
2025-05-29 19:22:30.122242: Epoch 215
2025-05-29 19:22:30.122382: Current learning rate: 0.00321
2025-05-29 19:23:45.276337: train_loss -1.2488
2025-05-29 19:23:45.276600: val_loss -0.7049
2025-05-29 19:23:45.276713: Pseudo dice [0.9209, 0.7262, 0.4451, 0.7416, 0.0814, 0.9413, 0.5913, 0.6706]
2025-05-29 19:23:45.276798: Epoch time: 75.16 s
2025-05-29 19:23:46.620364: 
2025-05-29 19:23:46.620795: Epoch 216
2025-05-29 19:23:46.620923: Current learning rate: 0.00318
2025-05-29 19:25:02.377332: train_loss -1.2496
2025-05-29 19:25:02.377588: val_loss -0.7613
2025-05-29 19:25:02.377747: Pseudo dice [0.9375, 0.7999, 0.4429, 0.7544, 0.2014, 0.9522, 0.5345, 0.7596]
2025-05-29 19:25:02.377835: Epoch time: 75.76 s
2025-05-29 19:25:02.377899: val_loss -0.7253
2025-05-29 19:05:28.807684: Pseudo dice [0.9199, 0.7317, 0.4592, 0.7306, 0.184, 0.9024, 0.6155, 0.7096]
2025-05-29 19:05:28.807779: Epoch time: 76.87 s
2025-05-29 19:05:30.449189: 
2025-05-29 19:05:30.449605: Epoch 193
2025-05-29 19:05:30.449737: Current learning rate: 0.00395
2025-05-29 19:06:46.911844: train_loss -1.2182
2025-05-29 19:06:46.912071: val_loss -0.7944
2025-05-29 19:06:46.912189: Pseudo dice [0.9299, 0.7307, 0.4795, 0.7567, 0.2553, 0.9054, 0.6014, 0.7116]
2025-05-29 19:06:46.912267: Epoch time: 76.46 s
2025-05-29 19:06:48.377878: 
2025-05-29 19:06:48.378211: Epoch 194
2025-05-29 19:06:48.378309: Current learning rate: 0.00392
2025-05-29 19:08:03.239165: train_loss -1.222
2025-05-29 19:08:03.239437: val_loss -0.7443
2025-05-29 19:08:03.239574: Pseudo dice [0.9177, 0.7015, 0.4177, 0.7947, 0.1922, 0.9003, 0.5676, 0.6831]
2025-05-29 19:08:03.239656: Epoch time: 74.86 s
2025-05-29 19:08:04.635835: 
2025-05-29 19:08:04.636135: Epoch 195
2025-05-29 19:08:04.636237: Current learning rate: 0.00389
2025-05-29 19:09:17.995692: train_loss -1.2057
2025-05-29 19:09:17.996054: val_loss -0.7996
2025-05-29 19:09:17.996179: Pseudo dice [0.9317, 0.7113, 0.4517, 0.7969, 0.1961, 0.9287, 0.6204, 0.7612]
2025-05-29 19:09:17.996282: Epoch time: 73.36 s
2025-05-29 19:09:19.432601: 
2025-05-29 19:09:19.432825: Epoch 196
2025-05-29 19:09:19.432916: Current learning rate: 0.00385
2025-05-29 19:10:36.444843: train_loss -1.2262
2025-05-29 19:10:36.445630: val_loss -0.6998
2025-05-29 19:10:36.445923: Pseudo dice [0.9193, 0.7706, 0.4795, 0.7591, 0.2879, 0.9299, 0.5934, 0.6914]
2025-05-29 19:10:36.446046: Epoch time: 77.01 s
2025-05-29 19:10:37.905019: 
2025-05-29 19:10:37.905355: Epoch 197
2025-05-29 19:10:37.905501: Current learning rate: 0.00382
2025-05-29 19:11:52.056912: train_loss -1.2101
2025-05-29 19:11:52.057140: val_loss -0.7443
2025-05-29 19:11:52.057326: Pseudo dice [0.9464, 0.7143, 0.4034, 0.7472, 0.1546, 0.9137, 0.6033, 0.7533]
2025-05-29 19:11:52.057471: Epoch time: 74.15 s
2025-05-29 19:11:54.442489: 
2025-05-29 19:11:54.442778: Epoch 198
2025-05-29 19:11:54.442931: Current learning rate: 0.00379
2025-05-29 19:13:12.114382: train_loss -1.2174
2025-05-29 19:13:12.114574: val_loss -0.7684
2025-05-29 19:13:12.114689: Pseudo dice [0.931, 0.7468, 0.4105, 0.7564, 0.2905, 0.9269, 0.6354, 0.7783]
2025-05-29 19:13:12.114763: Epoch time: 77.67 s
2025-05-29 19:13:13.515782: 
2025-05-29 19:13:13.516186: Epoch 199
2025-05-29 19:13:13.516341: Current learning rate: 0.00375
2025-05-29 19:14:29.832617: train_loss -1.2033
2025-05-29 19:14:29.832895: val_loss -0.7715
2025-05-29 19:14:29.833015: Pseudo dice [0.9228, 0.741, 0.4968, 0.7865, 0.1616, 0.9378, 0.6035, 0.7437]
2025-05-29 19:14:29.833117: Epoch time: 76.32 s
2025-05-29 19:14:32.538882: 
2025-05-29 19:14:32.539288: Epoch 200
2025-05-29 19:14:32.539424: Current learning rate: 0.00372
2025-05-29 19:15:49.508683: train_loss -1.2369
2025-05-29 19:15:49.509619: val_loss -0.801
2025-05-29 19:15:49.509816: Pseudo dice [0.9346, 0.7559, 0.4926, 0.7659, 0.3647, 0.9339, 0.6435, 0.7174]
2025-05-29 19:15:49.509960: Epoch time: 76.97 s
2025-05-29 19:15:51.009880: 
2025-05-29 19:15:51.010412: Epoch 201
2025-05-29 19:15:51.010571: Current learning rate: 0.00369
2025-05-29 19:17:06.944735: train_loss -1.2449
2025-05-29 19:17:06.945462: val_loss -0.7696
2025-05-29 19:17:06.945593: Pseudo dice [0.9382, 0.7443, 0.459, 0.7725, 0.2906, 0.9172, 0.6043, 0.765]
2025-05-29 19:17:06.945692: Epoch time: 75.94 s
2025-05-29 19:17:08.389183: 
2025-05-29 19:17:08.389652: Epoch 202
2025-05-29 19:17:08.389837: Current learning rate: 0.00365
2025-05-29 19:18:22.795756: train_loss -1.1961
2025-05-29 19:18:22.795992: val_loss -0.7097
2025-05-29 19:18:22.796110: Pseudo dice [0.9337, 0.7129, 0.4818, 0.6811, 0.2712, 0.9292, 0.6058, 0.7363]
2025-05-29 19:18:22.796194: Epoch time: 74.41 s
2025-05-29 19:18:24.238809: 
2025-05-29 19:18:24.239335: Epoch 203
2025-05-29 19:18:24.239460: Current learning rate: 0.00362
2025-05-29 19:19:38.179575: train_loss -1.2061
2025-05-29 19:19:38.180108: val_loss -0.7146
2025-05-29 19:19:38.180220: Pseudo dice [0.9417, 0.6936, 0.4582, 0.7555, 0.2488, 0.9352, 0.6124, 0.7093]
2025-05-29 19:19:38.180294: Epoch time: 73.94 s
2025-05-29 19:19:39.598811: 
2025-05-29 19:19:39.599034: Epoch 204
2025-05-29 19:19:39.599131: Current learning rate: 0.00359
2025-05-29 19:20:54.776161: train_loss -1.2284
2025-05-29 19:20:54.776540: val_loss -0.7003
2025-05-29 19:20:54.776652: Pseudo dice [0.9162, 0.7735, 0.4373, 0.6674, 0.2026, 0.9347, 0.5997, 0.6759]
2025-05-29 19:20:54.776732: Epoch time: 75.18 s
2025-05-29 19:20:56.367066: 
2025-05-29 19:20:56.367358: Epoch 205
2025-05-29 19:20:56.367473: Current learning rate: 0.00355
2025-05-29 19:22:09.990401: train_loss -1.2348
2025-05-29 19:22:09.990698: val_loss -0.7446
2025-05-29 19:22:09.990825: Pseudo dice [0.9337, 0.7365, 0.4266, 0.7409, 0.2699, 0.9296, 0.5772, 0.7583]
2025-05-29 19:22:09.990922: Epoch time: 73.62 s
2025-05-29 19:22:11.450503: 
2025-05-29 19:22:11.450884: Epoch 206
2025-05-29 19:22:11.451001: Current learning rate: 0.00352
2025-05-29 19:23:25.642625: train_loss -1.2336
2025-05-29 19:23:25.643602: val_loss -0.7181
2025-05-29 19:23:25.643860: Pseudo dice [0.9276, 0.7589, 0.4374, 0.6981, 0.0592, 0.9403, 0.5781, 0.7034]
2025-05-29 19:23:25.644032: Epoch time: 74.19 s
2025-05-29 19:23:27.052323: 
2025-05-29 19:23:27.052571: Epoch 207
2025-05-29 19:23:27.052673: Current learning rate: 0.00349
2025-05-29 19:24:45.038333: train_loss -1.1637
2025-05-29 19:24:45.038817: val_loss -0.7389
2025-05-29 19:24:45.039011: Pseudo dice [0.9223, 0.6965, 0.4628, 0.7751, 0.3439, 0.8962, 0.6189, 0.7191]
2025-05-29 19:24:45.039099: Epoch time: 77.99 s
2025-05-29 19:24:47.115169: 
2025-05-29 19:24:47.115453: Epoch 208
2025-05-29 19:24:47.115572: Current learning rate: 0.00345
2025-05-29 19:26:00.385417: train_loss -1.2021
2025-05-29 19:26:00.385725: val_loss -0.7553
2025-05-29 19:26:00.385843: Pseudo dice [0.9272, 0.7583, 0.4802, 0.758, 0.2609, 0.9075, 0.6558, 0.7678]
2025-05-29 19:26:00.385923: Epoch time: 73.27 s
2025-05-29 19:26:01.735608: 
2025-05-29 19:26:01.735927: Epoch 209
2025-05-29 19:26:01.736028: Current learning rate: 0.00342
2025-05-29 19:27:18.746029: train_loss -1.2221
2025-05-29 19:27:18.746271: val_loss -0.8058
2025-05-29 19:27:18.746390: Pseudo dice [0.9374, 0.7163, 0.4749, 0.7891, 0.1492, 0.9392, 0.624, 0.7861]
2025-05-29 19:27:18.746475: Epoch time: 77.01 s
2025-05-29 19:27:20.128875: 
2025-05-29 19:27:20.129138: Epoch 210
2025-05-29 19:27:20.129244: Current learning rate: 0.00338
2025-05-29 19:28:37.183227: train_loss -1.2205
2025-05-29 19:28:37.183488: val_loss -0.7794
2025-05-29 19:28:37.183612: Pseudo dice [0.9369, 0.7242, 0.4202, 0.7935, 0.1665, 0.9436, 0.624, 0.7712]
2025-05-29 19:28:37.183688: Epoch time: 77.06 s
2025-05-29 19:28:38.823952: 
2025-05-29 19:28:38.824469: Epoch 211
2025-05-29 19:28:38.824615: Current learning rate: 0.00335
2025-05-29 19:29:54.769703: train_loss -1.2271
2025-05-29 19:29:54.770140: val_loss -0.7312
2025-05-29 19:29:54.770256: Pseudo dice [0.9291, 0.7595, 0.4936, 0.7044, 0.163, 0.9282, 0.5965, 0.7771]
2025-05-29 19:29:54.770385: Epoch time: 75.95 s
2025-05-29 19:29:56.204976: 
2025-05-29 19:29:56.205307: Epoch 212
2025-05-29 19:29:56.205424: Current learning rate: 0.00332
2025-05-29 19:31:12.656835: train_loss -1.2376
2025-05-29 19:31:12.657255: val_loss -0.7165
2025-05-29 19:31:12.657384: Pseudo dice [0.915, 0.753, 0.4725, 0.677, 0.2165, 0.9362, 0.5899, 0.7429]
2025-05-29 19:31:12.657479: Epoch time: 76.45 s
2025-05-29 19:31:14.049748: 
2025-05-29 19:31:14.050303: Epoch 213
2025-05-29 19:31:14.050485: Current learning rate: 0.00328
2025-05-29 19:32:28.864102: train_loss -1.2397
2025-05-29 19:32:28.864328: val_loss -0.7812
2025-05-29 19:32:28.864434: Pseudo dice [0.9276, 0.7752, 0.4529, 0.7607, 0.2991, 0.9246, 0.6265, 0.7805]
2025-05-29 19:32:28.864521: Epoch time: 74.82 s
2025-05-29 19:32:30.238463: 
2025-05-29 19:32:30.238671: Epoch 214
2025-05-29 19:32:30.238810: Current learning rate: 0.00325
2025-05-29 19:33:47.005858: train_loss -1.2409
2025-05-29 19:33:47.006064: val_loss -0.8154
2025-05-29 19:33:47.006253:
2025-05-29 19:07:52.041322: Epoch time: 83.78 s
2025-05-29 19:07:53.414932: 
2025-05-29 19:07:53.415192: Epoch 172
2025-05-29 19:07:53.415373: Current learning rate: 0.00465
2025-05-29 19:09:13.002842: train_loss -1.1719
2025-05-29 19:09:13.003071: val_loss -0.6847
2025-05-29 19:09:13.003190: Pseudo dice [0.9109, 0.6487, 0.4384, 0.7411, 0.0256, 0.8952, 0.4893, 0.7764]
2025-05-29 19:09:13.003282: Epoch time: 79.59 s
2025-05-29 19:09:14.425716: 
2025-05-29 19:09:14.426026: Epoch 173
2025-05-29 19:09:14.426174: Current learning rate: 0.00461
2025-05-29 19:10:41.149857: train_loss -1.1419
2025-05-29 19:10:41.150077: val_loss -0.6241
2025-05-29 19:10:41.150193: Pseudo dice [0.9128, 0.6356, 0.4509, 0.5911, 0.0879, 0.8822, 0.516, 0.7647]
2025-05-29 19:10:41.150327: Epoch time: 86.73 s
2025-05-29 19:10:42.537339: 
2025-05-29 19:10:42.537549: Epoch 174
2025-05-29 19:10:42.537650: Current learning rate: 0.00458
2025-05-29 19:12:09.953256: train_loss -1.1645
2025-05-29 19:12:09.953491: val_loss -0.6457
2025-05-29 19:12:09.953608: Pseudo dice [0.9094, 0.5913, 0.4355, 0.631, 0.0706, 0.9218, 0.5362, 0.801]
2025-05-29 19:12:09.953698: Epoch time: 87.42 s
2025-05-29 19:12:11.328742: 
2025-05-29 19:12:11.328988: Epoch 175
2025-05-29 19:12:11.329093: Current learning rate: 0.00455
2025-05-29 19:13:35.039329: train_loss -1.1283
2025-05-29 19:13:35.039597: val_loss -0.5893
2025-05-29 19:13:35.039738: Pseudo dice [0.8986, 0.6048, 0.4071, 0.5683, 0.027, 0.9091, 0.4638, 0.7998]
2025-05-29 19:13:35.039834: Epoch time: 83.71 s
2025-05-29 19:13:36.454272: 
2025-05-29 19:13:36.454453: Epoch 176
2025-05-29 19:13:36.454554: Current learning rate: 0.00452
2025-05-29 19:15:04.166227: train_loss -1.1714
2025-05-29 19:15:04.166477: val_loss -0.6759
2025-05-29 19:15:04.166600: Pseudo dice [0.9107, 0.6329, 0.4929, 0.6718, 0.014, 0.893, 0.5038, 0.8141]
2025-05-29 19:15:04.166678: Epoch time: 87.71 s
2025-05-29 19:15:05.577383: 
2025-05-29 19:15:05.577655: Epoch 177
2025-05-29 19:15:05.577789: Current learning rate: 0.00448
2025-05-29 19:16:28.923114: train_loss -1.1921
2025-05-29 19:16:28.923328: val_loss -0.6536
2025-05-29 19:16:28.923438: Pseudo dice [0.9071, 0.6279, 0.4587, 0.6774, 0.0517, 0.8676, 0.4802, 0.7819]
2025-05-29 19:16:28.923541: Epoch time: 83.35 s
2025-05-29 19:16:30.296861: 
2025-05-29 19:16:30.297067: Epoch 178
2025-05-29 19:16:30.297159: Current learning rate: 0.00445
2025-05-29 19:17:56.411304: train_loss -1.1552
2025-05-29 19:17:56.411572: val_loss -0.5578
2025-05-29 19:17:56.411692: Pseudo dice [0.9153, 0.6386, 0.4374, 0.5564, 0.0615, 0.8983, 0.4758, 0.7601]
2025-05-29 19:17:56.411776: Epoch time: 86.12 s
2025-05-29 19:17:58.465384: 
2025-05-29 19:17:58.465663: Epoch 179
2025-05-29 19:17:58.465763: Current learning rate: 0.00442
2025-05-29 19:19:22.433246: train_loss -1.1656
2025-05-29 19:19:22.433469: val_loss -0.639
2025-05-29 19:19:22.433590: Pseudo dice [0.9011, 0.6362, 0.4526, 0.6853, 0.0607, 0.8877, 0.507, 0.7797]
2025-05-29 19:19:22.433690: Epoch time: 83.97 s
2025-05-29 19:19:23.819471: 
2025-05-29 19:19:23.819778: Epoch 180
2025-05-29 19:19:23.819871: Current learning rate: 0.00438
2025-05-29 19:20:51.690852: train_loss -1.149
2025-05-29 19:20:51.691182: val_loss -0.6484
2025-05-29 19:20:51.691323: Pseudo dice [0.8959, 0.6429, 0.4228, 0.6928, 0.1421, 0.8829, 0.4066, 0.69]
2025-05-29 19:20:51.691421: Epoch time: 87.87 s
2025-05-29 19:20:53.157619: 
2025-05-29 19:20:53.157998: Epoch 181
2025-05-29 19:20:53.158157: Current learning rate: 0.00435
2025-05-29 19:22:16.611295: train_loss -1.1359
2025-05-29 19:22:16.611601: val_loss -0.5824
2025-05-29 19:22:16.611716: Pseudo dice [0.9137, 0.6275, 0.3827, 0.5838, 0.1333, 0.8658, 0.5295, 0.7424]
2025-05-29 19:22:16.611806: Epoch time: 83.46 s
2025-05-29 19:22:17.990320: 
2025-05-29 19:22:17.990533: Epoch 182
2025-05-29 19:22:17.990630: Current learning rate: 0.00432
2025-05-29 19:23:45.167074: train_loss -1.1219
2025-05-29 19:23:45.167286: val_loss -0.6255
2025-05-29 19:23:45.167400: Pseudo dice [0.8815, 0.6323, 0.4448, 0.6603, 0.0851, 0.8356, 0.4596, 0.7599]
2025-05-29 19:23:45.167502: Epoch time: 87.18 s
2025-05-29 19:23:46.572775: 
2025-05-29 19:23:46.573201: Epoch 183
2025-05-29 19:23:46.573528: Current learning rate: 0.00429
2025-05-29 19:25:08.789165: train_loss -1.1486
2025-05-29 19:25:08.790236: val_loss -0.5815
2025-05-29 19:25:08.790377: Pseudo dice [0.907, 0.6753, 0.4628, 0.5764, 0.0512, 0.9, 0.5268, 0.8254]
2025-05-29 19:25:08.790552: Epoch time: 82.22 s
2025-05-29 19:25:10.269587: 
2025-05-29 19:25:10.269976: Epoch 184
2025-05-29 19:25:10.270083: Current learning rate: 0.00425
2025-05-29 19:26:38.496256: train_loss -1.1865
2025-05-29 19:26:38.496906: val_loss -0.6649
2025-05-29 19:26:38.497052: Pseudo dice [0.9155, 0.6789, 0.4146, 0.6552, 0.0489, 0.9007, 0.4977, 0.8235]
2025-05-29 19:26:38.497202: Epoch time: 88.23 s
2025-05-29 19:26:39.951404: 
2025-05-29 19:26:39.951816: Epoch 185
2025-05-29 19:26:39.952033: Current learning rate: 0.00422
2025-05-29 19:28:05.469169: train_loss -1.1886
2025-05-29 19:28:05.469485: val_loss -0.7553
2025-05-29 19:28:05.469638: Pseudo dice [0.9247, 0.7147, 0.4402, 0.7634, 0.099, 0.8879, 0.4991, 0.8025]
2025-05-29 19:28:05.469748: Epoch time: 85.52 s
2025-05-29 19:28:06.899127: 
2025-05-29 19:28:06.899480: Epoch 186
2025-05-29 19:28:06.899680: Current learning rate: 0.00419
2025-05-29 19:29:31.184532: train_loss -1.178
2025-05-29 19:29:31.184827: val_loss -0.6917
2025-05-29 19:29:31.185032: Pseudo dice [0.9055, 0.6076, 0.4202, 0.7134, 0.0525, 0.9119, 0.5217, 0.7852]
2025-05-29 19:29:31.185134: Epoch time: 84.29 s
2025-05-29 19:29:32.589928: 
2025-05-29 19:29:32.590141: Epoch 187
2025-05-29 19:29:32.590269: Current learning rate: 0.00415
2025-05-29 19:31:02.911318: train_loss -1.1943
2025-05-29 19:31:02.911587: val_loss -0.6712
2025-05-29 19:31:02.911713: Pseudo dice [0.9209, 0.6391, 0.4312, 0.6955, 0.0751, 0.8602, 0.4397, 0.8435]
2025-05-29 19:31:02.911799: Epoch time: 90.32 s
2025-05-29 19:31:04.412002: 
2025-05-29 19:31:04.412362: Epoch 188
2025-05-29 19:31:04.412592: Current learning rate: 0.00412
2025-05-29 19:32:32.900308: train_loss -1.2027
2025-05-29 19:32:32.900690: val_loss -0.6591
2025-05-29 19:32:32.900800: Pseudo dice [0.9245, 0.6514, 0.4473, 0.6586, 0.0339, 0.8931, 0.5193, 0.802]
2025-05-29 19:32:32.900878: Epoch time: 88.49 s
2025-05-29 19:32:35.408047: 
2025-05-29 19:32:35.408345: Epoch 189
2025-05-29 19:32:35.408507: Current learning rate: 0.00409
2025-05-29 19:34:05.509986: train_loss -1.1977
2025-05-29 19:34:05.510377: val_loss -0.815
2025-05-29 19:34:05.510518: Pseudo dice [0.9169, 0.6751, 0.4721, 0.7985, 0.0755, 0.9157, 0.5272, 0.8287]
2025-05-29 19:34:05.510648: Epoch time: 90.1 s
2025-05-29 19:34:06.893849: 
2025-05-29 19:34:06.894094: Epoch 190
2025-05-29 19:34:06.894356: Current learning rate: 0.00405
2025-05-29 19:35:36.803458: train_loss -1.2094
2025-05-29 19:35:36.803691: val_loss -0.7289
2025-05-29 19:35:36.803806: Pseudo dice [0.9088, 0.6534, 0.475, 0.693, 0.0571, 0.9172, 0.522, 0.8097]
2025-05-29 19:35:36.803892: Epoch time: 89.91 s
2025-05-29 19:35:38.219467: 
2025-05-29 19:35:38.219841: Epoch 191
2025-05-29 19:35:38.219991: Current learning rate: 0.00402
2025-05-29 19:37:08.942710: train_loss -1.1865
2025-05-29 19:37:08.943109: val_loss -0.7148
2025-05-29 19:37:08.943227: Pseudo dice [0.9255, 0.6965, 0.4156, 0.6741, 0.1147, 0.8616, 0.524, 0.815]
2025-05-29 19:37:08.943308: Epoch time: 90.72 s
2025-05-29 19:37:10.354063: 
2025-05-29 19:37:10.354390: Epoch 192
2025-05-29 19:37:10.354500: Current learning rate: 0.00399
2025-05-29 19:38:41.088879: train_loss -1.1966
2025-05-29 19:38:41.089192: val_loss -0.6181
2025-05-29 19:38:41.089313: Pseudo dice [0.9117, 0.6039, 0.4842, 0.6541, 0.1317, 0.902, 0.4775, 0.8021]
2025-05-29 19:38:41.089392: Epoch time: 90.74 s
2025-05-29 19:38:42.496091: 
2025-05-29 19:38:42.496431: Epoch 193
2025-05-29 19:38:42.496567: Current learning rate: 0.00395
2025-05-29 19:40:13.259294: train_loss -1.2074
2025-05-29 19:40:13.259562: val_loss -0.6261
2025-05-29 19:40:13.259818: Pseudo dice [0.9034, 0.7093, 0.4212, 0.6536, 0.1321, 0.8863, 0.4955, 0.761]
2025-05-29 19:40:13.259898: Epoch time: 90.76 s
2025-05-29 19:40:14.701644: Yayy! New best EMA pseudo Dice: 0.6567
2025-05-29 19:25:05.311729: 
2025-05-29 19:25:05.312103: Epoch 217
2025-05-29 19:25:05.312243: Current learning rate: 0.00315
2025-05-29 19:26:19.814952: train_loss -1.2631
2025-05-29 19:26:19.815312: val_loss -0.7336
2025-05-29 19:26:19.815474: Pseudo dice [0.9323, 0.766, 0.4617, 0.7239, 0.0456, 0.9393, 0.5932, 0.7164]
2025-05-29 19:26:19.815577: Epoch time: 74.5 s
2025-05-29 19:26:21.182217: 
2025-05-29 19:26:21.182693: Epoch 218
2025-05-29 19:26:21.182853: Current learning rate: 0.00311
2025-05-29 19:27:35.857649: train_loss -1.2706
2025-05-29 19:27:35.857931: val_loss -0.744
2025-05-29 19:27:35.858049: Pseudo dice [0.9299, 0.7923, 0.488, 0.6988, 0.1324, 0.9513, 0.5961, 0.724]
2025-05-29 19:27:35.858135: Epoch time: 74.68 s
2025-05-29 19:27:37.278595: 
2025-05-29 19:27:37.278812: Epoch 219
2025-05-29 19:27:37.278913: Current learning rate: 0.00308
2025-05-29 19:28:52.488719: train_loss -1.2362
2025-05-29 19:28:52.488947: val_loss -0.6701
2025-05-29 19:28:52.489067: Pseudo dice [0.9307, 0.7509, 0.4748, 0.6109, 0.2044, 0.9339, 0.5754, 0.7249]
2025-05-29 19:28:52.489150: Epoch time: 75.21 s
2025-05-29 19:28:53.857069: 
2025-05-29 19:28:53.857352: Epoch 220
2025-05-29 19:28:53.857467: Current learning rate: 0.00304
2025-05-29 19:30:08.256552: train_loss -1.2453
2025-05-29 19:30:08.256851: val_loss -0.6584
2025-05-29 19:30:08.256983: Pseudo dice [0.9191, 0.7511, 0.4192, 0.704, 0.0703, 0.9496, 0.5434, 0.7005]
2025-05-29 19:30:08.257086: Epoch time: 74.4 s
2025-05-29 19:30:09.691109: 
2025-05-29 19:30:09.691509: Epoch 221
2025-05-29 19:30:09.691608: Current learning rate: 0.00301
2025-05-29 19:31:24.726046: train_loss -1.2627
2025-05-29 19:31:24.726247: val_loss -0.729
2025-05-29 19:31:24.726375: Pseudo dice [0.9238, 0.7758, 0.5266, 0.751, 0.2715, 0.9339, 0.5829, 0.719]
2025-05-29 19:31:24.726475: Epoch time: 75.04 s
2025-05-29 19:31:24.726535: Yayy! New best EMA pseudo Dice: 0.6568
2025-05-29 19:31:27.382221: 
2025-05-29 19:31:27.382464: Epoch 222
2025-05-29 19:31:27.382583: Current learning rate: 0.00297
2025-05-29 19:32:42.467930: train_loss -1.2719
2025-05-29 19:32:42.468089: val_loss -0.6773
2025-05-29 19:32:42.468203: Pseudo dice [0.919, 0.7696, 0.4469, 0.7126, 0.1151, 0.939, 0.5423, 0.6533]
2025-05-29 19:32:42.468277: Epoch time: 75.09 s
2025-05-29 19:32:43.841007: 
2025-05-29 19:32:43.841411: Epoch 223
2025-05-29 19:32:43.841563: Current learning rate: 0.00294
2025-05-29 19:33:59.457844: train_loss -1.2631
2025-05-29 19:33:59.458164: val_loss -0.7056
2025-05-29 19:33:59.458361: Pseudo dice [0.945, 0.7771, 0.4801, 0.6618, 0.1165, 0.9352, 0.583, 0.7967]
2025-05-29 19:33:59.458459: Epoch time: 75.62 s
2025-05-29 19:34:00.872908: 
2025-05-29 19:34:00.873306: Epoch 224
2025-05-29 19:34:00.873536: Current learning rate: 0.00291
2025-05-29 19:35:15.807353: train_loss -1.2444
2025-05-29 19:35:15.807702: val_loss -0.6375
2025-05-29 19:35:15.807835: Pseudo dice [0.9278, 0.7564, 0.4734, 0.611, 0.1468, 0.9423, 0.5771, 0.6513]
2025-05-29 19:35:15.807928: Epoch time: 74.94 s
2025-05-29 19:35:18.099445: 
2025-05-29 19:35:18.099949: Epoch 225
2025-05-29 19:35:18.100263: Current learning rate: 0.00287
2025-05-29 19:36:32.675484: train_loss -1.2709
2025-05-29 19:36:32.675968: val_loss -0.6465
2025-05-29 19:36:32.676085: Pseudo dice [0.9174, 0.746, 0.4688, 0.6535, 0.072, 0.9417, 0.5738, 0.6724]
2025-05-29 19:36:32.676189: Epoch time: 74.58 s
2025-05-29 19:36:34.070652: 
2025-05-29 19:36:34.071234: Epoch 226
2025-05-29 19:36:34.071392: Current learning rate: 0.00284
2025-05-29 19:37:49.108763: train_loss -1.2477
2025-05-29 19:37:49.109137: val_loss -0.6345
2025-05-29 19:37:49.109279: Pseudo dice [0.9217, 0.7469, 0.4477, 0.6533, 0.2547, 0.9042, 0.5882, 0.7347]
2025-05-29 19:37:49.109370: Epoch time: 75.04 s
2025-05-29 19:37:50.532278: 
2025-05-29 19:37:50.532677: Epoch 227
2025-05-29 19:37:50.532782: Current learning rate: 0.0028
2025-05-29 19:39:05.984294: train_loss -1.2428
2025-05-29 19:39:05.984687: val_loss -0.6436
2025-05-29 19:39:05.984820: Pseudo dice [0.9305, 0.747, 0.4602, 0.5812, 0.2007, 0.9184, 0.5514, 0.6571]
2025-05-29 19:39:05.984907: Epoch time: 75.45 s
2025-05-29 19:39:07.348333: 
2025-05-29 19:39:07.348691: Epoch 228
2025-05-29 19:39:07.348858: Current learning rate: 0.00277
2025-05-29 19:40:21.553467: train_loss -1.2532
2025-05-29 19:40:21.553873: val_loss -0.688
2025-05-29 19:40:21.554082: Pseudo dice [0.9257, 0.7417, 0.498, 0.7358, 0.1187, 0.9351, 0.6031, 0.7041]
2025-05-29 19:40:21.554212: Epoch time: 74.21 s
2025-05-29 19:40:22.926617: 
2025-05-29 19:40:22.927036: Epoch 229
2025-05-29 19:40:22.927133: Current learning rate: 0.00273
2025-05-29 19:41:40.445952: train_loss -1.2591
2025-05-29 19:41:40.446305: val_loss -0.7018
2025-05-29 19:41:40.446467: Pseudo dice [0.9404, 0.7854, 0.4991, 0.6582, 0.2089, 0.9497, 0.5874, 0.7434]
2025-05-29 19:41:40.446578: Epoch time: 77.52 s
2025-05-29 19:41:41.862079: 
2025-05-29 19:41:41.862437: Epoch 230
2025-05-29 19:41:41.862563: Current learning rate: 0.0027
2025-05-29 19:42:57.513442: train_loss -1.2554
2025-05-29 19:42:57.513963: val_loss -0.6362
2025-05-29 19:42:57.514087: Pseudo dice [0.9115, 0.7742, 0.464, 0.6601, 0.172, 0.9307, 0.5969, 0.701]
2025-05-29 19:42:57.514168: Epoch time: 75.65 s
2025-05-29 19:42:58.983266: 
2025-05-29 19:42:58.983936: Epoch 231
2025-05-29 19:42:58.984252: Current learning rate: 0.00266
2025-05-29 19:44:13.840507: train_loss -1.2635
2025-05-29 19:44:13.841267: val_loss -0.651
2025-05-29 19:44:13.841476: Pseudo dice [0.9271, 0.778, 0.4992, 0.6733, 0.0453, 0.9488, 0.5522, 0.72]
2025-05-29 19:44:13.841659: Epoch time: 74.86 s
2025-05-29 19:44:15.355714: 
2025-05-29 19:44:15.356180: Epoch 232
2025-05-29 19:44:15.356345: Current learning rate: 0.00263
2025-05-29 19:45:30.855383: train_loss -1.2678
2025-05-29 19:45:30.855859: val_loss -0.6466
2025-05-29 19:45:30.855972: Pseudo dice [0.9303, 0.7429, 0.4796, 0.6715, 0.1965, 0.9373, 0.5726, 0.6975]
2025-05-29 19:45:30.856086: Epoch time: 75.5 s
2025-05-29 19:45:32.255967: 
2025-05-29 19:45:32.256207: Epoch 233
2025-05-29 19:45:32.256434: Current learning rate: 0.00259
2025-05-29 19:46:49.083071: train_loss -1.2777
2025-05-29 19:46:49.083312: val_loss -0.7189
2025-05-29 19:46:49.083430: Pseudo dice [0.9346, 0.7551, 0.4877, 0.706, 0.144, 0.9229, 0.5963, 0.7565]
2025-05-29 19:46:49.083531: Epoch time: 76.83 s
2025-05-29 19:46:50.460236: 
2025-05-29 19:46:50.460572: Epoch 234
2025-05-29 19:46:50.460680: Current learning rate: 0.00256
2025-05-29 19:48:06.681235: train_loss -1.2787
2025-05-29 19:48:06.681550: val_loss -0.7303
2025-05-29 19:48:06.681671: Pseudo dice [0.9313, 0.7835, 0.4907, 0.71, 0.0987, 0.9476, 0.5623, 0.7256]
2025-05-29 19:48:06.681755: Epoch time: 76.22 s
2025-05-29 19:48:08.039107: 
2025-05-29 19:48:08.039407: Epoch 235
2025-05-29 19:48:08.039514: Current learning rate: 0.00252
2025-05-29 19:49:26.658347: train_loss -1.2827
2025-05-29 19:49:26.658559: val_loss -0.6691
2025-05-29 19:49:26.658675: Pseudo dice [0.9263, 0.761, 0.4623, 0.6444, 0.1344, 0.9586, 0.5612, 0.7454]
2025-05-29 19:49:26.658759: Epoch time: 78.62 s
2025-05-29 19:49:28.027890: 
2025-05-29 19:49:28.028172: Epoch 236
2025-05-29 19:49:28.028393: Current learning rate: 0.00249
2025-05-29 19:50:45.533189: train_loss -1.2821
2025-05-29 19:50:45.533484: val_loss -0.7381
2025-05-29 19:50:45.533612: Pseudo dice [0.9342, 0.773, 0.4483, 0.7361, 0.2677, 0.962, 0.5491, 0.7183]
2025-05-29 19:50:45.533725: Epoch time: 77.51 s
2025-05-29 19:50:47.902491: 
2025-05-29 19:50:47.903045: Epoch 237
2025-05-29 19:50:47.903178: Current learning rate: 0.00245
2025-05-29 19:52:05.805094: train_loss -1.2818
2025-05-29 19:52:05.805269: val_loss -0.7607
2025-05-29 19:52:05.805380: Pseudo dice [0.9293, 0.7832, 0.4715, 0.714, 0.1248, 0.9555, 0.5876, 0.7519]
2025-05-29 19:52:05.805471: Epoch time: 77.9 s
2025-05-29 19:52:07.155032: 
2025-05-29 19:52:07.155267: Epoch 238
2025-05-29 19:52:07.155370: Current learning rate: 0.00242
2025-05-29 19:53:23.755544: train_loss -1.2685
2025-05-29 19:53:23.755928: val_loss -0.6855
2025-05-29 19:53:23.756081: Pseudo dice [0.9339, 0.7594, 0.4731, 0.6777, 0.1095, 0.9374, 0.5467, 0.7133]
2025-05-29 19:53:23.756226: Pseudo dice [0.9273, 0.7539, 0.4721, 0.8148, 0.292, 0.9336, 0.6164, 0.7687]
2025-05-29 19:33:47.006690: Epoch time: 76.77 s
2025-05-29 19:33:48.391038: 
2025-05-29 19:33:48.391278: Epoch 215
2025-05-29 19:33:48.391374: Current learning rate: 0.00321
2025-05-29 19:35:04.830194: train_loss -1.2415
2025-05-29 19:35:04.830534: val_loss -0.7724
2025-05-29 19:35:04.830697: Pseudo dice [0.9401, 0.7536, 0.4448, 0.7303, 0.2986, 0.926, 0.6177, 0.7434]
2025-05-29 19:35:04.830817: Epoch time: 76.44 s
2025-05-29 19:35:06.206774: 
2025-05-29 19:35:06.207045: Epoch 216
2025-05-29 19:35:06.207179: Current learning rate: 0.00318
2025-05-29 19:36:20.884236: train_loss -1.2382
2025-05-29 19:36:20.884611: val_loss -0.8
2025-05-29 19:36:20.884737: Pseudo dice [0.9363, 0.7694, 0.4902, 0.782, 0.201, 0.9353, 0.5969, 0.7618]
2025-05-29 19:36:20.884838: Epoch time: 74.68 s
2025-05-29 19:36:22.273111: 
2025-05-29 19:36:22.273439: Epoch 217
2025-05-29 19:36:22.273552: Current learning rate: 0.00315
2025-05-29 19:37:38.656803: train_loss -1.2602
2025-05-29 19:37:38.657100: val_loss -0.8372
2025-05-29 19:37:38.657234: Pseudo dice [0.9351, 0.7509, 0.4795, 0.7988, 0.2653, 0.9322, 0.601, 0.7333]
2025-05-29 19:37:38.657322: Epoch time: 76.39 s
2025-05-29 19:37:40.078393: 
2025-05-29 19:37:40.078714: Epoch 218
2025-05-29 19:37:40.078813: Current learning rate: 0.00311
2025-05-29 19:38:56.673410: train_loss -1.2471
2025-05-29 19:38:56.673649: val_loss -0.7218
2025-05-29 19:38:56.673846: Pseudo dice [0.935, 0.7494, 0.4424, 0.7058, 0.1312, 0.9276, 0.6217, 0.7251]
2025-05-29 19:38:56.673938: Epoch time: 76.6 s
2025-05-29 19:38:58.042335: 
2025-05-29 19:38:58.042599: Epoch 219
2025-05-29 19:38:58.042721: Current learning rate: 0.00308
2025-05-29 19:40:15.280211: train_loss -1.2346
2025-05-29 19:40:15.280465: val_loss -0.7767
2025-05-29 19:40:15.280599: Pseudo dice [0.9234, 0.7611, 0.4539, 0.7206, 0.2508, 0.9221, 0.6437, 0.6977]
2025-05-29 19:40:15.280708: Epoch time: 77.24 s
2025-05-29 19:40:16.691695: 
2025-05-29 19:40:16.692129: Epoch 220
2025-05-29 19:40:16.692233: Current learning rate: 0.00304
2025-05-29 19:41:35.282235: train_loss -1.2476
2025-05-29 19:41:35.282566: val_loss -0.7838
2025-05-29 19:41:35.282694: Pseudo dice [0.933, 0.7469, 0.499, 0.7821, 0.3028, 0.9289, 0.6099, 0.6608]
2025-05-29 19:41:35.282804: Epoch time: 78.59 s
2025-05-29 19:41:36.668571: 
2025-05-29 19:41:36.668917: Epoch 221
2025-05-29 19:41:36.669017: Current learning rate: 0.00301
2025-05-29 19:42:53.697440: train_loss -1.2416
2025-05-29 19:42:53.697782: val_loss -0.7864
2025-05-29 19:42:53.697892: Pseudo dice [0.9408, 0.7624, 0.4629, 0.7499, 0.1902, 0.8941, 0.6342, 0.768]
2025-05-29 19:42:53.697983: Epoch time: 77.03 s
2025-05-29 19:42:55.064565: 
2025-05-29 19:42:55.064917: Epoch 222
2025-05-29 19:42:55.065039: Current learning rate: 0.00297
2025-05-29 19:44:10.623773: train_loss -1.2561
2025-05-29 19:44:10.624237: val_loss -0.7839
2025-05-29 19:44:10.624376: Pseudo dice [0.9384, 0.7646, 0.4169, 0.786, 0.2041, 0.9306, 0.5824, 0.7651]
2025-05-29 19:44:10.624474: Epoch time: 75.56 s
2025-05-29 19:44:11.978528: 
2025-05-29 19:44:11.978843: Epoch 223
2025-05-29 19:44:11.978950: Current learning rate: 0.00294
2025-05-29 19:45:28.600647: train_loss -1.2551
2025-05-29 19:45:28.600903: val_loss -0.7767
2025-05-29 19:45:28.601019: Pseudo dice [0.9343, 0.7315, 0.4036, 0.8077, 0.1934, 0.9288, 0.6052, 0.7083]
2025-05-29 19:45:28.601109: Epoch time: 76.62 s
2025-05-29 19:45:29.964153: 
2025-05-29 19:45:29.964511: Epoch 224
2025-05-29 19:45:29.964761: Current learning rate: 0.00291
2025-05-29 19:46:48.035024: train_loss -1.2628
2025-05-29 19:46:48.035247: val_loss -0.7384
2025-05-29 19:46:48.035367: Pseudo dice [0.9278, 0.774, 0.4597, 0.7766, 0.199, 0.9303, 0.5961, 0.7043]
2025-05-29 19:46:48.035467: Epoch time: 78.07 s
2025-05-29 19:46:49.394625: 
2025-05-29 19:46:49.394835: Epoch 225
2025-05-29 19:46:49.394931: Current learning rate: 0.00287
2025-05-29 19:48:06.288230: train_loss -1.2684
2025-05-29 19:48:06.288564: val_loss -0.7456
2025-05-29 19:48:06.288733: Pseudo dice [0.9147, 0.7065, 0.4338, 0.75, 0.2501, 0.9318, 0.6211, 0.6579]
2025-05-29 19:48:06.288833: Epoch time: 76.89 s
2025-05-29 19:48:07.712643: 
2025-05-29 19:48:07.712915: Epoch 226
2025-05-29 19:48:07.713018: Current learning rate: 0.00284
2025-05-29 19:49:26.979873: train_loss -1.2626
2025-05-29 19:49:26.980188: val_loss -0.6949
2025-05-29 19:49:26.980391: Pseudo dice [0.9228, 0.7372, 0.4346, 0.7298, 0.2742, 0.9349, 0.5887, 0.7464]
2025-05-29 19:49:26.980527: Epoch time: 79.27 s
2025-05-29 19:49:28.509125: 
2025-05-29 19:49:28.509442: Epoch 227
2025-05-29 19:49:28.509581: Current learning rate: 0.0028
2025-05-29 19:50:46.639079: train_loss -1.2448
2025-05-29 19:50:46.639245: val_loss -0.675
2025-05-29 19:50:46.639353: Pseudo dice [0.9086, 0.7129, 0.456, 0.6346, 0.2943, 0.9151, 0.5798, 0.7271]
2025-05-29 19:50:46.639430: Epoch time: 78.13 s
2025-05-29 19:50:47.994361: 
2025-05-29 19:50:47.994578: Epoch 228
2025-05-29 19:50:47.994719: Current learning rate: 0.00277
2025-05-29 19:52:06.641749: train_loss -1.2297
2025-05-29 19:52:06.641987: val_loss -0.7566
2025-05-29 19:52:06.642160: Pseudo dice [0.9255, 0.7231, 0.4516, 0.7729, 0.2713, 0.9022, 0.628, 0.699]
2025-05-29 19:52:06.642254: Epoch time: 78.65 s
2025-05-29 19:52:08.017434: 
2025-05-29 19:52:08.017817: Epoch 229
2025-05-29 19:52:08.017942: Current learning rate: 0.00273
2025-05-29 19:53:25.095860: train_loss -1.2577
2025-05-29 19:53:25.096074: val_loss -0.8056
2025-05-29 19:53:25.096186: Pseudo dice [0.933, 0.7489, 0.4636, 0.8192, 0.3104, 0.9219, 0.6124, 0.7578]
2025-05-29 19:53:25.096273: Epoch time: 77.08 s
2025-05-29 19:53:26.448284: 
2025-05-29 19:53:26.448583: Epoch 230
2025-05-29 19:53:26.448730: Current learning rate: 0.0027
2025-05-29 19:54:43.619758: train_loss -1.2507
2025-05-29 19:54:43.620049: val_loss -0.7807
2025-05-29 19:54:43.620193: Pseudo dice [0.9279, 0.7067, 0.4686, 0.8076, 0.393, 0.9207, 0.5949, 0.7349]
2025-05-29 19:54:43.620289: Epoch time: 77.17 s
2025-05-29 19:54:44.986772: 
2025-05-29 19:54:44.987171: Epoch 231
2025-05-29 19:54:44.987271: Current learning rate: 0.00266
2025-05-29 19:56:01.863006: train_loss -1.2525
2025-05-29 19:56:01.863321: val_loss -0.7497
2025-05-29 19:56:01.863493: Pseudo dice [0.9251, 0.7306, 0.4555, 0.7997, 0.2212, 0.9172, 0.6126, 0.7047]
2025-05-29 19:56:01.863660: Epoch time: 76.88 s
2025-05-29 19:56:03.249232: 
2025-05-29 19:56:03.249595: Epoch 232
2025-05-29 19:56:03.249722: Current learning rate: 0.00263
2025-05-29 19:57:19.940428: train_loss -1.2465
2025-05-29 19:57:19.940768: val_loss -0.8506
2025-05-29 19:57:19.940993: Pseudo dice [0.9353, 0.7544, 0.4924, 0.8229, 0.2489, 0.9155, 0.6278, 0.7514]
2025-05-29 19:57:19.941087: Epoch time: 76.69 s
2025-05-29 19:57:21.337232: 
2025-05-29 19:57:21.337728: Epoch 233
2025-05-29 19:57:21.337833: Current learning rate: 0.00259
2025-05-29 19:58:37.623767: train_loss -1.2473
2025-05-29 19:58:37.624037: val_loss -0.787
2025-05-29 19:58:37.624156: Pseudo dice [0.9225, 0.7086, 0.4099, 0.8257, 0.385, 0.9236, 0.5977, 0.6942]
2025-05-29 19:58:37.624245: Epoch time: 76.29 s
2025-05-29 19:58:39.091212: 
2025-05-29 19:58:39.091629: Epoch 234
2025-05-29 19:58:39.091736: Current learning rate: 0.00256
2025-05-29 19:59:53.361593: train_loss -1.2492
2025-05-29 19:59:53.361988: val_loss -0.8023
2025-05-29 19:59:53.362227: Pseudo dice [0.9341, 0.7536, 0.5084, 0.8027, 0.2486, 0.9063, 0.6046, 0.7673]
2025-05-29 19:59:53.362335: Epoch time: 74.27 s
2025-05-29 19:59:54.798878: 
2025-05-29 19:59:54.799302: Epoch 235
2025-05-29 19:59:54.799413: Current learning rate: 0.00252
2025-05-29 20:01:08.280966: train_loss -1.2584
2025-05-29 20:01:08.281299: val_loss -0.8045
2025-05-29 20:01:08.281625: Pseudo dice [0.9384, 0.7519, 0.467, 0.798, 0.28, 0.8972, 0.6096, 0.7633]
2025-05-29 20:01:08.281710: Epoch time: 73.48 s
2025-05-29 20:01:08.281760: Yayy! New best EMA pseudo Dice: 0.6797
2025-05-29 20:01:11.004516: 
2025-05-29 20:01:11.005109: Epoch 236
2025-05-29 20:01:11.005419: Current learning rate: 0.00249
2025-05-29 20:02:26.698106: train_loss -1.2606
2025-05-29 20:02:26.698525: val_loss -0.7735
2025-05-29 20:02:26.698718: 
2025-05-29 19:40:14.702376: Epoch 194
2025-05-29 19:40:14.702489: Current learning rate: 0.00392
2025-05-29 19:41:39.157079: train_loss -1.1963
2025-05-29 19:41:39.157376: val_loss -0.6979
2025-05-29 19:41:39.157521: Pseudo dice [0.9119, 0.6617, 0.3845, 0.7449, 0.022, 0.9003, 0.4809, 0.8098]
2025-05-29 19:41:39.157600: Epoch time: 84.46 s
2025-05-29 19:41:40.543283: 
2025-05-29 19:41:40.543537: Epoch 195
2025-05-29 19:41:40.543645: Current learning rate: 0.00389
2025-05-29 19:43:05.125041: train_loss -1.2172
2025-05-29 19:43:05.125279: val_loss -0.7491
2025-05-29 19:43:05.125398: Pseudo dice [0.9161, 0.6465, 0.4451, 0.7838, 0.0899, 0.9099, 0.4996, 0.7916]
2025-05-29 19:43:05.125490: Epoch time: 84.58 s
2025-05-29 19:43:06.561125: 
2025-05-29 19:43:06.561325: Epoch 196
2025-05-29 19:43:06.561477: Current learning rate: 0.00385
2025-05-29 19:44:34.495920: train_loss -1.216
2025-05-29 19:44:34.496309: val_loss -0.6905
2025-05-29 19:44:34.496426: Pseudo dice [0.9126, 0.6618, 0.4081, 0.7057, 0.0083, 0.9257, 0.5291, 0.7884]
2025-05-29 19:44:34.496534: Epoch time: 87.94 s
2025-05-29 19:44:35.979268: 
2025-05-29 19:44:35.979541: Epoch 197
2025-05-29 19:44:35.979657: Current learning rate: 0.00382
2025-05-29 19:46:06.267499: train_loss -1.2066
2025-05-29 19:46:06.267734: val_loss -0.5991
2025-05-29 19:46:06.267857: Pseudo dice [0.8963, 0.6295, 0.4618, 0.6181, 0.0316, 0.8879, 0.5058, 0.7987]
2025-05-29 19:46:06.267948: Epoch time: 90.29 s
2025-05-29 19:46:07.748630: 
2025-05-29 19:46:07.748933: Epoch 198
2025-05-29 19:46:07.749069: Current learning rate: 0.00379
2025-05-29 19:47:37.707136: train_loss -1.1954
2025-05-29 19:47:37.707366: val_loss -0.7666
2025-05-29 19:47:37.707598: Pseudo dice [0.9273, 0.6836, 0.4545, 0.7567, 0.0913, 0.9103, 0.5429, 0.8447]
2025-05-29 19:47:37.707712: Epoch time: 89.96 s
2025-05-29 19:47:37.707765: Yayy! New best EMA pseudo Dice: 0.622
2025-05-29 19:47:41.410864: 
2025-05-29 19:47:41.411027: Epoch 199
2025-05-29 19:47:41.411129: Current learning rate: 0.00375
2025-05-29 19:49:10.194878: train_loss -1.1718
2025-05-29 19:49:10.195158: val_loss -0.6873
2025-05-29 19:49:10.195277: Pseudo dice [0.899, 0.6541, 0.4742, 0.7023, 0.1259, 0.8925, 0.5292, 0.784]
2025-05-29 19:49:10.195396: Epoch time: 88.79 s
2025-05-29 19:49:11.781223: Yayy! New best EMA pseudo Dice: 0.623
2025-05-29 19:49:14.466481: 
2025-05-29 19:49:14.466915: Epoch 200
2025-05-29 19:49:14.467021: Current learning rate: 0.00372
2025-05-29 19:50:44.180470: train_loss -1.2188
2025-05-29 19:50:44.180696: val_loss -0.7197
2025-05-29 19:50:44.180817: Pseudo dice [0.9212, 0.6452, 0.4912, 0.729, 0.0775, 0.9145, 0.5539, 0.8144]
2025-05-29 19:50:44.180918: Epoch time: 89.72 s
2025-05-29 19:50:44.180986: Yayy! New best EMA pseudo Dice: 0.6251
2025-05-29 19:50:47.046796: 
2025-05-29 19:50:47.047145: Epoch 201
2025-05-29 19:50:47.047280: Current learning rate: 0.00369
2025-05-29 19:52:11.406598: train_loss -1.1996
2025-05-29 19:52:11.406927: val_loss -0.7087
2025-05-29 19:52:11.407058: Pseudo dice [0.9013, 0.6912, 0.4469, 0.7605, 0.0091, 0.897, 0.4875, 0.7873]
2025-05-29 19:52:11.407160: Epoch time: 84.36 s
2025-05-29 19:52:12.791684: 
2025-05-29 19:52:12.792019: Epoch 202
2025-05-29 19:52:12.792123: Current learning rate: 0.00365
2025-05-29 19:53:37.551893: train_loss -1.1724
2025-05-29 19:53:37.552178: val_loss -0.6568
2025-05-29 19:53:37.552306: Pseudo dice [0.9054, 0.6043, 0.4984, 0.668, 0.0555, 0.8819, 0.5584, 0.7665]
2025-05-29 19:53:37.552413: Epoch time: 84.76 s
2025-05-29 19:53:38.966971: 
2025-05-29 19:53:38.967256: Epoch 203
2025-05-29 19:53:38.967355: Current learning rate: 0.00362
2025-05-29 19:55:05.960157: train_loss -1.1548
2025-05-29 19:55:05.960377: val_loss -0.7244
2025-05-29 19:55:05.960503: Pseudo dice [0.8975, 0.6438, 0.4251, 0.7432, 0.1014, 0.8841, 0.5191, 0.7945]
2025-05-29 19:55:05.960593: Epoch time: 86.99 s
2025-05-29 19:55:07.369418: 
2025-05-29 19:55:07.369831: Epoch 204
2025-05-29 19:55:07.369942: Current learning rate: 0.00359
2025-05-29 19:56:32.807384: train_loss -1.1934
2025-05-29 19:56:32.807627: val_loss -0.6927
2025-05-29 19:56:32.807777: Pseudo dice [0.9263, 0.6832, 0.423, 0.6914, 0.0596, 0.9, 0.4942, 0.8057]
2025-05-29 19:56:32.807863: Epoch time: 85.44 s
2025-05-29 19:56:34.202760: 
2025-05-29 19:56:34.203229: Epoch 205
2025-05-29 19:56:34.203410: Current learning rate: 0.00355
2025-05-29 19:57:57.947796: train_loss -1.1668
2025-05-29 19:57:57.948014: val_loss -0.7157
2025-05-29 19:57:57.948131: Pseudo dice [0.9171, 0.6673, 0.3684, 0.714, 0.0479, 0.9033, 0.5223, 0.845]
2025-05-29 19:57:57.948215: Epoch time: 83.75 s
2025-05-29 19:57:59.422226: 
2025-05-29 19:57:59.422532: Epoch 206
2025-05-29 19:57:59.422653: Current learning rate: 0.00352
2025-05-29 19:59:29.001248: train_loss -1.1987
2025-05-29 19:59:29.001496: val_loss -0.7179
2025-05-29 19:59:29.001617: Pseudo dice [0.9105, 0.6827, 0.4633, 0.6713, 0.1028, 0.8961, 0.5465, 0.8284]
2025-05-29 19:59:29.001713: Epoch time: 89.58 s
2025-05-29 19:59:29.001839: Yayy! New best EMA pseudo Dice: 0.6254
2025-05-29 19:59:31.566037: 
2025-05-29 19:59:31.566281: Epoch 207
2025-05-29 19:59:31.566378: Current learning rate: 0.00349
2025-05-29 20:01:01.665805: train_loss -1.2072
2025-05-29 20:01:01.666102: val_loss -0.692
2025-05-29 20:01:01.666266: Pseudo dice [0.9198, 0.6449, 0.4635, 0.7121, 0.0691, 0.9133, 0.4811, 0.8418]
2025-05-29 20:01:01.666420: Epoch time: 90.1 s
2025-05-29 20:01:01.666533: Yayy! New best EMA pseudo Dice: 0.6259
2025-05-29 20:01:04.911435: 
2025-05-29 20:01:04.911900: Epoch 208
2025-05-29 20:01:04.912136: Current learning rate: 0.00345
2025-05-29 20:02:33.436071: train_loss -1.2309
2025-05-29 20:02:33.436287: val_loss -0.739
2025-05-29 20:02:33.436401: Pseudo dice [0.923, 0.6613, 0.4461, 0.7454, 0.0512, 0.8996, 0.5408, 0.8571]
2025-05-29 20:02:33.436492: Epoch time: 88.53 s
2025-05-29 20:02:33.436547: Yayy! New best EMA pseudo Dice: 0.6274
2025-05-29 20:02:36.028013: 
2025-05-29 20:02:36.028161: Epoch 209
2025-05-29 20:02:36.028342: Current learning rate: 0.00342
2025-05-29 20:04:05.142630: train_loss -1.2232
2025-05-29 20:04:05.142843: val_loss -0.7447
2025-05-29 20:04:05.143015: Pseudo dice [0.9261, 0.6879, 0.4314, 0.7561, 0.0817, 0.8644, 0.5265, 0.793]
2025-05-29 20:04:05.143110: Epoch time: 89.12 s
2025-05-29 20:04:05.143177: Yayy! New best EMA pseudo Dice: 0.628
2025-05-29 20:04:07.679282: 
2025-05-29 20:04:07.679698: Epoch 210
2025-05-29 20:04:07.679873: Current learning rate: 0.00338
2025-05-29 20:05:36.374943: train_loss -1.2078
2025-05-29 20:05:36.375131: val_loss -0.6376
2025-05-29 20:05:36.375242: Pseudo dice [0.9171, 0.6081, 0.4507, 0.6676, 0.0598, 0.88, 0.4868, 0.7945]
2025-05-29 20:05:36.375381: Epoch time: 88.7 s
2025-05-29 20:05:37.725039: 
2025-05-29 20:05:37.725266: Epoch 211
2025-05-29 20:05:37.725365: Current learning rate: 0.00335
2025-05-29 20:07:07.718954: train_loss -1.1979
2025-05-29 20:07:07.719149: val_loss -0.6918
2025-05-29 20:07:07.719265: Pseudo dice [0.9206, 0.6605, 0.4521, 0.6763, 0.1709, 0.9017, 0.5022, 0.7975]
2025-05-29 20:07:07.719340: Epoch time: 90.0 s
2025-05-29 20:07:09.141257: 
2025-05-29 20:07:09.141704: Epoch 212
2025-05-29 20:07:09.141922: Current learning rate: 0.00332
2025-05-29 20:08:37.431497: train_loss -1.2105
2025-05-29 20:08:37.431913: val_loss -0.7549
2025-05-29 20:08:37.432062: Pseudo dice [0.9193, 0.6552, 0.4234, 0.7652, 0.0842, 0.9202, 0.4985, 0.836]
2025-05-29 20:08:37.432152: Epoch time: 88.29 s
2025-05-29 20:08:37.432208: Yayy! New best EMA pseudo Dice: 0.628
2025-05-29 20:08:39.886167: 
2025-05-29 20:08:39.886532: Epoch 213
2025-05-29 20:08:39.886689: Current learning rate: 0.00328
2025-05-29 20:10:04.373445: train_loss -1.2224
2025-05-29 20:10:04.373694: val_loss -0.6941
2025-05-29 20:10:04.373842: Pseudo dice [0.9198, 0.6566, 0.4537, 0.6895, 0.0746, 0.8688, 0.4947, 0.7946]
2025-05-29 20:10:04.373940: Epoch time: 84.49 s
2025-05-29 20:10:05.782975: 
2025-05-29 20:10:05.783257: Epoch 214
2025-05-29 20:10:05.783376: Current learning rate: 0.00325
2025-05-29 20:11:28.930516: train_loss -1.2177
2025-05-29 20:11:28.930753: val_loss -0.6854
2025-05-29 20:11:28.931009: Pseudo dice [0.9081, 0.6628, 0.4218, 0.7281, 0.1393, 0.8682, 0.4965, 0.8088] Epoch time: 76.6 s
2025-05-29 19:53:25.117241: 
2025-05-29 19:53:25.117663: Epoch 239
2025-05-29 19:53:25.117759: Current learning rate: 0.00238
2025-05-29 19:54:39.571350: train_loss -1.2855
2025-05-29 19:54:39.571762: val_loss -0.6944
2025-05-29 19:54:39.571914: Pseudo dice [0.9397, 0.779, 0.4439, 0.6963, 0.105, 0.9539, 0.5905, 0.7252]
2025-05-29 19:54:39.571994: Epoch time: 74.46 s
2025-05-29 19:54:40.991305: 
2025-05-29 19:54:40.991623: Epoch 240
2025-05-29 19:54:40.991744: Current learning rate: 0.00235
2025-05-29 19:55:56.481422: train_loss -1.2717
2025-05-29 19:55:56.481728: val_loss -0.6506
2025-05-29 19:55:56.482031: Pseudo dice [0.9338, 0.7626, 0.4898, 0.6294, 0.1837, 0.9475, 0.5662, 0.7037]
2025-05-29 19:55:56.482175: Epoch time: 75.49 s
2025-05-29 19:55:57.873866: 
2025-05-29 19:55:57.874003: Epoch 241
2025-05-29 19:55:57.874096: Current learning rate: 0.00231
2025-05-29 19:57:12.706208: train_loss -1.2681
2025-05-29 19:57:12.706528: val_loss -0.6576
2025-05-29 19:57:12.706659: Pseudo dice [0.9186, 0.7796, 0.458, 0.6913, 0.2058, 0.956, 0.6231, 0.6828]
2025-05-29 19:57:12.706758: Epoch time: 74.83 s
2025-05-29 19:57:14.077722: 
2025-05-29 19:57:14.078149: Epoch 242
2025-05-29 19:57:14.078247: Current learning rate: 0.00228
2025-05-29 19:58:28.249772: train_loss -1.2906
2025-05-29 19:58:28.249985: val_loss -0.6243
2025-05-29 19:58:28.250108: Pseudo dice [0.9295, 0.7544, 0.449, 0.6772, 0.256, 0.9436, 0.5747, 0.7433]
2025-05-29 19:58:28.250240: Epoch time: 74.17 s
2025-05-29 19:58:29.631410: 
2025-05-29 19:58:29.631757: Epoch 243
2025-05-29 19:58:29.631872: Current learning rate: 0.00224
2025-05-29 19:59:44.154603: train_loss -1.2941
2025-05-29 19:59:44.154891: val_loss -0.6821
2025-05-29 19:59:44.155109: Pseudo dice [0.9306, 0.7816, 0.4403, 0.6917, 0.2499, 0.9602, 0.5893, 0.7234]
2025-05-29 19:59:44.155208: Epoch time: 74.52 s
2025-05-29 19:59:44.155265: Yayy! New best EMA pseudo Dice: 0.6579
2025-05-29 19:59:46.882764: 
2025-05-29 19:59:46.883054: Epoch 244
2025-05-29 19:59:46.883182: Current learning rate: 0.00221
2025-05-29 20:01:01.483662: train_loss -1.284
2025-05-29 20:01:01.483893: val_loss -0.7077
2025-05-29 20:01:01.484006: Pseudo dice [0.9297, 0.7764, 0.4845, 0.7319, 0.2091, 0.9446, 0.5832, 0.7617]
2025-05-29 20:01:01.484093: Epoch time: 74.6 s
2025-05-29 20:01:01.484201: Yayy! New best EMA pseudo Dice: 0.6598
2025-05-29 20:01:04.875001: 
2025-05-29 20:01:04.875345: Epoch 245
2025-05-29 20:01:04.875515: Current learning rate: 0.00217
2025-05-29 20:02:16.614006: train_loss -1.2815
2025-05-29 20:02:16.614285: val_loss -0.6479
2025-05-29 20:02:16.614437: Pseudo dice [0.9324, 0.7771, 0.4685, 0.6537, 0.0969, 0.9579, 0.594, 0.7097]
2025-05-29 20:02:16.614567: Epoch time: 71.74 s
2025-05-29 20:02:18.019604: 
2025-05-29 20:02:18.019937: Epoch 246
2025-05-29 20:02:18.020039: Current learning rate: 0.00214
2025-05-29 20:03:30.497864: train_loss -1.2887
2025-05-29 20:03:30.498238: val_loss -0.7097
2025-05-29 20:03:30.498467: Pseudo dice [0.93, 0.7453, 0.4596, 0.6773, 0.255, 0.9372, 0.5338, 0.7233]
2025-05-29 20:03:30.498613: Epoch time: 72.48 s
2025-05-29 20:03:31.930943: 
2025-05-29 20:03:31.931247: Epoch 247
2025-05-29 20:03:31.931344: Current learning rate: 0.0021
2025-05-29 20:04:46.533172: train_loss -1.2717
2025-05-29 20:04:46.533386: val_loss -0.7064
2025-05-29 20:04:46.533511: Pseudo dice [0.9383, 0.7945, 0.4413, 0.678, 0.1847, 0.9552, 0.5877, 0.7799]
2025-05-29 20:04:46.533602: Epoch time: 74.6 s
2025-05-29 20:04:48.692732: 
2025-05-29 20:04:48.693012: Epoch 248
2025-05-29 20:04:48.693119: Current learning rate: 0.00207
2025-05-29 20:06:02.843986: train_loss -1.2874
2025-05-29 20:06:02.844209: val_loss -0.6432
2025-05-29 20:06:02.844322: Pseudo dice [0.925, 0.7967, 0.4166, 0.6821, 0.222, 0.9432, 0.5798, 0.6864]
2025-05-29 20:06:02.844407: Epoch time: 74.15 s
2025-05-29 20:06:04.274647: 
2025-05-29 20:06:04.274945: Epoch 249
2025-05-29 20:06:04.275129: Current learning rate: 0.00203
2025-05-29 20:07:18.542386: train_loss -1.3029
2025-05-29 20:07:18.542664: val_loss -0.6662
2025-05-29 20:07:18.542780: Pseudo dice [0.9332, 0.7822, 0.443, 0.6527, 0.0409, 0.9408, 0.5719, 0.77]
2025-05-29 20:07:18.542874: Epoch time: 74.27 s
2025-05-29 20:07:21.248986: 
2025-05-29 20:07:21.249343: Epoch 250
2025-05-29 20:07:21.249507: Current learning rate: 0.00199
2025-05-29 20:08:34.896727: train_loss -1.3019
2025-05-29 20:08:34.896966: val_loss -0.7297
2025-05-29 20:08:34.897082: Pseudo dice [0.9322, 0.7793, 0.4631, 0.7261, 0.3489, 0.9456, 0.5683, 0.7182]
2025-05-29 20:08:34.897160: Epoch time: 73.65 s
2025-05-29 20:08:34.897214: Yayy! New best EMA pseudo Dice: 0.6604
2025-05-29 20:08:37.450310: 
2025-05-29 20:08:37.450606: Epoch 251
2025-05-29 20:08:37.450793: Current learning rate: 0.00196
2025-05-29 20:09:51.985148: train_loss -1.2892
2025-05-29 20:09:51.985476: val_loss -0.7629
2025-05-29 20:09:51.985631: Pseudo dice [0.9358, 0.7753, 0.5043, 0.7347, 0.2224, 0.9439, 0.5997, 0.7188]
2025-05-29 20:09:51.985736: Epoch time: 74.54 s
2025-05-29 20:09:51.985791: Yayy! New best EMA pseudo Dice: 0.6623
2025-05-29 20:09:54.711582: 
2025-05-29 20:09:54.711941: Epoch 252
2025-05-29 20:09:54.712065: Current learning rate: 0.00192
2025-05-29 20:11:05.898030: train_loss -1.3022
2025-05-29 20:11:05.898253: val_loss -0.7525
2025-05-29 20:11:05.898366: Pseudo dice [0.9413, 0.7672, 0.4776, 0.7263, 0.146, 0.9403, 0.6074, 0.7768]
2025-05-29 20:11:05.898478: Epoch time: 71.19 s
2025-05-29 20:11:05.898640: Yayy! New best EMA pseudo Dice: 0.6634
2025-05-29 20:11:08.627790: 
2025-05-29 20:11:08.628093: Epoch 253
2025-05-29 20:11:08.628246: Current learning rate: 0.00189
2025-05-29 20:12:20.624285: train_loss -1.2851
2025-05-29 20:12:20.624510: val_loss -0.7075
2025-05-29 20:12:20.624623: Pseudo dice [0.9313, 0.7776, 0.4506, 0.7312, 0.2344, 0.9339, 0.586, 0.7143]
2025-05-29 20:12:20.624705: Epoch time: 72.0 s
2025-05-29 20:12:20.624759: Yayy! New best EMA pseudo Dice: 0.664
2025-05-29 20:12:23.372174: 
2025-05-29 20:12:23.372569: Epoch 254
2025-05-29 20:12:23.372674: Current learning rate: 0.00185
2025-05-29 20:13:34.913937: train_loss -1.301
2025-05-29 20:13:34.914186: val_loss -0.6657
2025-05-29 20:13:34.914295: Pseudo dice [0.9211, 0.7569, 0.4976, 0.7048, 0.1136, 0.9528, 0.5696, 0.7254]
2025-05-29 20:13:34.914374: Epoch time: 71.54 s
2025-05-29 20:13:36.292687: 
2025-05-29 20:13:36.293018: Epoch 255
2025-05-29 20:13:36.293139: Current learning rate: 0.00181
2025-05-29 20:14:48.599952: train_loss -1.2947
2025-05-29 20:14:48.600168: val_loss -0.718
2025-05-29 20:14:48.600286: Pseudo dice [0.9351, 0.8077, 0.4581, 0.7336, 0.2286, 0.9592, 0.582, 0.7023]
2025-05-29 20:14:48.600374: Epoch time: 72.31 s
2025-05-29 20:14:48.600427: Yayy! New best EMA pseudo Dice: 0.6644
2025-05-29 20:14:51.239597: 
2025-05-29 20:14:51.239837: Epoch 256
2025-05-29 20:14:51.239932: Current learning rate: 0.00178
2025-05-29 20:16:03.589936: train_loss -1.2956
2025-05-29 20:16:03.590137: val_loss -0.6666
2025-05-29 20:16:03.590254: Pseudo dice [0.9403, 0.8045, 0.4443, 0.6243, 0.1957, 0.9592, 0.5536, 0.7741]
2025-05-29 20:16:03.590337: Epoch time: 72.35 s
2025-05-29 20:16:04.929568: 
2025-05-29 20:16:04.929960: Epoch 257
2025-05-29 20:16:04.930054: Current learning rate: 0.00174
2025-05-29 20:17:19.897790: train_loss -1.2872
2025-05-29 20:17:19.898009: val_loss -0.723
2025-05-29 20:17:19.898123: Pseudo dice [0.9331, 0.7611, 0.4726, 0.711, 0.2229, 0.9547, 0.613, 0.7298]
2025-05-29 20:17:19.898214: Epoch time: 74.97 s
2025-05-29 20:17:19.898268: Yayy! New best EMA pseudo Dice: 0.6652
2025-05-29 20:17:23.257709: 
2025-05-29 20:17:23.258066: Epoch 258
2025-05-29 20:17:23.258225: Current learning rate: 0.0017
2025-05-29 20:18:36.299978: train_loss -1.292
2025-05-29 20:18:36.300184: val_loss -0.7159
2025-05-29 20:18:36.300298: Pseudo dice [0.9363, 0.7854, 0.4602, 0.7254, 0.1882, 0.9507, 0.5841, 0.6698]
2025-05-29 20:18:36.300380: Epoch time: 73.04 s
2025-05-29 20:18:37.671655: 
2025-05-29 20:18:37.671965: Epoch 259
2025-05-29 20:18:37.672130: Current learning rate: 0.00167
2025-05-29 20:19:48.677044: train_loss -1.2824
2025-05-29 20:19:48.677266: val_loss -0.7505
2025-05-29 20:19:48.677416: Pseudo dice Pseudo dice [0.937, 0.7571, 0.4531, 0.8017, 0.3045, 0.929, 0.6037, 0.754]
2025-05-29 20:02:26.699440: Epoch time: 75.7 s
2025-05-29 20:02:26.699546: Yayy! New best EMA pseudo Dice: 0.681
2025-05-29 20:02:29.197915: 
2025-05-29 20:02:29.198194: Epoch 237
2025-05-29 20:02:29.198300: Current learning rate: 0.00245
2025-05-29 20:03:45.420319: train_loss -1.2485
2025-05-29 20:03:45.420608: val_loss -0.7865
2025-05-29 20:03:45.421093: Pseudo dice [0.9281, 0.786, 0.4686, 0.8188, 0.2426, 0.9082, 0.61, 0.6768]
2025-05-29 20:03:45.421407: Epoch time: 76.22 s
2025-05-29 20:03:46.820091: 
2025-05-29 20:03:46.820329: Epoch 238
2025-05-29 20:03:46.820495: Current learning rate: 0.00242
2025-05-29 20:05:02.328317: train_loss -1.2652
2025-05-29 20:05:02.328583: val_loss -0.7629
2025-05-29 20:05:02.328705: Pseudo dice [0.9327, 0.7445, 0.4709, 0.7912, 0.2415, 0.914, 0.6136, 0.6487]
2025-05-29 20:05:02.328909: Epoch time: 75.51 s
2025-05-29 20:05:03.737165: 
2025-05-29 20:05:03.737558: Epoch 239
2025-05-29 20:05:03.737661: Current learning rate: 0.00238
2025-05-29 20:06:19.792046: train_loss -1.2604
2025-05-29 20:06:19.792289: val_loss -0.7689
2025-05-29 20:06:19.792411: Pseudo dice [0.9257, 0.7436, 0.4495, 0.8106, 0.2196, 0.9332, 0.6024, 0.6566]
2025-05-29 20:06:19.792920: Epoch time: 76.06 s
2025-05-29 20:06:21.198589: 
2025-05-29 20:06:21.199007: Epoch 240
2025-05-29 20:06:21.199127: Current learning rate: 0.00235
2025-05-29 20:07:35.436543: train_loss -1.2652
2025-05-29 20:07:35.436762: val_loss -0.7754
2025-05-29 20:07:35.436881: Pseudo dice [0.9241, 0.761, 0.4569, 0.7858, 0.1914, 0.9329, 0.6165, 0.7385]
2025-05-29 20:07:35.436969: Epoch time: 74.24 s
2025-05-29 20:07:36.849843: 
2025-05-29 20:07:36.850125: Epoch 241
2025-05-29 20:07:36.850269: Current learning rate: 0.00231
2025-05-29 20:08:51.051956: train_loss -1.2678
2025-05-29 20:08:51.052251: val_loss -0.8399
2025-05-29 20:08:51.052370: Pseudo dice [0.9327, 0.7729, 0.4246, 0.8443, 0.2621, 0.9084, 0.6244, 0.7707]
2025-05-29 20:08:51.052472: Epoch time: 74.2 s
2025-05-29 20:08:52.486999: 
2025-05-29 20:08:52.487673: Epoch 242
2025-05-29 20:08:52.487946: Current learning rate: 0.00228
2025-05-29 20:10:06.340852: train_loss -1.275
2025-05-29 20:10:06.341083: val_loss -0.8187
2025-05-29 20:10:06.341197: Pseudo dice [0.9446, 0.7929, 0.4495, 0.8169, 0.2575, 0.9084, 0.6098, 0.799]
2025-05-29 20:10:06.341284: Epoch time: 73.86 s
2025-05-29 20:10:06.341338: Yayy! New best EMA pseudo Dice: 0.6814
2025-05-29 20:10:09.217566: 
2025-05-29 20:10:09.218132: Epoch 243
2025-05-29 20:10:09.218397: Current learning rate: 0.00224
2025-05-29 20:11:23.409769: train_loss -1.2648
2025-05-29 20:11:23.410875: val_loss -0.8241
2025-05-29 20:11:23.411061: Pseudo dice [0.9407, 0.7726, 0.5033, 0.8007, 0.4571, 0.9219, 0.6133, 0.7982]
2025-05-29 20:11:23.411280: Epoch time: 74.19 s
2025-05-29 20:11:23.411337: Yayy! New best EMA pseudo Dice: 0.6859
2025-05-29 20:11:26.299806: 
2025-05-29 20:11:26.300128: Epoch 244
2025-05-29 20:11:26.300245: Current learning rate: 0.00221
2025-05-29 20:12:40.562249: train_loss -1.2805
2025-05-29 20:12:40.562632: val_loss -0.7437
2025-05-29 20:12:40.562825: Pseudo dice [0.9259, 0.7213, 0.4809, 0.7841, 0.3039, 0.9267, 0.6055, 0.7726]
2025-05-29 20:12:40.562983: Epoch time: 74.26 s
2025-05-29 20:12:40.563057: Yayy! New best EMA pseudo Dice: 0.6863
2025-05-29 20:12:43.377221: 
2025-05-29 20:12:43.378311: Epoch 245
2025-05-29 20:12:43.378595: Current learning rate: 0.00217
2025-05-29 20:13:58.800229: train_loss -1.2637
2025-05-29 20:13:58.800719: val_loss -0.7797
2025-05-29 20:13:58.800870: Pseudo dice [0.9438, 0.7446, 0.469, 0.7739, 0.3343, 0.9308, 0.5822, 0.7658]
2025-05-29 20:13:58.800995: Epoch time: 75.43 s
2025-05-29 20:13:58.801108: Yayy! New best EMA pseudo Dice: 0.687
2025-05-29 20:14:01.572886: 
2025-05-29 20:14:01.573286: Epoch 246
2025-05-29 20:14:01.573388: Current learning rate: 0.00214
2025-05-29 20:15:16.023019: train_loss -1.281
2025-05-29 20:15:16.023332: val_loss -0.7921
2025-05-29 20:15:16.023525: Pseudo dice [0.9323, 0.7552, 0.4306, 0.7897, 0.3022, 0.926, 0.6035, 0.7615]
2025-05-29 20:15:16.023633: Epoch time: 74.45 s
2025-05-29 20:15:16.023710: Yayy! New best EMA pseudo Dice: 0.6871
2025-05-29 20:15:18.854353: 
2025-05-29 20:15:18.854668: Epoch 247
2025-05-29 20:15:18.854772: Current learning rate: 0.0021
2025-05-29 20:16:35.520981: train_loss -1.2953
2025-05-29 20:16:35.521272: val_loss -0.7764
2025-05-29 20:16:35.521408: Pseudo dice [0.919, 0.745, 0.5124, 0.7952, 0.304, 0.9228, 0.617, 0.6755]
2025-05-29 20:16:35.521527: Epoch time: 76.67 s
2025-05-29 20:16:36.893621: 
2025-05-29 20:16:36.893976: Epoch 248
2025-05-29 20:16:36.894078: Current learning rate: 0.00207
2025-05-29 20:17:50.554541: train_loss -1.2632
2025-05-29 20:17:50.554850: val_loss -0.7902
2025-05-29 20:17:50.555013: Pseudo dice [0.9363, 0.7325, 0.4884, 0.7695, 0.3674, 0.9229, 0.6209, 0.7088]
2025-05-29 20:17:50.555176: Epoch time: 73.66 s
2025-05-29 20:17:50.555244: Yayy! New best EMA pseudo Dice: 0.6876
2025-05-29 20:17:53.318088: 
2025-05-29 20:17:53.318542: Epoch 249
2025-05-29 20:17:53.318676: Current learning rate: 0.00203
2025-05-29 20:19:09.700433: train_loss -1.2798
2025-05-29 20:19:09.700881: val_loss -0.794
2025-05-29 20:19:09.701172: Pseudo dice [0.9258, 0.7625, 0.4705, 0.8124, 0.2817, 0.9233, 0.6246, 0.704]
2025-05-29 20:19:09.701264: Epoch time: 76.39 s
2025-05-29 20:19:10.843723: Yayy! New best EMA pseudo Dice: 0.6877
2025-05-29 20:19:13.641754: 
2025-05-29 20:19:13.642053: Epoch 250
2025-05-29 20:19:13.642171: Current learning rate: 0.00199
2025-05-29 20:20:30.836552: train_loss -1.2705
2025-05-29 20:20:30.836784: val_loss -0.7828
2025-05-29 20:20:30.836954: Pseudo dice [0.9378, 0.764, 0.4651, 0.7807, 0.2088, 0.9164, 0.6214, 0.7305]
2025-05-29 20:20:30.837076: Epoch time: 77.2 s
2025-05-29 20:20:32.877126: 
2025-05-29 20:20:32.877523: Epoch 251
2025-05-29 20:20:32.877661: Current learning rate: 0.00196
2025-05-29 20:21:49.776293: train_loss -1.2834
2025-05-29 20:21:49.776529: val_loss -0.7577
2025-05-29 20:21:49.776660: Pseudo dice [0.9414, 0.754, 0.4632, 0.7657, 0.2526, 0.9135, 0.5958, 0.7698]
2025-05-29 20:21:49.776758: Epoch time: 76.9 s
2025-05-29 20:21:51.143172: 
2025-05-29 20:21:51.143375: Epoch 252
2025-05-29 20:21:51.143486: Current learning rate: 0.00192
2025-05-29 20:23:07.584522: train_loss -1.2725
2025-05-29 20:23:07.584856: val_loss -0.7889
2025-05-29 20:23:07.585013: Pseudo dice [0.9374, 0.7575, 0.4512, 0.8069, 0.2481, 0.9059, 0.6006, 0.7327]
2025-05-29 20:23:07.585108: Epoch time: 76.44 s
2025-05-29 20:23:08.967098: 
2025-05-29 20:23:08.967270: Epoch 253
2025-05-29 20:23:08.967398: Current learning rate: 0.00189
2025-05-29 20:24:25.872293: train_loss -1.278
2025-05-29 20:24:25.872705: val_loss -0.7771
2025-05-29 20:24:25.872955: Pseudo dice [0.9348, 0.7428, 0.4809, 0.808, 0.3359, 0.9225, 0.6113, 0.7079]
2025-05-29 20:24:25.873074: Epoch time: 76.91 s
2025-05-29 20:24:27.278150: 
2025-05-29 20:24:27.278486: Epoch 254
2025-05-29 20:24:27.278588: Current learning rate: 0.00185
2025-05-29 20:25:44.132516: train_loss -1.2835
2025-05-29 20:25:44.132791: val_loss -0.8403
2025-05-29 20:25:44.132910: Pseudo dice [0.9321, 0.7436, 0.4595, 0.81, 0.3943, 0.9159, 0.6295, 0.7658]
2025-05-29 20:25:44.133003: Epoch time: 76.86 s
2025-05-29 20:25:44.133068: Yayy! New best EMA pseudo Dice: 0.6884
2025-05-29 20:25:47.022078: 
2025-05-29 20:25:47.022413: Epoch 255
2025-05-29 20:25:47.022535: Current learning rate: 0.00181
2025-05-29 20:27:03.485811: train_loss -1.289
2025-05-29 20:27:03.486051: val_loss -0.743
2025-05-29 20:27:03.486172: Pseudo dice [0.9283, 0.7518, 0.4571, 0.7839, 0.3769, 0.9267, 0.6372, 0.7306]
2025-05-29 20:27:03.486251: Epoch time: 76.46 s
2025-05-29 20:27:03.486302: Yayy! New best EMA pseudo Dice: 0.6894
2025-05-29 20:27:06.184883: 
2025-05-29 20:27:06.185421: Epoch 256
2025-05-29 20:27:06.185590: Current learning rate: 0.00178
2025-05-29 20:28:22.410394: train_loss -1.2855
2025-05-29 20:28:22.410785: val_loss -0.7277
2025-05-29 20:28:22.410972: Pseudo dice [0.9348, 0.7549, 0.4446, 0.7852, 0.3299, 0.924, 0.5908, 0.7275]
2025-05-29 20:28:22.411054: Epoch time: 76.23 s
2025-05-29 20:28:23.776849:
2025-05-29 20:11:28.931565: Epoch time: 83.15 s
2025-05-29 20:11:30.337026: 
2025-05-29 20:11:30.337301: Epoch 215
2025-05-29 20:11:30.337425: Current learning rate: 0.00321
2025-05-29 20:12:58.309688: train_loss -1.2201
2025-05-29 20:12:58.309968: val_loss -0.6646
2025-05-29 20:12:58.310091: Pseudo dice [0.9258, 0.6584, 0.4315, 0.6567, 0.1709, 0.9082, 0.5074, 0.8192]
2025-05-29 20:12:58.310183: Epoch time: 87.97 s
2025-05-29 20:12:58.310364: Yayy! New best EMA pseudo Dice: 0.6281
2025-05-29 20:13:01.202743: 
2025-05-29 20:13:01.202978: Epoch 216
2025-05-29 20:13:01.203073: Current learning rate: 0.00318
2025-05-29 20:14:30.358329: train_loss -1.2188
2025-05-29 20:14:30.358572: val_loss -0.6674
2025-05-29 20:14:30.358685: Pseudo dice [0.9167, 0.6572, 0.4789, 0.645, 0.0782, 0.8647, 0.5243, 0.8312]
2025-05-29 20:14:30.358771: Epoch time: 89.16 s
2025-05-29 20:14:31.720392: 
2025-05-29 20:14:31.720607: Epoch 217
2025-05-29 20:14:31.720758: Current learning rate: 0.00315
2025-05-29 20:16:00.642018: train_loss -1.2154
2025-05-29 20:16:00.642243: val_loss -0.6389
2025-05-29 20:16:00.642363: Pseudo dice [0.8957, 0.6762, 0.3995, 0.6781, 0.065, 0.8769, 0.5457, 0.8309]
2025-05-29 20:16:00.642467: Epoch time: 88.92 s
2025-05-29 20:16:02.044553: 
2025-05-29 20:16:02.044797: Epoch 218
2025-05-29 20:16:02.044892: Current learning rate: 0.00311
2025-05-29 20:17:31.800079: train_loss -1.1898
2025-05-29 20:17:31.800322: val_loss -0.6937
2025-05-29 20:17:31.800434: Pseudo dice [0.9206, 0.6406, 0.4404, 0.6615, 0.0947, 0.91, 0.4827, 0.8236]
2025-05-29 20:17:31.800529: Epoch time: 89.76 s
2025-05-29 20:17:33.182156: 
2025-05-29 20:17:33.182494: Epoch 219
2025-05-29 20:17:33.182595: Current learning rate: 0.00308
2025-05-29 20:19:03.084544: train_loss -1.227
2025-05-29 20:19:03.084785: val_loss -0.6471
2025-05-29 20:19:03.084908: Pseudo dice [0.9169, 0.6312, 0.4382, 0.6691, 0.0632, 0.8978, 0.4947, 0.8015]
2025-05-29 20:19:03.084994: Epoch time: 89.9 s
2025-05-29 20:19:05.116796: 
2025-05-29 20:19:05.117199: Epoch 220
2025-05-29 20:19:05.117324: Current learning rate: 0.00304
2025-05-29 20:20:34.293756: train_loss -1.233
2025-05-29 20:20:34.293933: val_loss -0.7272
2025-05-29 20:20:34.294038: Pseudo dice [0.9049, 0.6548, 0.4447, 0.744, 0.1083, 0.9067, 0.5448, 0.7988]
2025-05-29 20:20:34.294147: Epoch time: 89.18 s
2025-05-29 20:20:35.653772: 
2025-05-29 20:20:35.654019: Epoch 221
2025-05-29 20:20:35.654111: Current learning rate: 0.00301
2025-05-29 20:22:06.022774: train_loss -1.2327
2025-05-29 20:22:06.023088: val_loss -0.6992
2025-05-29 20:22:06.023211: Pseudo dice [0.9221, 0.6592, 0.4492, 0.6873, 0.0827, 0.9032, 0.4885, 0.8143]
2025-05-29 20:22:06.023302: Epoch time: 90.37 s
2025-05-29 20:22:07.450826: 
2025-05-29 20:22:07.451128: Epoch 222
2025-05-29 20:22:07.451273: Current learning rate: 0.00297
2025-05-29 20:23:36.962322: train_loss -1.2391
2025-05-29 20:23:36.962571: val_loss -0.6669
2025-05-29 20:23:36.962688: Pseudo dice [0.919, 0.65, 0.4425, 0.6814, 0.0829, 0.8755, 0.5149, 0.8197]
2025-05-29 20:23:36.962773: Epoch time: 89.51 s
2025-05-29 20:23:38.321189: 
2025-05-29 20:23:38.321491: Epoch 223
2025-05-29 20:23:38.321616: Current learning rate: 0.00294
2025-05-29 20:25:02.765972: train_loss -1.2415
2025-05-29 20:25:02.766372: val_loss -0.6844
2025-05-29 20:25:02.766506: Pseudo dice [0.9291, 0.6359, 0.4666, 0.6559, 0.0524, 0.9004, 0.5546, 0.799]
2025-05-29 20:25:02.766592: Epoch time: 84.45 s
2025-05-29 20:25:04.217740: 
2025-05-29 20:25:04.218168: Epoch 224
2025-05-29 20:25:04.218375: Current learning rate: 0.00291
2025-05-29 20:26:26.868289: train_loss -1.227
2025-05-29 20:26:26.868580: val_loss -0.741
2025-05-29 20:26:26.868708: Pseudo dice [0.9192, 0.6401, 0.4237, 0.7486, 0.0722, 0.8749, 0.5148, 0.8252]
2025-05-29 20:26:26.868782: Epoch time: 82.65 s
2025-05-29 20:26:28.260413: 
2025-05-29 20:26:28.260596: Epoch 225
2025-05-29 20:26:28.260690: Current learning rate: 0.00287
2025-05-29 20:27:53.674193: train_loss -1.2327
2025-05-29 20:27:53.674418: val_loss -0.6904
2025-05-29 20:27:53.674546: Pseudo dice [0.9113, 0.678, 0.4576, 0.6942, 0.1038, 0.8764, 0.5023, 0.8107]
2025-05-29 20:27:53.674624: Epoch time: 85.42 s
2025-05-29 20:27:55.028514: 
2025-05-29 20:27:55.028872: Epoch 226
2025-05-29 20:27:55.029006: Current learning rate: 0.00284
2025-05-29 20:29:25.347738: train_loss -1.246
2025-05-29 20:29:25.348137: val_loss -0.6864
2025-05-29 20:29:25.348269: Pseudo dice [0.9285, 0.6799, 0.4344, 0.6955, 0.0423, 0.9169, 0.5445, 0.8154]
2025-05-29 20:29:25.348346: Epoch time: 90.32 s
2025-05-29 20:29:26.711178: 
2025-05-29 20:29:26.711391: Epoch 227
2025-05-29 20:29:26.711503: Current learning rate: 0.0028
2025-05-29 20:30:55.958500: train_loss -1.2394
2025-05-29 20:30:55.959299: val_loss -0.6289
2025-05-29 20:30:55.959553: Pseudo dice [0.9214, 0.6274, 0.4068, 0.6413, 0.1153, 0.8858, 0.4964, 0.8399]
2025-05-29 20:30:55.959772: Epoch time: 89.25 s
2025-05-29 20:30:57.425538: 
2025-05-29 20:30:57.426412: Epoch 228
2025-05-29 20:30:57.426817: Current learning rate: 0.00277
2025-05-29 20:32:25.358603: train_loss -1.2367
2025-05-29 20:32:25.359100: val_loss -0.6586
2025-05-29 20:32:25.359241: Pseudo dice [0.9192, 0.6578, 0.4715, 0.6565, 0.1815, 0.8989, 0.5032, 0.8091]
2025-05-29 20:32:25.359411: Epoch time: 87.93 s
2025-05-29 20:32:26.743799: 
2025-05-29 20:32:26.744090: Epoch 229
2025-05-29 20:32:26.744205: Current learning rate: 0.00273
2025-05-29 20:33:57.304141: train_loss -1.2039
2025-05-29 20:33:57.304477: val_loss -0.6431
2025-05-29 20:33:57.304688: Pseudo dice [0.9016, 0.6183, 0.4148, 0.668, 0.1008, 0.9047, 0.5339, 0.7854]
2025-05-29 20:33:57.304773: Epoch time: 90.56 s
2025-05-29 20:33:58.669586: 
2025-05-29 20:33:58.670262: Epoch 230
2025-05-29 20:33:58.670507: Current learning rate: 0.0027
2025-05-29 20:35:27.794333: train_loss -1.2376
2025-05-29 20:35:27.794608: val_loss -0.6676
2025-05-29 20:35:27.794785: Pseudo dice [0.9112, 0.6081, 0.4237, 0.6863, 0.1004, 0.8995, 0.5245, 0.8292]
2025-05-29 20:35:27.794912: Epoch time: 89.13 s
2025-05-29 20:35:29.942127: 
2025-05-29 20:35:29.942885: Epoch 231
2025-05-29 20:35:29.943163: Current learning rate: 0.00266
2025-05-29 20:36:56.319623: train_loss -1.2411
2025-05-29 20:36:56.319859: val_loss -0.6219
2025-05-29 20:36:56.319982: Pseudo dice [0.921, 0.6065, 0.4408, 0.6202, 0.1164, 0.8972, 0.5312, 0.7862]
2025-05-29 20:36:56.320058: Epoch time: 86.38 s
2025-05-29 20:36:57.685103: 
2025-05-29 20:36:57.685413: Epoch 232
2025-05-29 20:36:57.685570: Current learning rate: 0.00263
2025-05-29 20:38:24.582765: train_loss -1.2537
2025-05-29 20:38:24.583068: val_loss -0.6129
2025-05-29 20:38:24.583183: Pseudo dice [0.916, 0.6179, 0.4246, 0.6691, 0.0295, 0.8721, 0.5145, 0.825]
2025-05-29 20:38:24.583276: Epoch time: 86.9 s
2025-05-29 20:38:25.957788: 
2025-05-29 20:38:25.958102: Epoch 233
2025-05-29 20:38:25.958333: Current learning rate: 0.00259
2025-05-29 20:39:50.612272: train_loss -1.2599
2025-05-29 20:39:50.612510: val_loss -0.7201
2025-05-29 20:39:50.612628: Pseudo dice [0.9221, 0.6544, 0.4701, 0.7211, 0.0551, 0.8869, 0.5508, 0.8241]
2025-05-29 20:39:50.612709: Epoch time: 84.66 s
2025-05-29 20:39:51.990603: 
2025-05-29 20:39:51.990998: Epoch 234
2025-05-29 20:39:51.991092: Current learning rate: 0.00256
2025-05-29 20:41:17.896286: train_loss -1.2548
2025-05-29 20:41:17.896569: val_loss -0.6807
2025-05-29 20:41:17.896688: Pseudo dice [0.9289, 0.6424, 0.4267, 0.6846, 0.0559, 0.8683, 0.5445, 0.8509]
2025-05-29 20:41:17.896770: Epoch time: 85.91 s
2025-05-29 20:41:19.266410: 
2025-05-29 20:41:19.266650: Epoch 235
2025-05-29 20:41:19.266749: Current learning rate: 0.00252
2025-05-29 20:42:43.855870: train_loss -1.2549
2025-05-29 20:42:43.856147: val_loss -0.6327
2025-05-29 20:42:43.856298: Pseudo dice [0.9165, 0.6219, 0.4601, 0.6559, 0.0844, 0.8903, 0.5468, 0.8171]
2025-05-29 20:42:43.856387: Epoch time: 84.59 s
2025-05-29 20:42:45.251323: 
2025-05-29 20:42:45.251688: Epoch 236
2025-05-29 20:42:45.251850: Current learning rate: 0.00249
2025-05-29 20:44:16.126838: train_loss -1.2595
2025-05-29 20:44:16.127115: val_loss -0.6142
2025-05-29 20:44:16.127280: Pseudo dice [0.9224, 0.6279, 0.4456, 0.6532, 0.0439, 0.9063, 0.52, 0.7556] [0.9378, 0.7665, 0.4593, 0.7218, 0.0841, 0.9453, 0.5961, 0.745]
2025-05-29 20:19:48.677776: Epoch time: 71.01 s
2025-05-29 20:19:50.063662: 
2025-05-29 20:19:50.064036: Epoch 260
2025-05-29 20:19:50.064206: Current learning rate: 0.00163
2025-05-29 20:21:04.142990: train_loss -1.2908
2025-05-29 20:21:04.143385: val_loss -0.7017
2025-05-29 20:21:04.143530: Pseudo dice [0.9358, 0.7981, 0.4664, 0.6749, 0.1568, 0.9167, 0.6154, 0.7097]
2025-05-29 20:21:04.143614: Epoch time: 74.08 s
2025-05-29 20:21:05.563353: 
2025-05-29 20:21:05.563808: Epoch 261
2025-05-29 20:21:05.563916: Current learning rate: 0.00159
2025-05-29 20:22:20.039047: train_loss -1.284
2025-05-29 20:22:20.039256: val_loss -0.632
2025-05-29 20:22:20.039369: Pseudo dice [0.9341, 0.7628, 0.4747, 0.6119, 0.0975, 0.9212, 0.598, 0.6841]
2025-05-29 20:22:20.039461: Epoch time: 74.48 s
2025-05-29 20:22:21.461399: 
2025-05-29 20:22:21.461695: Epoch 262
2025-05-29 20:22:21.461935: Current learning rate: 0.00156
2025-05-29 20:23:35.999817: train_loss -1.2939
2025-05-29 20:23:36.000036: val_loss -0.6177
2025-05-29 20:23:36.000157: Pseudo dice [0.9351, 0.7749, 0.4991, 0.6283, 0.0595, 0.9307, 0.58, 0.7442]
2025-05-29 20:23:36.000238: Epoch time: 74.54 s
2025-05-29 20:23:37.425088: 
2025-05-29 20:23:37.425495: Epoch 263
2025-05-29 20:23:37.425624: Current learning rate: 0.00152
2025-05-29 20:24:52.802866: train_loss -1.3007
2025-05-29 20:24:52.803086: val_loss -0.7414
2025-05-29 20:24:52.803198: Pseudo dice [0.9334, 0.7753, 0.4668, 0.7364, 0.0237, 0.9264, 0.5628, 0.7941]
2025-05-29 20:24:52.803313: Epoch time: 75.38 s
2025-05-29 20:24:54.166062: 
2025-05-29 20:24:54.166197: Epoch 264
2025-05-29 20:24:54.166296: Current learning rate: 0.00148
2025-05-29 20:26:06.222404: train_loss -1.3015
2025-05-29 20:26:06.222677: val_loss -0.7174
2025-05-29 20:26:06.222798: Pseudo dice [0.9341, 0.7899, 0.495, 0.7354, 0.1923, 0.9557, 0.5834, 0.7423]
2025-05-29 20:26:06.222933: Epoch time: 72.06 s
2025-05-29 20:26:07.585798: 
2025-05-29 20:26:07.586096: Epoch 265
2025-05-29 20:26:07.586205: Current learning rate: 0.00145
2025-05-29 20:27:20.393801: train_loss -1.2973
2025-05-29 20:27:20.394012: val_loss -0.7048
2025-05-29 20:27:20.394190: Pseudo dice [0.9296, 0.7956, 0.494, 0.7252, 0.0814, 0.9434, 0.6056, 0.7171]
2025-05-29 20:27:20.394305: Epoch time: 72.81 s
2025-05-29 20:27:21.802395: 
2025-05-29 20:27:21.802693: Epoch 266
2025-05-29 20:27:21.802856: Current learning rate: 0.00141
2025-05-29 20:28:36.396683: train_loss -1.3013
2025-05-29 20:28:36.396902: val_loss -0.7493
2025-05-29 20:28:36.397020: Pseudo dice [0.9371, 0.746, 0.4771, 0.7254, 0.1183, 0.9539, 0.5639, 0.7646]
2025-05-29 20:28:36.397105: Epoch time: 74.6 s
2025-05-29 20:28:37.740432: 
2025-05-29 20:28:37.740812: Epoch 267
2025-05-29 20:28:37.740975: Current learning rate: 0.00137
2025-05-29 20:29:52.336775: train_loss -1.3
2025-05-29 20:29:52.337021: val_loss -0.719
2025-05-29 20:29:52.337171: Pseudo dice [0.9278, 0.7719, 0.4944, 0.695, 0.2701, 0.9252, 0.5755, 0.708]
2025-05-29 20:29:52.337257: Epoch time: 74.6 s
2025-05-29 20:29:53.670187: 
2025-05-29 20:29:53.670371: Epoch 268
2025-05-29 20:29:53.670487: Current learning rate: 0.00133
2025-05-29 20:31:09.647194: train_loss -1.3046
2025-05-29 20:31:09.647691: val_loss -0.6929
2025-05-29 20:31:09.647812: Pseudo dice [0.9323, 0.7646, 0.5014, 0.7152, 0.2069, 0.9537, 0.5773, 0.7222]
2025-05-29 20:31:09.648037: Epoch time: 75.98 s
2025-05-29 20:31:12.014411: 
2025-05-29 20:31:12.014919: Epoch 269
2025-05-29 20:31:12.015033: Current learning rate: 0.0013
2025-05-29 20:32:26.778539: train_loss -1.3125
2025-05-29 20:32:26.778861: val_loss -0.7572
2025-05-29 20:32:26.779006: Pseudo dice [0.9358, 0.7905, 0.4942, 0.7434, 0.149, 0.952, 0.595, 0.7395]
2025-05-29 20:32:26.779094: Epoch time: 74.77 s
2025-05-29 20:32:28.152409: 
2025-05-29 20:32:28.152825: Epoch 270
2025-05-29 20:32:28.152924: Current learning rate: 0.00126
2025-05-29 20:33:43.302245: train_loss -1.3072
2025-05-29 20:33:43.302940: val_loss -0.735
2025-05-29 20:33:43.303133: Pseudo dice [0.9302, 0.8002, 0.4825, 0.7186, 0.1182, 0.9506, 0.5733, 0.7567]
2025-05-29 20:33:43.303506: Epoch time: 75.15 s
2025-05-29 20:33:44.797948: 
2025-05-29 20:33:44.798386: Epoch 271
2025-05-29 20:33:44.798573: Current learning rate: 0.00122
2025-05-29 20:34:58.912868: train_loss -1.2956
2025-05-29 20:34:58.913465: val_loss -0.7463
2025-05-29 20:34:58.913633: Pseudo dice [0.9334, 0.7626, 0.4799, 0.7598, 0.2458, 0.9485, 0.584, 0.7208]
2025-05-29 20:34:58.913762: Epoch time: 74.12 s
2025-05-29 20:34:58.913846: Yayy! New best EMA pseudo Dice: 0.6656
2025-05-29 20:35:01.508240: 
2025-05-29 20:35:01.508637: Epoch 272
2025-05-29 20:35:01.508810: Current learning rate: 0.00118
2025-05-29 20:36:15.303670: train_loss -1.3066
2025-05-29 20:36:15.304442: val_loss -0.6866
2025-05-29 20:36:15.304606: Pseudo dice [0.9269, 0.7748, 0.4381, 0.6933, 0.2827, 0.9445, 0.5507, 0.7155]
2025-05-29 20:36:15.304717: Epoch time: 73.8 s
2025-05-29 20:36:15.304801: Yayy! New best EMA pseudo Dice: 0.6657
2025-05-29 20:36:18.571592: 
2025-05-29 20:36:18.571913: Epoch 273
2025-05-29 20:36:18.572060: Current learning rate: 0.00115
2025-05-29 20:37:31.356061: train_loss -1.3109
2025-05-29 20:37:31.356625: val_loss -0.6814
2025-05-29 20:37:31.356799: Pseudo dice [0.9284, 0.7741, 0.4842, 0.6853, 0.1659, 0.9409, 0.5811, 0.7265]
2025-05-29 20:37:31.357088: Epoch time: 72.79 s
2025-05-29 20:37:32.826688: 
2025-05-29 20:37:32.827038: Epoch 274
2025-05-29 20:37:32.827148: Current learning rate: 0.00111
2025-05-29 20:38:44.921999: train_loss -1.3022
2025-05-29 20:38:44.922650: val_loss -0.6841
2025-05-29 20:38:44.922812: Pseudo dice [0.9325, 0.7563, 0.444, 0.7416, 0.0811, 0.9528, 0.5573, 0.7148]
2025-05-29 20:38:44.922926: Epoch time: 72.1 s
2025-05-29 20:38:46.520293: 
2025-05-29 20:38:46.520678: Epoch 275
2025-05-29 20:38:46.520841: Current learning rate: 0.00107
2025-05-29 20:40:00.579157: train_loss -1.3097
2025-05-29 20:40:00.579385: val_loss -0.7198
2025-05-29 20:40:00.579514: Pseudo dice [0.9354, 0.7573, 0.5241, 0.7554, 0.1922, 0.9562, 0.54, 0.6901]
2025-05-29 20:40:00.579605: Epoch time: 74.06 s
2025-05-29 20:40:01.949314: 
2025-05-29 20:40:01.949626: Epoch 276
2025-05-29 20:40:01.949820: Current learning rate: 0.00103
2025-05-29 20:41:17.102874: train_loss -1.3098
2025-05-29 20:41:17.103113: val_loss -0.7507
2025-05-29 20:41:17.103271: Pseudo dice [0.9436, 0.7932, 0.5297, 0.7244, 0.1072, 0.9521, 0.5985, 0.7304]
2025-05-29 20:41:17.103374: Epoch time: 75.16 s
2025-05-29 20:41:18.478094: 
2025-05-29 20:41:18.478465: Epoch 277
2025-05-29 20:41:18.478569: Current learning rate: 0.00099
2025-05-29 20:42:33.953159: train_loss -1.3125
2025-05-29 20:42:33.953470: val_loss -0.6888
2025-05-29 20:42:33.953685: Pseudo dice [0.9348, 0.7889, 0.5311, 0.6722, 0.1134, 0.9455, 0.5707, 0.707]
2025-05-29 20:42:33.953764: Epoch time: 75.48 s
2025-05-29 20:42:35.305983: 
2025-05-29 20:42:35.306292: Epoch 278
2025-05-29 20:42:35.306421: Current learning rate: 0.00095
2025-05-29 20:43:51.411822: train_loss -1.3108
2025-05-29 20:43:51.412136: val_loss -0.7285
2025-05-29 20:43:51.412257: Pseudo dice [0.9323, 0.7991, 0.4845, 0.736, 0.0379, 0.9476, 0.5806, 0.6989]
2025-05-29 20:43:51.412340: Epoch time: 76.11 s
2025-05-29 20:43:52.770022: 
2025-05-29 20:43:52.770297: Epoch 279
2025-05-29 20:43:52.770455: Current learning rate: 0.00091
2025-05-29 20:45:07.424072: train_loss -1.3161
2025-05-29 20:45:07.424272: val_loss -0.7023
2025-05-29 20:45:07.424392: Pseudo dice [0.9384, 0.7873, 0.4499, 0.7119, 0.0998, 0.9431, 0.5888, 0.7607]
2025-05-29 20:45:07.424486: Epoch time: 74.66 s
2025-05-29 20:45:09.647680: 
2025-05-29 20:45:09.648056: Epoch 280
2025-05-29 20:45:09.648211: Current learning rate: 0.00087
2025-05-29 20:46:22.447615: train_loss -1.3139
2025-05-29 20:46:22.447873: val_loss -0.6951
2025-05-29 20:46:22.448094: Pseudo dice [0.9354, 0.7881, 0.5002, 0.7314, 0.2094, 0.958, 0.5531, 0.6837]
2025-05-29 20:46:22.448189: Epoch time: 72.8 s
2025-05-29 20:46:23.800199: 
2025-05-29 20:46:23.800487: Epoch 281
2025-05-29 20:46:23.800607: Current learning rate: 0.00083
2025-05-29 20:47:38.265893: train_loss -1.3211
2025-05-29 20:47:38.266146: 
2025-05-29 20:28:23.777589: Epoch 257
2025-05-29 20:28:23.777711: Current learning rate: 0.00174
2025-05-29 20:29:39.944240: train_loss -1.2812
2025-05-29 20:29:39.944625: val_loss -0.7739
2025-05-29 20:29:39.944809: Pseudo dice [0.9395, 0.7476, 0.4927, 0.7977, 0.1776, 0.932, 0.6133, 0.7638]
2025-05-29 20:29:39.944899: Epoch time: 76.17 s
2025-05-29 20:29:41.312274: 
2025-05-29 20:29:41.312583: Epoch 258
2025-05-29 20:29:41.312682: Current learning rate: 0.0017
2025-05-29 20:30:59.433730: train_loss -1.2695
2025-05-29 20:30:59.434054: val_loss -0.7496
2025-05-29 20:30:59.434173: Pseudo dice [0.9316, 0.7206, 0.467, 0.8204, 0.2846, 0.8907, 0.6241, 0.726]
2025-05-29 20:30:59.434290: Epoch time: 78.12 s
2025-05-29 20:31:00.791722: 
2025-05-29 20:31:00.792109: Epoch 259
2025-05-29 20:31:00.792269: Current learning rate: 0.00167
2025-05-29 20:32:14.924640: train_loss -1.293
2025-05-29 20:32:14.925003: val_loss -0.7318
2025-05-29 20:32:14.925310: Pseudo dice [0.9354, 0.7254, 0.4554, 0.726, 0.2708, 0.9089, 0.5881, 0.7464]
2025-05-29 20:32:14.925400: Epoch time: 74.13 s
2025-05-29 20:32:16.391491: 
2025-05-29 20:32:16.391981: Epoch 260
2025-05-29 20:32:16.392125: Current learning rate: 0.00163
2025-05-29 20:33:32.242266: train_loss -1.2656
2025-05-29 20:33:32.242611: val_loss -0.7392
2025-05-29 20:33:32.242731: Pseudo dice [0.9371, 0.7486, 0.4527, 0.7891, 0.264, 0.92, 0.6348, 0.7261]
2025-05-29 20:33:32.242826: Epoch time: 75.85 s
2025-05-29 20:33:33.587980: 
2025-05-29 20:33:33.588176: Epoch 261
2025-05-29 20:33:33.588314: Current learning rate: 0.00159
2025-05-29 20:34:49.639891: train_loss -1.2785
2025-05-29 20:34:49.640198: val_loss -0.7177
2025-05-29 20:34:49.640321: Pseudo dice [0.9272, 0.7494, 0.4734, 0.7919, 0.2558, 0.9165, 0.6306, 0.7005]
2025-05-29 20:34:49.640401: Epoch time: 76.05 s
2025-05-29 20:34:51.673508: 
2025-05-29 20:34:51.673892: Epoch 262
2025-05-29 20:34:51.674112: Current learning rate: 0.00156
2025-05-29 20:36:05.028806: train_loss -1.2842
2025-05-29 20:36:05.029228: val_loss -0.8166
2025-05-29 20:36:05.029473: Pseudo dice [0.9339, 0.7399, 0.4657, 0.8425, 0.3196, 0.9146, 0.629, 0.7032]
2025-05-29 20:36:05.029626: Epoch time: 73.36 s
2025-05-29 20:36:06.456806: 
2025-05-29 20:36:06.457306: Epoch 263
2025-05-29 20:36:06.457620: Current learning rate: 0.00152
2025-05-29 20:37:17.812018: train_loss -1.2779
2025-05-29 20:37:17.812339: val_loss -0.753
2025-05-29 20:37:17.812517: Pseudo dice [0.9223, 0.771, 0.4688, 0.8077, 0.2444, 0.9247, 0.5926, 0.708]
2025-05-29 20:37:17.812619: Epoch time: 71.36 s
2025-05-29 20:37:19.228029: 
2025-05-29 20:37:19.228328: Epoch 264
2025-05-29 20:37:19.228483: Current learning rate: 0.00148
2025-05-29 20:38:32.658564: train_loss -1.2734
2025-05-29 20:38:32.659025: val_loss -0.793
2025-05-29 20:38:32.659161: Pseudo dice [0.9312, 0.7593, 0.4886, 0.8056, 0.2727, 0.9032, 0.5901, 0.7069]
2025-05-29 20:38:32.659247: Epoch time: 73.43 s
2025-05-29 20:38:34.037314: 
2025-05-29 20:38:34.037689: Epoch 265
2025-05-29 20:38:34.037836: Current learning rate: 0.00145
2025-05-29 20:39:47.984267: train_loss -1.2739
2025-05-29 20:39:47.984607: val_loss -0.8281
2025-05-29 20:39:47.984730: Pseudo dice [0.9405, 0.7635, 0.4588, 0.7919, 0.2485, 0.9241, 0.6292, 0.7818]
2025-05-29 20:39:47.984815: Epoch time: 73.95 s
2025-05-29 20:39:49.361605: 
2025-05-29 20:39:49.362049: Epoch 266
2025-05-29 20:39:49.362215: Current learning rate: 0.00141
2025-05-29 20:41:06.013072: train_loss -1.2683
2025-05-29 20:41:06.013307: val_loss -0.7903
2025-05-29 20:41:06.013427: Pseudo dice [0.9356, 0.7379, 0.4699, 0.8097, 0.3317, 0.9222, 0.5985, 0.6882]
2025-05-29 20:41:06.013597: Epoch time: 76.65 s
2025-05-29 20:41:07.384867: 
2025-05-29 20:41:07.385334: Epoch 267
2025-05-29 20:41:07.385482: Current learning rate: 0.00137
2025-05-29 20:42:23.840368: train_loss -1.2886
2025-05-29 20:42:23.840616: val_loss -0.8213
2025-05-29 20:42:23.840738: Pseudo dice [0.9321, 0.7651, 0.46, 0.8361, 0.338, 0.9157, 0.5998, 0.7617]
2025-05-29 20:42:23.840829: Epoch time: 76.46 s
2025-05-29 20:42:25.202336: 
2025-05-29 20:42:25.202554: Epoch 268
2025-05-29 20:42:25.202655: Current learning rate: 0.00133
2025-05-29 20:43:42.493119: train_loss -1.2863
2025-05-29 20:43:42.493465: val_loss -0.7876
2025-05-29 20:43:42.493700: Pseudo dice [0.9356, 0.7413, 0.4468, 0.8422, 0.3025, 0.9226, 0.6432, 0.7432]
2025-05-29 20:43:42.493794: Epoch time: 77.29 s
2025-05-29 20:43:43.885207: 
2025-05-29 20:43:43.885530: Epoch 269
2025-05-29 20:43:43.885692: Current learning rate: 0.0013
2025-05-29 20:45:00.464888: train_loss -1.2723
2025-05-29 20:45:00.465078: val_loss -0.7563
2025-05-29 20:45:00.465193: Pseudo dice [0.9427, 0.7419, 0.5055, 0.7962, 0.2842, 0.9192, 0.5921, 0.747]
2025-05-29 20:45:00.465288: Epoch time: 76.58 s
2025-05-29 20:45:01.819298: 
2025-05-29 20:45:01.819570: Epoch 270
2025-05-29 20:45:01.819718: Current learning rate: 0.00126
2025-05-29 20:46:17.035709: train_loss -1.3
2025-05-29 20:46:17.036330: val_loss -0.8071
2025-05-29 20:46:17.036463: Pseudo dice [0.9295, 0.7539, 0.4733, 0.8363, 0.2618, 0.9343, 0.6596, 0.7336]
2025-05-29 20:46:17.036559: Epoch time: 75.22 s
2025-05-29 20:46:17.036610: Yayy! New best EMA pseudo Dice: 0.6897
2025-05-29 20:46:19.829431: 
2025-05-29 20:46:19.829783: Epoch 271
2025-05-29 20:46:19.829893: Current learning rate: 0.00122
2025-05-29 20:47:36.091411: train_loss -1.2914
2025-05-29 20:47:36.091677: val_loss -0.8023
2025-05-29 20:47:36.091873: Pseudo dice [0.9241, 0.7713, 0.4628, 0.8579, 0.1618, 0.9182, 0.6304, 0.6856]
2025-05-29 20:47:36.091987: Epoch time: 76.26 s
2025-05-29 20:47:37.461220: 
2025-05-29 20:47:37.461444: Epoch 272
2025-05-29 20:47:37.461601: Current learning rate: 0.00118
2025-05-29 20:48:53.631441: train_loss -1.2868
2025-05-29 20:48:53.631785: val_loss -0.7568
2025-05-29 20:48:53.631909: Pseudo dice [0.9422, 0.7524, 0.4622, 0.7937, 0.2489, 0.9227, 0.5956, 0.786]
2025-05-29 20:48:53.632010: Epoch time: 76.17 s
2025-05-29 20:48:55.653481: 
2025-05-29 20:48:55.653744: Epoch 273
2025-05-29 20:48:55.653891: Current learning rate: 0.00115
2025-05-29 20:50:13.268953: train_loss -1.2817
2025-05-29 20:50:13.269191: val_loss -0.7169
2025-05-29 20:50:13.269307: Pseudo dice [0.9251, 0.7439, 0.4754, 0.7774, 0.2911, 0.9235, 0.6164, 0.7458]
2025-05-29 20:50:13.269416: Epoch time: 77.62 s
2025-05-29 20:50:14.606407: 
2025-05-29 20:50:14.606777: Epoch 274
2025-05-29 20:50:14.606873: Current learning rate: 0.00111
2025-05-29 20:51:31.783458: train_loss -1.3013
2025-05-29 20:51:31.783704: val_loss -0.7873
2025-05-29 20:51:31.783828: Pseudo dice [0.9337, 0.7504, 0.4231, 0.8117, 0.1835, 0.9292, 0.6498, 0.7064]
2025-05-29 20:51:31.783919: Epoch time: 77.18 s
2025-05-29 20:51:33.182903: 
2025-05-29 20:51:33.183295: Epoch 275
2025-05-29 20:51:33.183461: Current learning rate: 0.00107
2025-05-29 20:52:49.661625: train_loss -1.2916
2025-05-29 20:52:49.661993: val_loss -0.7945
2025-05-29 20:52:49.662130: Pseudo dice [0.9321, 0.7741, 0.4425, 0.7911, 0.2676, 0.9246, 0.6499, 0.7459]
2025-05-29 20:52:49.662229: Epoch time: 76.48 s
2025-05-29 20:52:51.031204: 
2025-05-29 20:52:51.031429: Epoch 276
2025-05-29 20:52:51.031535: Current learning rate: 0.00103
2025-05-29 20:54:08.016396: train_loss -1.2832
2025-05-29 20:54:08.016679: val_loss -0.8235
2025-05-29 20:54:08.016833: Pseudo dice [0.9303, 0.758, 0.4667, 0.8276, 0.3216, 0.9162, 0.6047, 0.7377]
2025-05-29 20:54:08.016920: Epoch time: 76.99 s
2025-05-29 20:54:09.380060: 
2025-05-29 20:54:09.380440: Epoch 277
2025-05-29 20:54:09.380551: Current learning rate: 0.00099
2025-05-29 20:55:25.631271: train_loss -1.2917
2025-05-29 20:55:25.631524: val_loss -0.7981
2025-05-29 20:55:25.631650: Pseudo dice [0.9329, 0.7667, 0.4957, 0.8195, 0.268, 0.9094, 0.6425, 0.7306]
2025-05-29 20:55:25.631741: Epoch time: 76.25 s
2025-05-29 20:55:26.986599: 
2025-05-29 20:55:26.986844: Epoch 278
2025-05-29 20:55:26.986964: Current learning rate: 0.00095
2025-05-29 20:56:43.088233: train_loss -1.2917
2025-05-29 20:56:43.088550: val_loss -0.7829
2025-05-29 20:56:43.088779: Pseudo dice [0.9388, 0.7526, 0.4585, 0.8243, 0.2011, 0.9078, 0.6103, 0.7237]
2025-05-29 20:56:43.088920: Epoch time: 76.1 s
2025-05-29 20:56:44.468695: val_loss -0.7149
2025-05-29 20:47:38.267678: Pseudo dice [0.9233, 0.7844, 0.5121, 0.7416, 0.1745, 0.9369, 0.5658, 0.7157]
2025-05-29 20:47:38.267817: Epoch time: 74.47 s
2025-05-29 20:47:39.629753: 
2025-05-29 20:47:39.630109: Epoch 282
2025-05-29 20:47:39.630239: Current learning rate: 0.00079
2025-05-29 20:48:54.698490: train_loss -1.3134
2025-05-29 20:48:54.698883: val_loss -0.6819
2025-05-29 20:48:54.699052: Pseudo dice [0.9354, 0.7879, 0.4874, 0.7279, 0.2198, 0.944, 0.5888, 0.7545]
2025-05-29 20:48:54.699172: Epoch time: 75.07 s
2025-05-29 20:48:56.059494: 
2025-05-29 20:48:56.059875: Epoch 283
2025-05-29 20:48:56.060013: Current learning rate: 0.00076
2025-05-29 20:50:13.182842: train_loss -1.3117
2025-05-29 20:50:13.183071: val_loss -0.7096
2025-05-29 20:50:13.183189: Pseudo dice [0.929, 0.7657, 0.4796, 0.7596, 0.2166, 0.9476, 0.5615, 0.7491]
2025-05-29 20:50:13.183279: Epoch time: 77.12 s
2025-05-29 20:50:13.183347: Yayy! New best EMA pseudo Dice: 0.6667
2025-05-29 20:50:15.739404: 
2025-05-29 20:50:15.739676: Epoch 284
2025-05-29 20:50:15.739794: Current learning rate: 0.00071
2025-05-29 20:51:32.241937: train_loss -1.3143
2025-05-29 20:51:32.242139: val_loss -0.7296
2025-05-29 20:51:32.242254: Pseudo dice [0.9372, 0.7732, 0.4908, 0.7226, 0.2376, 0.9334, 0.5763, 0.7474]
2025-05-29 20:51:32.242340: Epoch time: 76.5 s
2025-05-29 20:51:32.242393: Yayy! New best EMA pseudo Dice: 0.6677
2025-05-29 20:51:34.750890: 
2025-05-29 20:51:34.751189: Epoch 285
2025-05-29 20:51:34.751288: Current learning rate: 0.00067
2025-05-29 20:52:50.812687: train_loss -1.3025
2025-05-29 20:52:50.813140: val_loss -0.7325
2025-05-29 20:52:50.813338: Pseudo dice [0.936, 0.7744, 0.462, 0.7455, 0.1216, 0.9229, 0.5688, 0.7511]
2025-05-29 20:52:50.813428: Epoch time: 76.06 s
2025-05-29 20:52:52.272410: 
2025-05-29 20:52:52.272711: Epoch 286
2025-05-29 20:52:52.272806: Current learning rate: 0.00063
2025-05-29 20:54:08.682139: train_loss -1.322
2025-05-29 20:54:08.682519: val_loss -0.7501
2025-05-29 20:54:08.682832: Pseudo dice [0.9311, 0.7802, 0.4768, 0.7427, 0.2181, 0.9581, 0.5834, 0.7061]
2025-05-29 20:54:08.682960: Epoch time: 76.41 s
2025-05-29 20:54:08.683030: Yayy! New best EMA pseudo Dice: 0.6677
2025-05-29 20:54:11.410125: 
2025-05-29 20:54:11.410554: Epoch 287
2025-05-29 20:54:11.410656: Current learning rate: 0.00059
2025-05-29 20:55:26.975535: train_loss -1.3107
2025-05-29 20:55:26.975903: val_loss -0.6899
2025-05-29 20:55:26.976022: Pseudo dice [0.9406, 0.7644, 0.4892, 0.724, 0.1868, 0.945, 0.5726, 0.7104]
2025-05-29 20:55:26.976115: Epoch time: 75.57 s
2025-05-29 20:55:28.359925: 
2025-05-29 20:55:28.360297: Epoch 288
2025-05-29 20:55:28.360473: Current learning rate: 0.00055
2025-05-29 20:56:43.786389: train_loss -1.3119
2025-05-29 20:56:43.786634: val_loss -0.6964
2025-05-29 20:56:43.786754: Pseudo dice [0.9211, 0.7484, 0.5154, 0.7181, 0.2019, 0.9428, 0.5279, 0.6766]
2025-05-29 20:56:43.786838: Epoch time: 75.43 s
2025-05-29 20:56:45.151865: 
2025-05-29 20:56:45.152099: Epoch 289
2025-05-29 20:56:45.152195: Current learning rate: 0.00051
2025-05-29 20:58:02.715577: train_loss -1.3119
2025-05-29 20:58:02.715810: val_loss -0.718
2025-05-29 20:58:02.715932: Pseudo dice [0.9348, 0.7879, 0.4862, 0.7083, 0.1639, 0.9504, 0.5717, 0.7336]
2025-05-29 20:58:02.716015: Epoch time: 77.56 s
2025-05-29 20:58:04.065073: 
2025-05-29 20:58:04.065257: Epoch 290
2025-05-29 20:58:04.065361: Current learning rate: 0.00047
2025-05-29 20:59:21.599250: train_loss -1.3125
2025-05-29 20:59:21.599547: val_loss -0.7292
2025-05-29 20:59:21.599713: Pseudo dice [0.9342, 0.7849, 0.4559, 0.7154, 0.1686, 0.9436, 0.5919, 0.7717]
2025-05-29 20:59:21.599852: Epoch time: 77.54 s
2025-05-29 20:59:23.750700: 
2025-05-29 20:59:23.750935: Epoch 291
2025-05-29 20:59:23.751049: Current learning rate: 0.00043
2025-05-29 21:00:41.400792: train_loss -1.309
2025-05-29 21:00:41.401002: val_loss -0.6955
2025-05-29 21:00:41.401202: Pseudo dice [0.9307, 0.8002, 0.4499, 0.7171, 0.1769, 0.9535, 0.5308, 0.7659]
2025-05-29 21:00:41.401285: Epoch time: 77.65 s
2025-05-29 21:00:42.763440: 
2025-05-29 21:00:42.763788: Epoch 292
2025-05-29 21:00:42.763908: Current learning rate: 0.00038
2025-05-29 21:01:59.357511: train_loss -1.3235
2025-05-29 21:01:59.357706: val_loss -0.7331
2025-05-29 21:01:59.357820: Pseudo dice [0.9378, 0.8165, 0.4499, 0.7309, 0.1824, 0.9553, 0.5664, 0.7623]
2025-05-29 21:01:59.357911: Epoch time: 76.6 s
2025-05-29 21:02:00.748971: 
2025-05-29 21:02:00.749161: Epoch 293
2025-05-29 21:02:00.749339: Current learning rate: 0.00034
2025-05-29 21:03:16.268848: train_loss -1.3147
2025-05-29 21:03:16.269123: val_loss -0.6521
2025-05-29 21:03:16.269242: Pseudo dice [0.9314, 0.7549, 0.4795, 0.6695, 0.2449, 0.9496, 0.5638, 0.703]
2025-05-29 21:03:16.269321: Epoch time: 75.52 s
2025-05-29 21:03:17.659165: 
2025-05-29 21:03:17.659525: Epoch 294
2025-05-29 21:03:17.659645: Current learning rate: 0.0003
2025-05-29 21:04:31.261867: train_loss -1.3143
2025-05-29 21:04:31.262202: val_loss -0.6736
2025-05-29 21:04:31.262319: Pseudo dice [0.9265, 0.7861, 0.4899, 0.7187, 0.1995, 0.9327, 0.6029, 0.6719]
2025-05-29 21:04:31.262407: Epoch time: 73.6 s
2025-05-29 21:04:32.639130: 
2025-05-29 21:04:32.639467: Epoch 295
2025-05-29 21:04:32.639612: Current learning rate: 0.00025
2025-05-29 21:05:42.672128: train_loss -1.3262
2025-05-29 21:05:42.672348: val_loss -0.739
2025-05-29 21:05:42.672481: Pseudo dice [0.9394, 0.7783, 0.4911, 0.7231, 0.1327, 0.9572, 0.5876, 0.7251]
2025-05-29 21:05:42.672570: Epoch time: 70.03 s
2025-05-29 21:05:44.030626: 
2025-05-29 21:05:44.030936: Epoch 296
2025-05-29 21:05:44.031108: Current learning rate: 0.00021
2025-05-29 21:06:55.930768: train_loss -1.3229
2025-05-29 21:06:55.930977: val_loss -0.7475
2025-05-29 21:06:55.931162: Pseudo dice [0.9446, 0.8082, 0.4661, 0.738, 0.0913, 0.955, 0.5969, 0.7892]
2025-05-29 21:06:55.931257: Epoch time: 71.9 s
2025-05-29 21:06:57.296776: 
2025-05-29 21:06:57.297051: Epoch 297
2025-05-29 21:06:57.297174: Current learning rate: 0.00016
2025-05-29 21:08:09.090715: train_loss -1.3318
2025-05-29 21:08:09.090971: val_loss -0.7132
2025-05-29 21:08:09.091118: Pseudo dice [0.926, 0.7817, 0.5031, 0.7326, 0.246, 0.9498, 0.5848, 0.6853]
2025-05-29 21:08:09.091204: Epoch time: 71.8 s
2025-05-29 21:08:09.091271: Yayy! New best EMA pseudo Dice: 0.6685
2025-05-29 21:08:11.850432: 
2025-05-29 21:08:11.850586: Epoch 298
2025-05-29 21:08:11.850720: Current learning rate: 0.00011
2025-05-29 21:09:22.794026: train_loss -1.3108
2025-05-29 21:09:22.794198: val_loss -0.6513
2025-05-29 21:09:22.794310: Pseudo dice [0.9325, 0.7829, 0.4686, 0.6698, 0.263, 0.9437, 0.5586, 0.7316]
2025-05-29 21:09:22.794386: Epoch time: 70.94 s
2025-05-29 21:09:22.794437: Yayy! New best EMA pseudo Dice: 0.6686
2025-05-29 21:09:25.609976: 
2025-05-29 21:09:25.610239: Epoch 299
2025-05-29 21:09:25.610340: Current learning rate: 6e-05
2025-05-29 21:10:37.634429: train_loss -1.3187
2025-05-29 21:10:37.634678: val_loss -0.7381
2025-05-29 21:10:37.634822: Pseudo dice [0.9448, 0.7913, 0.5025, 0.7286, 0.2892, 0.9342, 0.5871, 0.7874]
2025-05-29 21:10:37.634906: Epoch time: 72.03 s
2025-05-29 21:10:37.634961: Yayy! New best EMA pseudo Dice: 0.6713
2025-05-29 21:10:41.421070: Training done.
2025-05-29 21:10:41.463393: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 21:10:41.464140: The split file contains 5 splits.
2025-05-29 21:10:41.464197: Desired fold for training: 3
2025-05-29 21:10:41.464229: This split has 507 training and 126 validation cases.
2025-05-29 21:10:41.465340: predicting ct14-10
2025-05-29 21:10:41.469907: ct14-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:07.874054: predicting ct14-16
2025-05-29 21:11:07.878802: ct14-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:07.926085: predicting ct14-21
2025-05-29 21:11:07.930032: ct14-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:07.973703: predicting ct14-23
2025-05-29 21:11:07.977569: ct14-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.030461: predicting ct14-29
2025-05-29 21:11:08.034349: ct14-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.092215: predicting ct14-32
2025-05-29 21:11:08.097371: ct14-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.144412: predicting ct14-33
2025-05-29 21:11:08.149385: ct14-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.198738: predicting ct14-43
2025-05-29 21:11:08.203412: ct14-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.250464: predicting ct14-45
2025-05-29 21:11:08.255295: ct14-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.303018: predicting ct14-48
2025-05-29 21:11:08.306953: ct14-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.352587: predicting ct14-5
2025-05-29 21:11:08.357291: ct14-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.403484: predicting ct14-54
2025-05-29 21:11:08.407903: ct14-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.451777: predicting ct14-58
2025-05-29 21:11:08.456208: ct14-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.496142: predicting ct14-9
2025-05-29 21:11:08.501018: ct14-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.548969: predicting ct15-2
2025-05-29 21:11:08.553663: ct15-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.600266: predicting ct15-24
2025-05-29 21:11:08.604834: ct15-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.653595: predicting ct15-27
2025-05-29 21:11:08.658093: ct15-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.703998: predicting ct15-36
2025-05-29 21:11:08.707937: ct15-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.750751: predicting ct15-37
2025-05-29 21:11:08.754478: ct15-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.795511: predicting ct15-38
2025-05-29 21:11:08.799141: ct15-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.860498: predicting ct15-39
2025-05-29 21:11:08.864147: ct15-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.905890: predicting ct15-4
2025-05-29 21:11:08.909501: ct15-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:08.958265: predicting ct15-41
2025-05-29 21:11:08.961939: ct15-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.002403: predicting ct15-47
2025-05-29 21:11:09.006304: ct15-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.053028: predicting ct2-13
2025-05-29 21:11:09.056651: ct2-13, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.102191: predicting ct2-18
2025-05-29 21:11:09.105809: ct2-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.148477: predicting ct2-22
2025-05-29 21:11:09.152116: ct2-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.188864: predicting ct2-26
2025-05-29 21:11:09.192584: ct2-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.235986: predicting ct2-33
2025-05-29 21:11:09.239470: ct2-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.282010: predicting ct2-34
2025-05-29 21:11:09.285552: ct2-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.334153: predicting ct2-35
2025-05-29 21:11:09.337739: ct2-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.378122: predicting ct2-36
2025-05-29 21:11:09.381689: ct2-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.425199: predicting ct2-39
2025-05-29 21:11:09.428872: ct2-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.466468: predicting ct2-40
2025-05-29 21:11:09.469987: ct2-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.506277: predicting ct2-42
2025-05-29 21:11:09.509813: ct2-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.553969: predicting ct2-44
2025-05-29 21:11:09.557638: ct2-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.605457: predicting ct2-57
2025-05-29 21:11:09.609043: ct2-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.649389: predicting ct2-61
2025-05-29 21:11:09.652842: ct2-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.687031: predicting ct2-62
2025-05-29 21:11:09.690484: ct2-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.731928: predicting ct2-64
2025-05-29 21:11:09.735243: ct2-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.780537: predicting ct2-65
2025-05-29 21:11:09.783975: ct2-65, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.829201: predicting ct2-7
2025-05-29 21:11:09.833336: ct2-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.879998: predicting ct2-71
2025-05-29 21:11:09.886009: ct2-71, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.933072: predicting ct3-1
2025-05-29 21:11:09.937560: ct3-1, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:09.984652: predicting ct3-14
2025-05-29 21:11:09.989543: ct3-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.033861: predicting ct3-2
2025-05-29 21:11:10.038018: ct3-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.081690: predicting ct3-21
2025-05-29 21:11:10.085277: ct3-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.129144: predicting ct3-23
2025-05-29 21:11:10.134088: ct3-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.176140: predicting ct3-26
2025-05-29 21:11:10.179801: ct3-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.221123: predicting ct3-3
2025-05-29 21:11:10.224634: ct3-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.278782: predicting ct3-30
2025-05-29 21:11:10.282945: ct3-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.337376: predicting ct3-38
2025-05-29 21:11:10.340861: ct3-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.376530: predicting ct3-41
2025-05-29 21:11:10.380071: ct3-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.425746: predicting ct3-44
2025-05-29 21:11:10.428996: ct3-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.473584: predicting ct3-47
2025-05-29 21:11:10.476967: ct3-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.523846: predicting ct3-50
2025-05-29 21:11:10.527144: ct3-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.571017: predicting ct3-53
2025-05-29 21:11:10.574769: ct3-53, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.618222: predicting ct3-60
2025-05-29 21:11:10.621616: ct3-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.667607: predicting ct3-65
2025-05-29 21:11:10.670975: ct3-65, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.706580: predicting ct3-66
2025-05-29 21:11:10.710796: ct3-66, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.757890: predicting ct4-12
2025-05-29 21:11:10.761516: ct4-12, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.816959: predicting ct4-20
2025-05-29 21:11:10.821711: ct4-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.881220: predicting ct4-23
2025-05-29 21:11:10.885229: ct4-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.941681: predicting ct4-26
2025-05-29 21:11:10.945345: ct4-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:10.995144: predicting ct4-28
2025-05-29 21:11:10.998770: ct4-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.039579: predicting ct4-63
2025-05-29 21:11:11.043717: ct4-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.085460: predicting ct4-67
2025-05-29 21:11:11.088963: ct4-67, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.133260: predicting ct4-70
2025-05-29 21:11:11.136823: ct4-70, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.178369: predicting ct4-72
2025-05-29 21:11:11.181991: ct4-72, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.218210: predicting ct4-75
2025-05-29 21:11:11.221944: ct4-75, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.266039: predicting ct4-76
2025-05-29 21:11:11.269623: ct4-76, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.310526: predicting ct4-81
2025-05-29 21:11:11.314118: ct4-81, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.356312: predicting ct4-85
2025-05-29 21:11:11.360062: ct4-85, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.399468: predicting ct5-11
2025-05-29 21:11:11.403401: ct5-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.451402: predicting ct5-2
2025-05-29 21:11:11.455191: ct5-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.497266: predicting ct5-25
2025-05-29 21:11:11.501937: ct5-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.547051: predicting ct5-29
2025-05-29 21:11:11.550740: ct5-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.594760: predicting ct5-37
2025-05-29 21:11:11.598582: ct5-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.640592: predicting ct5-4
2025-05-29 21:11:11.644396: ct5-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.685240: predicting ct5-41
2025-05-29 21:11:11.688977: ct5-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.730703: predicting ct5-42
2025-05-29 21:11:11.734442: ct5-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.775570: predicting ct5-46
2025-05-29 21:11:11.779315: ct5-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.824929: predicting ct5-58
2025-05-29 21:11:11.829165: ct5-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.878344: predicting ct5-59
2025-05-29 21:11:11.882837: ct5-59, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.923179: predicting ct5-65
2025-05-29 21:11:11.926882: ct5-65, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:11.979580: predicting ct5-67
2025-05-29 21:11:11.983295: ct5-67, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.027827: predicting ct5-68
2025-05-29 21:11:12.032259: ct5-68, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.078580: predicting ct5-72
2025-05-29 21:11:12.082206: ct5-72, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.129408: predicting ct5-75
2025-05-29 21:11:12.133201: ct5-75, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.180270: predicting ct5-78
2025-05-29 21:11:12.183980: ct5-78, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.239424: predicting ct7-17
2025-05-29 21:11:12.243128: ct7-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.281624: predicting ct7-2
2025-05-29 21:11:12.285506: ct7-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.328210: predicting ct7-27
2025-05-29 21:11:12.331798: ct7-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.378501: predicting ct7-28
2025-05-29 21:11:12.382093: ct7-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.426693: predicting ct7-54
2025-05-29 21:11:12.430298: ct7-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.476959: predicting ct7-60
2025-05-29 21:11:12.480487: ct7-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.522317: predicting ct7-7
2025-05-29 21:11:12.525880: ct7-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.569562: predicting ct7-8
2025-05-29 21:11:12.573282: ct7-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.628083: predicting ct8-12
2025-05-29 21:11:12.633185: ct8-12, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.704205: predicting ct8-16
2025-05-29 21:11:12.709299: ct8-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.766265: predicting ct8-18
2025-05-29 21:11:12.769939: ct8-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.811878: predicting ct8-19
2025-05-29 21:11:12.815675: ct8-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.860732: predicting ct8-20
2025-05-29 21:11:12.864326: ct8-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.905805: predicting ct8-23
2025-05-29 21:11:12.909386: ct8-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.947956: predicting ct8-32
2025-05-29 21:11:12.951756: ct8-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:12.995981: predicting ct8-34
2025-05-29 21:11:12.999701: ct8-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.042852: predicting ct8-38
2025-05-29 21:11:13.046618: ct8-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.087868: predicting ct8-40
2025-05-29 21:11:13.091239: ct8-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.130346: predicting ct8-41
2025-05-29 21:11:13.134230: ct8-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.179546: predicting ct8-42
2025-05-29 21:11:13.183103: ct8-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.228533: predicting ct8-48
2025-05-29 21:11:13.232127: ct8-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.275627: predicting ct8-56
2025-05-29 21:11:13.279217: ct8-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.322935: predicting ct8-57
2025-05-29 21:11:13.328078: ct8-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.373054: predicting ct8-67
2025-05-29 21:11:13.376688: ct8-67, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.425780: predicting ct9-12
2025-05-29 21:11:13.429374: ct9-12, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.465207: predicting ct9-14
2025-05-29 21:11:13.468665: ct9-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.512156: predicting ct9-21
2025-05-29 21:11:13.516234: ct9-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.560805: predicting ct9-31
2025-05-29 21:11:13.564434: ct9-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.617037: predicting ct9-35
2025-05-29 21:11:13.620733: ct9-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.663349: predicting ct9-44
2025-05-29 21:11:13.667161: ct9-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.709239: predicting ct9-53
2025-05-29 21:11:13.712672: ct9-53, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.756064: predicting ct9-59
2025-05-29 21:11:13.759754: ct9-59, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.798937: predicting ct9-60
2025-05-29 21:11:13.808208: ct9-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.857798: predicting ct9-63
2025-05-29 21:11:13.861943: ct9-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.906107: predicting ct9-68
2025-05-29 21:11:13.909438: ct9-68, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:13.950090: predicting ct9-69
2025-05-29 21:11:13.953557: ct9-69, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:11:18.907649: Validation complete
2025-05-29 21:11:18.907773: Mean Validation Dice:  0.4571684393522796

2025-05-29 20:44:16.127789: Epoch time: 90.88 s
2025-05-29 20:44:17.482263: 
2025-05-29 20:44:17.482456: Epoch 237
2025-05-29 20:44:17.482560: Current learning rate: 0.00245
2025-05-29 20:45:46.439174: train_loss -1.2389
2025-05-29 20:45:46.439494: val_loss -0.6633
2025-05-29 20:45:46.439615: Pseudo dice [0.9243, 0.6509, 0.4669, 0.6978, 0.0936, 0.8992, 0.4924, 0.81]
2025-05-29 20:45:46.439715: Epoch time: 88.96 s
2025-05-29 20:45:47.779406: 
2025-05-29 20:45:47.779715: Epoch 238
2025-05-29 20:45:47.779851: Current learning rate: 0.00242
2025-05-29 20:47:16.670444: train_loss -1.2574
2025-05-29 20:47:16.670791: val_loss -0.6922
2025-05-29 20:47:16.671009: Pseudo dice [0.9164, 0.6178, 0.4444, 0.7016, 0.0758, 0.8965, 0.5489, 0.8127]
2025-05-29 20:47:16.671209: Epoch time: 88.89 s
2025-05-29 20:47:18.034670: 
2025-05-29 20:47:18.035064: Epoch 239
2025-05-29 20:47:18.035190: Current learning rate: 0.00238
2025-05-29 20:48:47.709771: train_loss -1.2482
2025-05-29 20:48:47.710275: val_loss -0.5685
2025-05-29 20:48:47.710436: Pseudo dice [0.9068, 0.6261, 0.4448, 0.5967, 0.0641, 0.8634, 0.5365, 0.7823]
2025-05-29 20:48:47.710533: Epoch time: 89.68 s
2025-05-29 20:48:49.100338: 
2025-05-29 20:48:49.100660: Epoch 240
2025-05-29 20:48:49.100842: Current learning rate: 0.00235
2025-05-29 20:50:17.668324: train_loss -1.2529
2025-05-29 20:50:17.668559: val_loss -0.6579
2025-05-29 20:50:17.668674: Pseudo dice [0.9273, 0.6291, 0.3891, 0.7209, 0.0541, 0.8883, 0.5153, 0.7955]
2025-05-29 20:50:17.668767: Epoch time: 88.57 s
2025-05-29 20:50:19.028582: 
2025-05-29 20:50:19.028846: Epoch 241
2025-05-29 20:50:19.029278: Current learning rate: 0.00231
2025-05-29 20:51:48.388180: train_loss -1.2606
2025-05-29 20:51:48.388530: val_loss -0.6694
2025-05-29 20:51:48.388649: Pseudo dice [0.9211, 0.6454, 0.4361, 0.7054, 0.0563, 0.8933, 0.5156, 0.8204]
2025-05-29 20:51:48.388735: Epoch time: 89.36 s
2025-05-29 20:51:49.776473: 
2025-05-29 20:51:49.776752: Epoch 242
2025-05-29 20:51:49.776870: Current learning rate: 0.00228
2025-05-29 20:53:20.150429: train_loss -1.2624
2025-05-29 20:53:20.150640: val_loss -0.6964
2025-05-29 20:53:20.150754: Pseudo dice [0.9148, 0.6429, 0.4353, 0.7398, 0.0958, 0.9099, 0.5382, 0.7919]
2025-05-29 20:53:20.150838: Epoch time: 90.38 s
2025-05-29 20:53:21.560730: 
2025-05-29 20:53:21.561098: Epoch 243
2025-05-29 20:53:21.561209: Current learning rate: 0.00224
2025-05-29 20:54:49.432517: train_loss -1.2614
2025-05-29 20:54:49.432960: val_loss -0.7114
2025-05-29 20:54:49.433113: Pseudo dice [0.9256, 0.6857, 0.4196, 0.7319, 0.0474, 0.9051, 0.5496, 0.8268]
2025-05-29 20:54:49.433187: Epoch time: 87.87 s
2025-05-29 20:54:50.798639: 
2025-05-29 20:54:50.798931: Epoch 244
2025-05-29 20:54:50.799044: Current learning rate: 0.00221
2025-05-29 20:56:16.522656: train_loss -1.2741
2025-05-29 20:56:16.522880: val_loss -0.6427
2025-05-29 20:56:16.523010: Pseudo dice [0.9193, 0.649, 0.4437, 0.6446, 0.0744, 0.9017, 0.5402, 0.8293]
2025-05-29 20:56:16.523169: Epoch time: 85.73 s
2025-05-29 20:56:17.911037: 
2025-05-29 20:56:17.911277: Epoch 245
2025-05-29 20:56:17.911378: Current learning rate: 0.00217
2025-05-29 20:57:43.163433: train_loss -1.27
2025-05-29 20:57:43.163660: val_loss -0.6295
2025-05-29 20:57:43.163770: Pseudo dice [0.9211, 0.6396, 0.4154, 0.674, 0.123, 0.9031, 0.5532, 0.793]
2025-05-29 20:57:43.163862: Epoch time: 85.25 s
2025-05-29 20:57:44.651335: 
2025-05-29 20:57:44.651676: Epoch 246
2025-05-29 20:57:44.651808: Current learning rate: 0.00214
2025-05-29 20:59:13.035627: train_loss -1.2521
2025-05-29 20:59:13.035806: val_loss -0.7282
2025-05-29 20:59:13.035921: Pseudo dice [0.9257, 0.665, 0.4633, 0.7436, 0.0975, 0.9089, 0.5427, 0.789]
2025-05-29 20:59:13.036001: Epoch time: 88.39 s
2025-05-29 20:59:14.445722: 
2025-05-29 20:59:14.445933: Epoch 247
2025-05-29 20:59:14.446031: Current learning rate: 0.0021
2025-05-29 21:00:44.851638: train_loss -1.2691
2025-05-29 21:00:44.851804: val_loss -0.7255
2025-05-29 21:00:44.851912: Pseudo dice [0.9203, 0.6249, 0.4693, 0.7456, 0.1448, 0.8992, 0.5148, 0.8069]
2025-05-29 21:00:44.851985: Epoch time: 90.41 s
2025-05-29 21:00:46.234164: 
2025-05-29 21:00:46.234867: Epoch 248
2025-05-29 21:00:46.234993: Current learning rate: 0.00207
2025-05-29 21:02:16.884806: train_loss -1.2462
2025-05-29 21:02:16.885109: val_loss -0.6103
2025-05-29 21:02:16.885242: Pseudo dice [0.9227, 0.6242, 0.4228, 0.6724, 0.0645, 0.8613, 0.5256, 0.8117]
2025-05-29 21:02:16.885359: Epoch time: 90.65 s
2025-05-29 21:02:18.273810: 
2025-05-29 21:02:18.274188: Epoch 249
2025-05-29 21:02:18.274287: Current learning rate: 0.00203
2025-05-29 21:03:48.424955: train_loss -1.2619
2025-05-29 21:03:48.425255: val_loss -0.733
2025-05-29 21:03:48.425416: Pseudo dice [0.9187, 0.6208, 0.4624, 0.7448, 0.073, 0.9177, 0.507, 0.8181]
2025-05-29 21:03:48.425549: Epoch time: 90.15 s
2025-05-29 21:03:51.304501: 
2025-05-29 21:03:51.304861: Epoch 250
2025-05-29 21:03:51.304960: Current learning rate: 0.00199
2025-05-29 21:05:00.652215: train_loss -1.2627
2025-05-29 21:05:00.652838: val_loss -0.6652
2025-05-29 21:05:00.653026: Pseudo dice [0.9218, 0.6491, 0.4509, 0.6909, 0.081, 0.896, 0.5225, 0.7977]
2025-05-29 21:05:00.653214: Epoch time: 69.35 s
2025-05-29 21:05:02.063810: 
2025-05-29 21:05:02.064200: Epoch 251
2025-05-29 21:05:02.064404: Current learning rate: 0.00196
2025-05-29 21:05:52.157820: train_loss -1.2602
2025-05-29 21:05:52.158644: val_loss -0.6771
2025-05-29 21:05:52.158783: Pseudo dice [0.9223, 0.6501, 0.4674, 0.6873, 0.0932, 0.8802, 0.5658, 0.7851]
2025-05-29 21:05:52.158956: Epoch time: 50.1 s
2025-05-29 21:05:53.587633: 
2025-05-29 21:05:53.587961: Epoch 252
2025-05-29 21:05:53.588071: Current learning rate: 0.00192
2025-05-29 21:06:43.433257: train_loss -1.273
2025-05-29 21:06:43.433779: val_loss -0.7572
2025-05-29 21:06:43.433893: Pseudo dice [0.9129, 0.6703, 0.4113, 0.7724, 0.0963, 0.9087, 0.5231, 0.8143]
2025-05-29 21:06:43.434079: Epoch time: 49.85 s
2025-05-29 21:06:43.434134: Yayy! New best EMA pseudo Dice: 0.6284
2025-05-29 21:06:47.297577: 
2025-05-29 21:06:47.297818: Epoch 253
2025-05-29 21:06:47.297929: Current learning rate: 0.00189
2025-05-29 21:07:35.462507: train_loss -1.2655
2025-05-29 21:07:35.462975: val_loss -0.761
2025-05-29 21:07:35.463149: Pseudo dice [0.9197, 0.6303, 0.4517, 0.8055, 0.0463, 0.914, 0.5452, 0.8236]
2025-05-29 21:07:35.463241: Epoch time: 48.17 s
2025-05-29 21:07:35.463289: Yayy! New best EMA pseudo Dice: 0.6298
2025-05-29 21:07:38.439154: 
2025-05-29 21:07:38.439566: Epoch 254
2025-05-29 21:07:38.439853: Current learning rate: 0.00185
2025-05-29 21:08:21.480965: train_loss -1.2574
2025-05-29 21:08:21.481423: val_loss -0.6722
2025-05-29 21:08:21.481549: Pseudo dice [0.9305, 0.6201, 0.4241, 0.6999, 0.0536, 0.9152, 0.544, 0.8169]
2025-05-29 21:08:21.481668: Epoch time: 43.05 s
2025-05-29 21:08:22.975361: 
2025-05-29 21:08:22.975739: Epoch 255
2025-05-29 21:08:22.975859: Current learning rate: 0.00181
2025-05-29 21:09:03.008912: train_loss -1.2534
2025-05-29 21:09:03.009263: val_loss -0.6571
2025-05-29 21:09:03.009445: Pseudo dice [0.9219, 0.6397, 0.3904, 0.6972, 0.0456, 0.9001, 0.5155, 0.7912]
2025-05-29 21:09:03.009552: Epoch time: 40.03 s
2025-05-29 21:09:04.534921: 
2025-05-29 21:09:04.535144: Epoch 256
2025-05-29 21:09:04.535250: Current learning rate: 0.00178
2025-05-29 21:09:45.980006: train_loss -1.2813
2025-05-29 21:09:45.980322: val_loss -0.6549
2025-05-29 21:09:45.980442: Pseudo dice [0.9194, 0.6431, 0.4484, 0.7243, 0.037, 0.8951, 0.5031, 0.8151]
2025-05-29 21:09:45.980553: Epoch time: 41.45 s
2025-05-29 21:09:47.341000: 
2025-05-29 21:09:47.341277: Epoch 257
2025-05-29 21:09:47.341431: Current learning rate: 0.00174
2025-05-29 21:10:37.290716: train_loss -1.2909
2025-05-29 21:10:37.290933: val_loss -0.6643
2025-05-29 21:10:37.291048: Pseudo dice [0.911, 0.6726, 0.4457, 0.7113, 0.048, 0.8885, 0.523, 0.8255]
2025-05-29 21:10:37.291152: Epoch time: 49.95 s
2025-05-29 21:10:38.776784: 
2025-05-29 21:10:38.777107: Epoch 258
2025-05-29 21:10:38.777281: Current learning rate: 0.0017
2025-05-29 21:11:25.985942: train_loss -1.2669
2025-05-29 21:11:25.986171: val_loss -0.5946
2025-05-29 21:11:25.986286: 
2025-05-29 20:56:44.469398: Epoch 279
2025-05-29 20:56:44.469529: Current learning rate: 0.00091
2025-05-29 20:58:02.670096: train_loss -1.293
2025-05-29 20:58:02.670431: val_loss -0.8022
2025-05-29 20:58:02.670603: Pseudo dice [0.935, 0.7551, 0.4645, 0.8145, 0.2868, 0.936, 0.6083, 0.712]
2025-05-29 20:58:02.670721: Epoch time: 78.2 s
2025-05-29 20:58:04.032846: 
2025-05-29 20:58:04.033242: Epoch 280
2025-05-29 20:58:04.033374: Current learning rate: 0.00087
2025-05-29 20:59:22.152423: train_loss -1.2992
2025-05-29 20:59:22.152771: val_loss -0.829
2025-05-29 20:59:22.152905: Pseudo dice [0.9341, 0.7397, 0.4489, 0.8293, 0.2888, 0.9289, 0.5983, 0.7462]
2025-05-29 20:59:22.153014: Epoch time: 78.12 s
2025-05-29 20:59:23.512499: 
2025-05-29 20:59:23.512761: Epoch 281
2025-05-29 20:59:23.512877: Current learning rate: 0.00083
2025-05-29 21:00:41.830707: train_loss -1.2924
2025-05-29 21:00:41.831094: val_loss -0.7718
2025-05-29 21:00:41.831297: Pseudo dice [0.9303, 0.7551, 0.4624, 0.8154, 0.263, 0.9221, 0.6111, 0.7931]
2025-05-29 21:00:41.831393: Epoch time: 78.32 s
2025-05-29 21:00:43.218712: 
2025-05-29 21:00:43.219456: Epoch 282
2025-05-29 21:00:43.219730: Current learning rate: 0.00079
2025-05-29 21:02:00.326884: train_loss -1.3022
2025-05-29 21:02:00.327464: val_loss -0.8176
2025-05-29 21:02:00.327588: Pseudo dice [0.9313, 0.747, 0.4718, 0.8276, 0.3058, 0.9275, 0.6129, 0.7691]
2025-05-29 21:02:00.327703: Epoch time: 77.11 s
2025-05-29 21:02:01.735691: 
2025-05-29 21:02:01.736077: Epoch 283
2025-05-29 21:02:01.736328: Current learning rate: 0.00076
2025-05-29 21:03:18.281587: train_loss -1.2862
2025-05-29 21:03:18.282298: val_loss -0.7771
2025-05-29 21:03:18.282509: Pseudo dice [0.9381, 0.7521, 0.4456, 0.7958, 0.2951, 0.9179, 0.6224, 0.7242]
2025-05-29 21:03:18.282714: Epoch time: 76.55 s
2025-05-29 21:03:19.771297: 
2025-05-29 21:03:19.771697: Epoch 284
2025-05-29 21:03:19.771834: Current learning rate: 0.00071
2025-05-29 21:04:37.069887: train_loss -1.291
2025-05-29 21:04:37.070497: val_loss -0.8946
2025-05-29 21:04:37.070615: Pseudo dice [0.9469, 0.747, 0.5191, 0.8518, 0.3234, 0.9198, 0.6273, 0.7998]
2025-05-29 21:04:37.070699: Epoch time: 77.3 s
2025-05-29 21:04:37.070757: Yayy! New best EMA pseudo Dice: 0.692
2025-05-29 21:04:40.049312: 
2025-05-29 21:04:40.049854: Epoch 285
2025-05-29 21:04:40.049968: Current learning rate: 0.00067
2025-05-29 21:05:54.183802: train_loss -1.3039
2025-05-29 21:05:54.184142: val_loss -0.7637
2025-05-29 21:05:54.184271: Pseudo dice [0.9357, 0.7313, 0.4567, 0.7853, 0.2187, 0.9229, 0.6275, 0.7179]
2025-05-29 21:05:54.184375: Epoch time: 74.14 s
2025-05-29 21:05:55.606830: 
2025-05-29 21:05:55.607146: Epoch 286
2025-05-29 21:05:55.607282: Current learning rate: 0.00063
2025-05-29 21:07:09.097511: train_loss -1.3073
2025-05-29 21:07:09.097825: val_loss -0.8202
2025-05-29 21:07:09.097972: Pseudo dice [0.9255, 0.7555, 0.4939, 0.8182, 0.2955, 0.9496, 0.6285, 0.7237]
2025-05-29 21:07:09.098074: Epoch time: 73.49 s
2025-05-29 21:07:10.524010: 
2025-05-29 21:07:10.524305: Epoch 287
2025-05-29 21:07:10.524405: Current learning rate: 0.00059
2025-05-29 21:08:21.180137: train_loss -1.3
2025-05-29 21:08:21.180701: val_loss -0.7906
2025-05-29 21:08:21.180922: Pseudo dice [0.93, 0.7492, 0.4632, 0.8188, 0.2559, 0.9456, 0.6259, 0.6945]
2025-05-29 21:08:21.181062: Epoch time: 70.66 s
2025-05-29 21:08:22.695948: 
2025-05-29 21:08:22.696293: Epoch 288
2025-05-29 21:08:22.696476: Current learning rate: 0.00055
2025-05-29 21:09:32.722912: train_loss -1.2909
2025-05-29 21:09:32.723166: val_loss -0.7137
2025-05-29 21:09:32.723284: Pseudo dice [0.9214, 0.7601, 0.4732, 0.7807, 0.2655, 0.9179, 0.6373, 0.6763]
2025-05-29 21:09:32.723367: Epoch time: 70.03 s
2025-05-29 21:09:34.220259: 
2025-05-29 21:09:34.220601: Epoch 289
2025-05-29 21:09:34.220746: Current learning rate: 0.00051
2025-05-29 21:10:42.722761: train_loss -1.3078
2025-05-29 21:10:42.723044: val_loss -0.7691
2025-05-29 21:10:42.723167: Pseudo dice [0.9408, 0.7639, 0.4506, 0.8236, 0.2668, 0.9307, 0.6085, 0.7749]
2025-05-29 21:10:42.723256: Epoch time: 68.5 s
2025-05-29 21:10:44.440960: 
2025-05-29 21:10:44.441144: Epoch 290
2025-05-29 21:10:44.441359: Current learning rate: 0.00047
2025-05-29 21:11:16.335960: train_loss -1.3101
2025-05-29 21:11:16.336276: val_loss -0.8031
2025-05-29 21:11:16.336401: Pseudo dice [0.9278, 0.7701, 0.4435, 0.8332, 0.1994, 0.9327, 0.6378, 0.7476]
2025-05-29 21:11:16.336496: Epoch time: 31.9 s
2025-05-29 21:11:17.930520: 
2025-05-29 21:11:17.930792: Epoch 291
2025-05-29 21:11:17.930936: Current learning rate: 0.00043
2025-05-29 21:11:47.156194: train_loss -1.3096
2025-05-29 21:11:47.156553: val_loss -0.7862
2025-05-29 21:11:47.156726: Pseudo dice [0.936, 0.735, 0.4432, 0.7834, 0.2821, 0.9236, 0.6425, 0.7179]
2025-05-29 21:11:47.156851: Epoch time: 29.23 s
2025-05-29 21:11:48.572935: 
2025-05-29 21:11:48.573310: Epoch 292
2025-05-29 21:11:48.573498: Current learning rate: 0.00038
2025-05-29 21:12:17.684555: train_loss -1.3088
2025-05-29 21:12:17.685285: val_loss -0.845
2025-05-29 21:12:17.685404: Pseudo dice [0.9374, 0.7441, 0.4786, 0.7974, 0.304, 0.917, 0.6329, 0.7501]
2025-05-29 21:12:17.685541: Epoch time: 29.11 s
2025-05-29 21:12:19.080771: 
2025-05-29 21:12:19.081009: Epoch 293
2025-05-29 21:12:19.081176: Current learning rate: 0.00034
2025-05-29 21:12:48.178978: train_loss -1.2974
2025-05-29 21:12:48.179237: val_loss -0.7723
2025-05-29 21:12:48.179352: Pseudo dice [0.9448, 0.7804, 0.4733, 0.7874, 0.2469, 0.9167, 0.5993, 0.7712]
2025-05-29 21:12:48.179481: Epoch time: 29.1 s
2025-05-29 21:12:49.568078: 
2025-05-29 21:12:49.568442: Epoch 294
2025-05-29 21:12:49.568604: Current learning rate: 0.0003
2025-05-29 21:13:18.641995: train_loss -1.3042
2025-05-29 21:13:18.642272: val_loss -0.7873
2025-05-29 21:13:18.642429: Pseudo dice [0.9366, 0.764, 0.4524, 0.8161, 0.1834, 0.921, 0.626, 0.7433]
2025-05-29 21:13:18.642543: Epoch time: 29.08 s
2025-05-29 21:13:20.862571: 
2025-05-29 21:13:20.863078: Epoch 295
2025-05-29 21:13:20.863316: Current learning rate: 0.00025
2025-05-29 21:13:50.001137: train_loss -1.3006
2025-05-29 21:13:50.001635: val_loss -0.7559
2025-05-29 21:13:50.001805: Pseudo dice [0.923, 0.7577, 0.4347, 0.8231, 0.2407, 0.9313, 0.6197, 0.7294]
2025-05-29 21:13:50.002009: Epoch time: 29.14 s
2025-05-29 21:13:51.379574: 
2025-05-29 21:13:51.379812: Epoch 296
2025-05-29 21:13:51.379920: Current learning rate: 0.00021
2025-05-29 21:14:20.410356: train_loss -1.3016
2025-05-29 21:14:20.410848: val_loss -0.8129
2025-05-29 21:14:20.410965: Pseudo dice [0.9286, 0.7665, 0.4254, 0.8278, 0.2815, 0.9117, 0.6148, 0.755]
2025-05-29 21:14:20.411046: Epoch time: 29.03 s
2025-05-29 21:14:21.774766: 
2025-05-29 21:14:21.774986: Epoch 297
2025-05-29 21:14:21.775161: Current learning rate: 0.00016
2025-05-29 21:14:50.751623: train_loss -1.2922
2025-05-29 21:14:50.751906: val_loss -0.7854
2025-05-29 21:14:50.752035: Pseudo dice [0.934, 0.772, 0.4879, 0.8004, 0.2187, 0.9155, 0.6154, 0.7317]
2025-05-29 21:14:50.752124: Epoch time: 28.98 s
2025-05-29 21:14:52.325320: 
2025-05-29 21:14:52.325918: Epoch 298
2025-05-29 21:14:52.326118: Current learning rate: 0.00011
2025-05-29 21:15:21.245166: train_loss -1.3048
2025-05-29 21:15:21.245380: val_loss -0.8294
2025-05-29 21:15:21.245511: Pseudo dice [0.9362, 0.7646, 0.4681, 0.8431, 0.3362, 0.9237, 0.6056, 0.7967]
2025-05-29 21:15:21.245599: Epoch time: 28.92 s
2025-05-29 21:15:22.619140: 
2025-05-29 21:15:22.619349: Epoch 299
2025-05-29 21:15:22.619458: Current learning rate: 6e-05
2025-05-29 21:15:51.554706: train_loss -1.3018
2025-05-29 21:15:51.554953: val_loss -0.7516
2025-05-29 21:15:51.555115: Pseudo dice [0.9354, 0.7441, 0.445, 0.7684, 0.3135, 0.9229, 0.587, 0.7556]
2025-05-29 21:15:51.555236: Epoch time: 28.94 s
2025-05-29 21:15:53.613751: Training done.
2025-05-29 21:15:53.642371: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 21:15:53.643771: The split file contains 5 splits.
2025-05-29 21:15:53.643844: Desired fold for training: 4
2025-05-29 21:15:53.643877: This split has 507 training and 126 validation cases.
2025-05-29 21:15:53.644966: predicting ct14-14
2025-05-29 21:15:53.655315: ct14-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.075930: predicting ct14-30
2025-05-29 21:16:18.080673: ct14-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.119887: predicting ct14-36
2025-05-29 21:16:18.123234: ct14-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.157685: predicting ct14-39
2025-05-29 21:16:18.161361: ct14-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.194156: predicting ct14-40
2025-05-29 21:16:18.197584: ct14-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.232497: predicting ct14-42
2025-05-29 21:16:18.236751: ct14-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.285349: predicting ct14-49
2025-05-29 21:16:18.289914: ct14-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.326762: predicting ct14-62
2025-05-29 21:16:18.331073: ct14-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.369059: predicting ct14-63
2025-05-29 21:16:18.373311: ct14-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.410535: predicting ct14-8
2025-05-29 21:16:18.415165: ct14-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.451133: predicting ct15-1
2025-05-29 21:16:18.456033: ct15-1, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.497820: predicting ct15-15
2025-05-29 21:16:18.501601: ct15-15, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.540057: predicting ct15-18
2025-05-29 21:16:18.543461: ct15-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.582696: predicting ct15-21
2025-05-29 21:16:18.586239: ct15-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.624008: predicting ct15-22
2025-05-29 21:16:18.627529: ct15-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.665829: predicting ct15-23
2025-05-29 21:16:18.669472: ct15-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.705322: predicting ct15-26
2025-05-29 21:16:18.708668: ct15-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.743414: predicting ct15-28
2025-05-29 21:16:18.746954: ct15-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.778141: predicting ct15-30
2025-05-29 21:16:18.781727: ct15-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.821881: predicting ct15-35
2025-05-29 21:16:18.825311: ct15-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.856905: predicting ct15-48
2025-05-29 21:16:18.860246: ct15-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.892600: predicting ct15-5
2025-05-29 21:16:18.896198: ct15-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.926424: predicting ct15-50
2025-05-29 21:16:18.929417: ct15-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.961024: predicting ct2-12
2025-05-29 21:16:18.963710: ct2-12, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:18.995057: predicting ct2-14
2025-05-29 21:16:18.998210: ct2-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.030706: predicting ct2-17
2025-05-29 21:16:19.033619: ct2-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.063832: predicting ct2-2
2025-05-29 21:16:19.067000: ct2-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.098148: predicting ct2-20
2025-05-29 21:16:19.101719: ct2-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.133896: predicting ct2-21
2025-05-29 21:16:19.136985: ct2-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.166051: predicting ct2-24
2025-05-29 21:16:19.169106: ct2-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.200805: predicting ct2-37
2025-05-29 21:16:19.204142: ct2-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.234324: predicting ct2-4
2025-05-29 21:16:19.237138: ct2-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.269991: predicting ct2-48
2025-05-29 21:16:19.273323: ct2-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.304442: predicting ct2-58
2025-05-29 21:16:19.308088: ct2-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.341723: predicting ct2-59
2025-05-29 21:16:19.345141: ct2-59, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.380894: predicting ct2-63
2025-05-29 21:16:19.384491: ct2-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.421562: predicting ct2-67
2025-05-29 21:16:19.425695: ct2-67, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.461465: predicting ct2-8
2025-05-29 21:16:19.465148: ct2-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.498915: predicting ct3-29
2025-05-29 21:16:19.502787: ct3-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.535930: predicting ct3-32
2025-05-29 21:16:19.539523: ct3-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.571319: predicting ct3-34
2025-05-29 21:16:19.574868: ct3-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.608003: predicting ct3-43
2025-05-29 21:16:19.611387: ct3-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.643419: predicting ct3-45
2025-05-29 21:16:19.646920: ct3-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.679620: predicting ct3-46
2025-05-29 21:16:19.683022: ct3-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.714238: predicting ct3-5
2025-05-29 21:16:19.717543: ct3-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.751428: predicting ct3-54
2025-05-29 21:16:19.754442: ct3-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.784492: predicting ct3-56
2025-05-29 21:16:19.787356: ct3-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.819243: predicting ct3-6
2025-05-29 21:16:19.822362: ct3-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.851734: predicting ct3-62
2025-05-29 21:16:19.855003: ct3-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.887791: predicting ct3-8
2025-05-29 21:16:19.890620: ct3-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.920040: predicting ct4-15
2025-05-29 21:16:19.925646: ct4-15, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:19.959867: predicting ct4-17
2025-05-29 21:16:19.964163: ct4-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.002918: predicting ct4-19
2025-05-29 21:16:20.007215: ct4-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.046570: predicting ct4-2
2025-05-29 21:16:20.050838: ct4-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.083519: predicting ct4-22
2025-05-29 21:16:20.088176: ct4-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.121884: predicting ct4-24
2025-05-29 21:16:20.126465: ct4-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.159178: predicting ct4-33
2025-05-29 21:16:20.163086: ct4-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.198061: predicting ct4-34
2025-05-29 21:16:20.201678: ct4-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.238104: predicting ct4-39
2025-05-29 21:16:20.242376: ct4-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.277042: predicting ct4-40
2025-05-29 21:16:20.280618: ct4-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.326276: predicting ct4-41
2025-05-29 21:16:20.333937: ct4-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.377785: predicting ct4-46
2025-05-29 21:16:20.382879: ct4-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.424305: predicting ct4-47
2025-05-29 21:16:20.428688: ct4-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.468338: predicting ct4-5
2025-05-29 21:16:20.471919: ct4-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.511684: predicting ct4-53
2025-05-29 21:16:20.515459: ct4-53, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.548466: predicting ct4-54
2025-05-29 21:16:20.552073: ct4-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.582997: predicting ct4-59
2025-05-29 21:16:20.586929: ct4-59, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.622834: predicting ct4-60
2025-05-29 21:16:20.626474: ct4-60, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.659960: predicting ct4-66
2025-05-29 21:16:20.663681: ct4-66, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.698967: predicting ct4-69
2025-05-29 21:16:20.703793: ct4-69, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.748092: predicting ct4-71
2025-05-29 21:16:20.752430: ct4-71, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.791628: predicting ct4-82
2025-05-29 21:16:20.796036: ct4-82, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.831228: predicting ct4-86
2025-05-29 21:16:20.835701: ct4-86, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.871753: predicting ct4-89
2025-05-29 21:16:20.876336: ct4-89, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.911738: predicting ct5-10
2025-05-29 21:16:20.916265: ct5-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.951735: predicting ct5-19
2025-05-29 21:16:20.956613: ct5-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:20.989045: predicting ct5-22
2025-05-29 21:16:20.992840: ct5-22, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.042578: predicting ct5-33
2025-05-29 21:16:21.050729: ct5-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.105019: predicting ct5-35
2025-05-29 21:16:21.109332: ct5-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.166962: predicting ct5-38
2025-05-29 21:16:21.170889: ct5-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.202712: predicting ct5-45
2025-05-29 21:16:21.206031: ct5-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.236931: predicting ct5-5
2025-05-29 21:16:21.240284: ct5-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.277725: predicting ct5-51
2025-05-29 21:16:21.281326: ct5-51, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.316251: predicting ct5-54
2025-05-29 21:16:21.320053: ct5-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.359516: predicting ct5-55
2025-05-29 21:16:21.363565: ct5-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.405968: predicting ct5-6
2025-05-29 21:16:21.409735: ct5-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.457794: predicting ct5-63
2025-05-29 21:16:21.462898: ct5-63, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.498178: predicting ct5-66
2025-05-29 21:16:21.501857: ct5-66, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.552715: predicting ct5-7
2025-05-29 21:16:21.558444: ct5-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.593180: predicting ct5-70
2025-05-29 21:16:21.596943: ct5-70, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.658586: predicting ct5-79
2025-05-29 21:16:21.664730: ct5-79, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.698636: predicting ct5-8
2025-05-29 21:16:21.702543: ct5-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.760636: predicting ct7-10
2025-05-29 21:16:21.764474: ct7-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.801393: predicting ct7-11
2025-05-29 21:16:21.805502: ct7-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.839264: predicting ct7-23
2025-05-29 21:16:21.843374: ct7-23, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.877609: predicting ct7-25
2025-05-29 21:16:21.881764: ct7-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.915562: predicting ct7-31
2025-05-29 21:16:21.919502: ct7-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.955302: predicting ct7-39
2025-05-29 21:16:21.959086: ct7-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:21.995749: predicting ct7-41
2025-05-29 21:16:21.999685: ct7-41, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.034379: predicting ct7-53
2025-05-29 21:16:22.037997: ct7-53, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.073795: predicting ct7-62
2025-05-29 21:16:22.077482: ct7-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.109792: predicting ct7-9
2025-05-29 21:16:22.113396: ct7-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.151309: predicting ct8-15
2025-05-29 21:16:22.154575: ct8-15, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.187375: predicting ct8-2
2025-05-29 21:16:22.190604: ct8-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.220532: predicting ct8-30
2025-05-29 21:16:22.223883: ct8-30, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.256866: predicting ct8-33
2025-05-29 21:16:22.260136: ct8-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.291114: predicting ct8-35
2025-05-29 21:16:22.294357: ct8-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.326750: predicting ct8-39
2025-05-29 21:16:22.330249: ct8-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.359368: predicting ct8-44
2025-05-29 21:16:22.362558: ct8-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.398133: predicting ct8-50
2025-05-29 21:16:22.404576: ct8-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.434923: predicting ct8-6
2025-05-29 21:16:22.437862: ct8-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.466331: predicting ct8-64
2025-05-29 21:16:22.469699: ct8-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.504536: predicting ct8-69
2025-05-29 21:16:22.507569: ct8-69, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.538486: predicting ct8-72
2025-05-29 21:16:22.541867: ct8-72, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.571873: predicting ct9-24
2025-05-29 21:16:22.574945: ct9-24, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.606601: predicting ct9-26
2025-05-29 21:16:22.609781: ct9-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.639258: predicting ct9-29
2025-05-29 21:16:22.642308: ct9-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.674661: predicting ct9-32
2025-05-29 21:16:22.678041: ct9-32, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.708354: predicting ct9-33
2025-05-29 21:16:22.711144: ct9-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.744361: predicting ct9-34
2025-05-29 21:16:22.747501: ct9-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.777429: predicting ct9-36
2025-05-29 21:16:22.781035: ct9-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.817080: predicting ct9-37
2025-05-29 21:16:22.820930: ct9-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.855688: predicting ct9-39
2025-05-29 21:16:22.858833: ct9-39, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.890701: predicting ct9-43
2025-05-29 21:16:22.894024: ct9-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.930356: predicting ct9-46
2025-05-29 21:16:22.933439: ct9-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:22.966504: predicting ct9-5
2025-05-29 21:16:22.970426: ct9-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:16:27.639296: Validation complete
2025-05-29 21:16:27.639396: Mean Validation Dice:  0.46720437312058305
 Pseudo dice [0.915, 0.6595, 0.4218, 0.6347, 0.0304, 0.8785, 0.5141, 0.8147]
2025-05-29 21:11:25.986898: Epoch time: 47.21 s
2025-05-29 21:11:27.355777: 
2025-05-29 21:11:27.356016: Epoch 259
2025-05-29 21:11:27.356118: Current learning rate: 0.00167
2025-05-29 21:12:16.000059: train_loss -1.2975
2025-05-29 21:12:16.000270: val_loss -0.6217
2025-05-29 21:12:16.000383: Pseudo dice [0.9148, 0.6451, 0.463, 0.6633, 0.0545, 0.8841, 0.5416, 0.795]
2025-05-29 21:12:16.000480: Epoch time: 48.65 s
2025-05-29 21:12:17.406172: 
2025-05-29 21:12:17.406358: Epoch 260
2025-05-29 21:12:17.406484: Current learning rate: 0.00163
2025-05-29 21:12:59.675622: train_loss -1.2823
2025-05-29 21:12:59.675882: val_loss -0.7032
2025-05-29 21:12:59.676001: Pseudo dice [0.9231, 0.659, 0.439, 0.713, 0.0614, 0.8875, 0.5216, 0.8094]
2025-05-29 21:12:59.676089: Epoch time: 42.27 s
2025-05-29 21:13:01.072080: 
2025-05-29 21:13:01.072475: Epoch 261
2025-05-29 21:13:01.072697: Current learning rate: 0.00159
2025-05-29 21:13:44.885243: train_loss -1.268
2025-05-29 21:13:44.885489: val_loss -0.6849
2025-05-29 21:13:44.885609: Pseudo dice [0.9194, 0.6487, 0.3775, 0.749, 0.078, 0.9089, 0.5445, 0.8025]
2025-05-29 21:13:44.885692: Epoch time: 43.82 s
2025-05-29 21:13:46.275291: 
2025-05-29 21:13:46.275612: Epoch 262
2025-05-29 21:13:46.275739: Current learning rate: 0.00156
2025-05-29 21:14:29.885503: train_loss -1.2816
2025-05-29 21:14:29.885733: val_loss -0.6416
2025-05-29 21:14:29.885849: Pseudo dice [0.9291, 0.6301, 0.4822, 0.6808, 0.093, 0.9186, 0.5288, 0.8248]
2025-05-29 21:14:29.885935: Epoch time: 43.61 s
2025-05-29 21:14:31.317143: 
2025-05-29 21:14:31.317579: Epoch 263
2025-05-29 21:14:31.317861: Current learning rate: 0.00152
2025-05-29 21:15:15.291953: train_loss -1.2849
2025-05-29 21:15:15.292183: val_loss -0.6401
2025-05-29 21:15:15.292316: Pseudo dice [0.9165, 0.6687, 0.4262, 0.7086, 0.0685, 0.9054, 0.5546, 0.7874]
2025-05-29 21:15:15.292407: Epoch time: 43.98 s
2025-05-29 21:15:17.392266: 
2025-05-29 21:15:17.392580: Epoch 264
2025-05-29 21:15:17.392778: Current learning rate: 0.00148
2025-05-29 21:16:00.663702: train_loss -1.2692
2025-05-29 21:16:00.664018: val_loss -0.6087
2025-05-29 21:16:00.664148: Pseudo dice [0.9051, 0.6165, 0.4212, 0.7092, 0.0873, 0.8694, 0.4877, 0.7581]
2025-05-29 21:16:00.664246: Epoch time: 43.27 s
2025-05-29 21:16:02.038223: 
2025-05-29 21:16:02.038466: Epoch 265
2025-05-29 21:16:02.038670: Current learning rate: 0.00145
2025-05-29 21:16:37.818581: train_loss -1.2525
2025-05-29 21:16:37.818873: val_loss -0.6646
2025-05-29 21:16:37.819077: Pseudo dice [0.9255, 0.6737, 0.438, 0.6921, 0.1023, 0.912, 0.5413, 0.792]
2025-05-29 21:16:37.819180: Epoch time: 35.78 s
2025-05-29 21:16:39.197737: 
2025-05-29 21:16:39.198154: Epoch 266
2025-05-29 21:16:39.198308: Current learning rate: 0.00141
2025-05-29 21:17:18.349510: train_loss -1.2706
2025-05-29 21:17:18.349739: val_loss -0.6683
2025-05-29 21:17:18.349926: Pseudo dice [0.9224, 0.6424, 0.462, 0.672, 0.052, 0.9134, 0.5195, 0.7805]
2025-05-29 21:17:18.350017: Epoch time: 39.15 s
2025-05-29 21:17:19.725398: 
2025-05-29 21:17:19.725657: Epoch 267
2025-05-29 21:17:19.725820: Current learning rate: 0.00137
2025-05-29 21:17:56.268009: train_loss -1.2604
2025-05-29 21:17:56.268234: val_loss -0.6412
2025-05-29 21:17:56.268348: Pseudo dice [0.9236, 0.6109, 0.4199, 0.6907, 0.0639, 0.9072, 0.486, 0.7868]
2025-05-29 21:17:56.268435: Epoch time: 36.54 s
2025-05-29 21:17:57.658442: 
2025-05-29 21:17:57.658803: Epoch 268
2025-05-29 21:17:57.658916: Current learning rate: 0.00133
2025-05-29 21:18:39.496666: train_loss -1.2561
2025-05-29 21:18:39.496875: val_loss -0.7191
2025-05-29 21:18:39.496985: Pseudo dice [0.9227, 0.68, 0.4612, 0.7249, 0.0995, 0.8994, 0.4776, 0.7906]
2025-05-29 21:18:39.497062: Epoch time: 41.84 s
2025-05-29 21:18:40.823251: 
2025-05-29 21:18:40.823468: Epoch 269
2025-05-29 21:18:40.823571: Current learning rate: 0.0013
2025-05-29 21:19:22.905430: train_loss -1.269
2025-05-29 21:19:22.905698: val_loss -0.6809
2025-05-29 21:19:22.905885: Pseudo dice [0.921, 0.6627, 0.4622, 0.7447, 0.0027, 0.892, 0.5199, 0.7678]
2025-05-29 21:19:22.905985: Epoch time: 42.08 s
2025-05-29 21:19:24.245955: 
2025-05-29 21:19:24.246117: Epoch 270
2025-05-29 21:19:24.246243: Current learning rate: 0.00126
2025-05-29 21:20:08.159842: train_loss -1.2856
2025-05-29 21:20:08.160018: val_loss -0.6982
2025-05-29 21:20:08.160167: Pseudo dice [0.9304, 0.6247, 0.4859, 0.7223, 0.1345, 0.9054, 0.5224, 0.8124]
2025-05-29 21:20:08.160245: Epoch time: 43.92 s
2025-05-29 21:20:09.498666: 
2025-05-29 21:20:09.498869: Epoch 271
2025-05-29 21:20:09.498972: Current learning rate: 0.00122
2025-05-29 21:20:53.420587: train_loss -1.2743
2025-05-29 21:20:53.420811: val_loss -0.6648
2025-05-29 21:20:53.420947: Pseudo dice [0.9145, 0.6684, 0.4552, 0.7116, 0.1166, 0.8916, 0.5302, 0.8123]
2025-05-29 21:20:53.421035: Epoch time: 43.92 s
2025-05-29 21:20:54.750553: 
2025-05-29 21:20:54.750821: Epoch 272
2025-05-29 21:20:54.750935: Current learning rate: 0.00118
2025-05-29 21:21:39.136103: train_loss -1.2783
2025-05-29 21:21:39.136817: val_loss -0.6582
2025-05-29 21:21:39.137008: Pseudo dice [0.9169, 0.6669, 0.4765, 0.6928, 0.0597, 0.8868, 0.5277, 0.8026]
2025-05-29 21:21:39.137105: Epoch time: 44.39 s
2025-05-29 21:21:40.516049: 
2025-05-29 21:21:40.516281: Epoch 273
2025-05-29 21:21:40.516508: Current learning rate: 0.00115
2025-05-29 21:22:24.909343: train_loss -1.273
2025-05-29 21:22:24.909629: val_loss -0.7475
2025-05-29 21:22:24.909757: Pseudo dice [0.9246, 0.6893, 0.4462, 0.7602, 0.0619, 0.913, 0.522, 0.8303]
2025-05-29 21:22:24.909844: Epoch time: 44.39 s
2025-05-29 21:22:26.326162: 
2025-05-29 21:22:26.326415: Epoch 274
2025-05-29 21:22:26.326588: Current learning rate: 0.00111
2025-05-29 21:23:08.527641: train_loss -1.2795
2025-05-29 21:23:08.527880: val_loss -0.6858
2025-05-29 21:23:08.527995: Pseudo dice [0.9186, 0.6503, 0.4547, 0.7348, 0.105, 0.8691, 0.5627, 0.8188]
2025-05-29 21:23:08.528205: Epoch time: 42.2 s
2025-05-29 21:23:08.528291: Yayy! New best EMA pseudo Dice: 0.6301
2025-05-29 21:23:12.238677: 
2025-05-29 21:23:12.238935: Epoch 275
2025-05-29 21:23:12.239047: Current learning rate: 0.00107
2025-05-29 21:23:55.815810: train_loss -1.2833
2025-05-29 21:23:55.816025: val_loss -0.6379
2025-05-29 21:23:55.816139: Pseudo dice [0.9235, 0.6635, 0.4404, 0.6791, 0.0417, 0.9028, 0.5336, 0.8084]
2025-05-29 21:23:55.816211: Epoch time: 43.58 s
2025-05-29 21:23:57.160480: 
2025-05-29 21:23:57.160863: Epoch 276
2025-05-29 21:23:57.161000: Current learning rate: 0.00103
2025-05-29 21:24:36.534462: train_loss -1.2921
2025-05-29 21:24:36.534758: val_loss -0.6982
2025-05-29 21:24:36.534884: Pseudo dice [0.9229, 0.6769, 0.4652, 0.7135, 0.0537, 0.8896, 0.5438, 0.8046]
2025-05-29 21:24:36.534966: Epoch time: 39.38 s
2025-05-29 21:24:37.890627: 
2025-05-29 21:24:37.890841: Epoch 277
2025-05-29 21:24:37.890946: Current learning rate: 0.00099
2025-05-29 21:25:18.002100: train_loss -1.2717
2025-05-29 21:25:18.002302: val_loss -0.6512
2025-05-29 21:25:18.002415: Pseudo dice [0.9152, 0.6613, 0.45, 0.7053, 0.083, 0.892, 0.5391, 0.7991]
2025-05-29 21:25:18.002508: Epoch time: 40.11 s
2025-05-29 21:25:19.369153: 
2025-05-29 21:25:19.369574: Epoch 278
2025-05-29 21:25:19.369677: Current learning rate: 0.00095
2025-05-29 21:25:53.871655: train_loss -1.2721
2025-05-29 21:25:53.871992: val_loss -0.6781
2025-05-29 21:25:53.872181: Pseudo dice [0.9213, 0.6705, 0.4658, 0.6833, 0.0445, 0.8791, 0.5302, 0.8094]
2025-05-29 21:25:53.872274: Epoch time: 34.5 s
2025-05-29 21:25:55.228887: 
2025-05-29 21:25:55.229125: Epoch 279
2025-05-29 21:25:55.229248: Current learning rate: 0.00091
2025-05-29 21:26:34.915086: train_loss -1.2869
2025-05-29 21:26:34.915247: val_loss -0.6754
2025-05-29 21:26:34.915422: Pseudo dice [0.9156, 0.6817, 0.4447, 0.6815, 0.1061, 0.89, 0.506, 0.8269]
2025-05-29 21:26:34.915546: Epoch time: 39.69 s
2025-05-29 21:26:36.268187: 
2025-05-29 21:26:36.268480: Epoch 280
2025-05-29 21:26:36.268614: Current learning rate: 0.00087
2025-05-29 21:27:19.996355: train_loss -1.2734
2025-05-29 21:27:19.996824: val_loss -0.6755
2025-05-29 21:27:19.996992: Pseudo dice [0.9209, 0.6257, 0.4531, 0.7022, 0.0586, 0.8941, 0.5166, 0.8485]
2025-05-29 21:27:19.997581: Epoch time: 43.73 s
2025-05-29 21:27:21.348862: 
2025-05-29 21:27:21.349237: Epoch 281
2025-05-29 21:27:21.349385: Current learning rate: 0.00083
2025-05-29 21:28:04.320576: train_loss -1.2822
2025-05-29 21:28:04.320875: val_loss -0.6553
2025-05-29 21:28:04.321000: Pseudo dice [0.9155, 0.6466, 0.4547, 0.6954, 0.0471, 0.8952, 0.5326, 0.836]
2025-05-29 21:28:04.321107: Epoch time: 42.97 s
2025-05-29 21:28:05.655632: 
2025-05-29 21:28:05.655870: Epoch 282
2025-05-29 21:28:05.655985: Current learning rate: 0.00079
2025-05-29 21:28:48.969961: train_loss -1.2842
2025-05-29 21:28:48.970294: val_loss -0.6627
2025-05-29 21:28:48.970421: Pseudo dice [0.9236, 0.6608, 0.4701, 0.6481, 0.1287, 0.9053, 0.5199, 0.8299]
2025-05-29 21:28:48.970531: Epoch time: 43.32 s
2025-05-29 21:28:50.318566: 
2025-05-29 21:28:50.318853: Epoch 283
2025-05-29 21:28:50.318957: Current learning rate: 0.00076
2025-05-29 21:29:32.630425: train_loss -1.27
2025-05-29 21:29:32.630650: val_loss -0.6533
2025-05-29 21:29:32.630764: Pseudo dice [0.9169, 0.625, 0.4407, 0.6985, 0.0879, 0.904, 0.5177, 0.7928]
2025-05-29 21:29:32.630845: Epoch time: 42.31 s
2025-05-29 21:29:33.965417: 
2025-05-29 21:29:33.965691: Epoch 284
2025-05-29 21:29:33.965882: Current learning rate: 0.00071
2025-05-29 21:30:17.488861: train_loss -1.2992
2025-05-29 21:30:17.489341: val_loss -0.6443
2025-05-29 21:30:17.489471: Pseudo dice [0.9193, 0.6222, 0.4323, 0.6962, 0.0469, 0.8838, 0.5352, 0.815]
2025-05-29 21:30:17.489560: Epoch time: 43.52 s
2025-05-29 21:30:18.866067: 
2025-05-29 21:30:18.866596: Epoch 285
2025-05-29 21:30:18.866889: Current learning rate: 0.00067
2025-05-29 21:31:03.227237: train_loss -1.2853
2025-05-29 21:31:03.227482: val_loss -0.6558
2025-05-29 21:31:03.227606: Pseudo dice [0.9257, 0.6667, 0.435, 0.6943, 0.1063, 0.8831, 0.5276, 0.8203]
2025-05-29 21:31:03.227694: Epoch time: 44.36 s
2025-05-29 21:31:05.250520: 
2025-05-29 21:31:05.250920: Epoch 286
2025-05-29 21:31:05.251192: Current learning rate: 0.00063
2025-05-29 21:31:48.924946: train_loss -1.2778
2025-05-29 21:31:48.925455: val_loss -0.6356
2025-05-29 21:31:48.925580: Pseudo dice [0.9311, 0.6328, 0.4565, 0.6723, 0.1054, 0.8736, 0.5169, 0.8165]
2025-05-29 21:31:48.925667: Epoch time: 43.68 s
2025-05-29 21:31:50.297385: 
2025-05-29 21:31:50.297796: Epoch 287
2025-05-29 21:31:50.297948: Current learning rate: 0.00059
2025-05-29 21:32:34.264504: train_loss -1.2965
2025-05-29 21:32:34.264791: val_loss -0.6665
2025-05-29 21:32:34.264934: Pseudo dice [0.9179, 0.6629, 0.4299, 0.7006, 0.0741, 0.8965, 0.4981, 0.7932]
2025-05-29 21:32:34.265076: Epoch time: 43.97 s
2025-05-29 21:32:35.758351: 
2025-05-29 21:32:35.758686: Epoch 288
2025-05-29 21:32:35.758789: Current learning rate: 0.00055
2025-05-29 21:33:11.131316: train_loss -1.2946
2025-05-29 21:33:11.131580: val_loss -0.6885
2025-05-29 21:33:11.131699: Pseudo dice [0.93, 0.6676, 0.4539, 0.704, 0.0934, 0.8815, 0.4971, 0.8376]
2025-05-29 21:33:11.131786: Epoch time: 35.37 s
2025-05-29 21:33:12.491221: 
2025-05-29 21:33:12.491791: Epoch 289
2025-05-29 21:33:12.491902: Current learning rate: 0.00051
2025-05-29 21:33:51.620739: train_loss -1.2879
2025-05-29 21:33:51.621080: val_loss -0.6657
2025-05-29 21:33:51.621197: Pseudo dice [0.922, 0.6588, 0.4554, 0.7053, 0.0593, 0.8972, 0.5195, 0.8139]
2025-05-29 21:33:51.621292: Epoch time: 39.13 s
2025-05-29 21:33:52.987040: 
2025-05-29 21:33:52.987294: Epoch 290
2025-05-29 21:33:52.987421: Current learning rate: 0.00047
2025-05-29 21:34:29.180748: train_loss -1.2863
2025-05-29 21:34:29.181011: val_loss -0.685
2025-05-29 21:34:29.181127: Pseudo dice [0.9217, 0.6465, 0.4395, 0.7133, 0.0678, 0.9021, 0.5178, 0.8178]
2025-05-29 21:34:29.181208: Epoch time: 36.19 s
2025-05-29 21:34:30.547269: 
2025-05-29 21:34:30.547554: Epoch 291
2025-05-29 21:34:30.547708: Current learning rate: 0.00043
2025-05-29 21:35:12.780921: train_loss -1.2981
2025-05-29 21:35:12.781183: val_loss -0.6359
2025-05-29 21:35:12.781356: Pseudo dice [0.925, 0.6368, 0.4634, 0.6715, 0.0586, 0.9034, 0.5102, 0.7927]
2025-05-29 21:35:12.781466: Epoch time: 42.23 s
2025-05-29 21:35:14.182339: 
2025-05-29 21:35:14.182736: Epoch 292
2025-05-29 21:35:14.182839: Current learning rate: 0.00038
2025-05-29 21:35:56.277570: train_loss -1.3013
2025-05-29 21:35:56.277816: val_loss -0.6299
2025-05-29 21:35:56.277945: Pseudo dice [0.919, 0.6592, 0.4296, 0.6751, 0.108, 0.8938, 0.5238, 0.8043]
2025-05-29 21:35:56.278037: Epoch time: 42.1 s
2025-05-29 21:35:57.730435: 
2025-05-29 21:35:57.730801: Epoch 293
2025-05-29 21:35:57.730987: Current learning rate: 0.00034
2025-05-29 21:36:41.377597: train_loss -1.2805
2025-05-29 21:36:41.377855: val_loss -0.6796
2025-05-29 21:36:41.378016: Pseudo dice [0.9274, 0.6491, 0.4046, 0.7148, 0.0804, 0.914, 0.5204, 0.8118]
2025-05-29 21:36:41.378116: Epoch time: 43.65 s
2025-05-29 21:36:42.801028: 
2025-05-29 21:36:42.801403: Epoch 294
2025-05-29 21:36:42.801609: Current learning rate: 0.0003
2025-05-29 21:37:26.621925: train_loss -1.2912
2025-05-29 21:37:26.622210: val_loss -0.6511
2025-05-29 21:37:26.622430: Pseudo dice [0.9209, 0.6307, 0.4562, 0.7035, 0.0853, 0.8748, 0.5038, 0.8362]
2025-05-29 21:37:26.622555: Epoch time: 43.82 s
2025-05-29 21:37:28.026854: 
2025-05-29 21:37:28.027258: Epoch 295
2025-05-29 21:37:28.027461: Current learning rate: 0.00025
2025-05-29 21:38:10.996138: train_loss -1.2828
2025-05-29 21:38:10.996350: val_loss -0.681
2025-05-29 21:38:10.996479: Pseudo dice [0.9178, 0.6572, 0.4411, 0.687, 0.1051, 0.911, 0.5168, 0.8165]
2025-05-29 21:38:10.996569: Epoch time: 42.97 s
2025-05-29 21:38:12.357036: 
2025-05-29 21:38:12.357203: Epoch 296
2025-05-29 21:38:12.357360: Current learning rate: 0.00021
2025-05-29 21:38:55.996381: train_loss -1.2928
2025-05-29 21:38:55.996604: val_loss -0.6577
2025-05-29 21:38:55.996720: Pseudo dice [0.925, 0.6511, 0.4307, 0.684, 0.0643, 0.8966, 0.4945, 0.8236]
2025-05-29 21:38:55.996803: Epoch time: 43.64 s
2025-05-29 21:38:57.917583: 
2025-05-29 21:38:57.917924: Epoch 297
2025-05-29 21:38:57.918094: Current learning rate: 0.00016
2025-05-29 21:39:40.174472: train_loss -1.3054
2025-05-29 21:39:40.174664: val_loss -0.6198
2025-05-29 21:39:40.174791: Pseudo dice [0.9302, 0.6489, 0.435, 0.6629, 0.0656, 0.9047, 0.5216, 0.829]
2025-05-29 21:39:40.174874: Epoch time: 42.26 s
2025-05-29 21:39:41.599679: 
2025-05-29 21:39:41.600044: Epoch 298
2025-05-29 21:39:41.600224: Current learning rate: 0.00011
2025-05-29 21:40:24.362695: train_loss -1.305
2025-05-29 21:40:24.362861: val_loss -0.6444
2025-05-29 21:40:24.362970: Pseudo dice [0.9258, 0.6343, 0.4249, 0.6937, 0.0633, 0.8849, 0.5131, 0.8243]
2025-05-29 21:40:24.363041: Epoch time: 42.76 s
2025-05-29 21:40:25.713827: 
2025-05-29 21:40:25.714133: Epoch 299
2025-05-29 21:40:25.714276: Current learning rate: 6e-05
2025-05-29 21:41:07.250468: train_loss -1.2848
2025-05-29 21:41:07.250694: val_loss -0.6739
2025-05-29 21:41:07.250833: Pseudo dice [0.923, 0.6596, 0.4333, 0.688, 0.0756, 0.9183, 0.5258, 0.8104]
2025-05-29 21:41:07.250907: Epoch time: 41.54 s
2025-05-29 21:41:09.189333: Training done.
2025-05-29 21:41:09.212209: Using splits from existing split file: /home/zyr/nnUNet/nnUNet-wh/DATASET/nnUNet_preprocessed/Dataset228_adomi/splits_final.json
2025-05-29 21:41:09.212832: The split file contains 5 splits.
2025-05-29 21:41:09.212886: Desired fold for training: 1
2025-05-29 21:41:09.212916: This split has 506 training and 127 validation cases.
2025-05-29 21:41:09.214016: predicting ct14-11
2025-05-29 21:41:09.218095: ct14-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.325936: predicting ct14-12
2025-05-29 21:41:32.335029: ct14-12, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.390483: predicting ct14-18
2025-05-29 21:41:32.394487: ct14-18, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.440267: predicting ct14-2
2025-05-29 21:41:32.444940: ct14-2, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.479483: predicting ct14-25
2025-05-29 21:41:32.483210: ct14-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.516134: predicting ct14-26
2025-05-29 21:41:32.519788: ct14-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.552614: predicting ct14-28
2025-05-29 21:41:32.556063: ct14-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.590017: predicting ct14-31
2025-05-29 21:41:32.593531: ct14-31, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.627782: predicting ct14-34
2025-05-29 21:41:32.631330: ct14-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.665888: predicting ct14-35
2025-05-29 21:41:32.670110: ct14-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.705466: predicting ct14-38
2025-05-29 21:41:32.709568: ct14-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.742761: predicting ct14-4
2025-05-29 21:41:32.747072: ct14-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.781791: predicting ct14-46
2025-05-29 21:41:32.785357: ct14-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.819915: predicting ct14-57
2025-05-29 21:41:32.823361: ct14-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.857486: predicting ct14-61
2025-05-29 21:41:32.860817: ct14-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.894859: predicting ct15-11
2025-05-29 21:41:32.898954: ct15-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.936240: predicting ct15-14
2025-05-29 21:41:32.940664: ct15-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:32.974477: predicting ct15-16
2025-05-29 21:41:32.979160: ct15-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.011342: predicting ct15-20
2025-05-29 21:41:33.014868: ct15-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.048844: predicting ct15-29
2025-05-29 21:41:33.052083: ct15-29, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.086236: predicting ct15-3
2025-05-29 21:41:33.089606: ct15-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.124437: predicting ct15-33
2025-05-29 21:41:33.127921: ct15-33, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.161429: predicting ct15-40
2025-05-29 21:41:33.165792: ct15-40, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.198683: predicting ct15-42
2025-05-29 21:41:33.202389: ct15-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.237546: predicting ct15-44
2025-05-29 21:41:33.241485: ct15-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.278317: predicting ct15-49
2025-05-29 21:41:33.282372: ct15-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.316960: predicting ct15-6
2025-05-29 21:41:33.321335: ct15-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.354236: predicting ct15-7
2025-05-29 21:41:33.358613: ct15-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.389953: predicting ct15-8
2025-05-29 21:41:33.393336: ct15-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.427230: predicting ct15-9
2025-05-29 21:41:33.430193: ct15-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.466421: predicting ct2-16
2025-05-29 21:41:33.470762: ct2-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.508220: predicting ct2-19
2025-05-29 21:41:33.512281: ct2-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.552932: predicting ct2-25
2025-05-29 21:41:33.556211: ct2-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.592043: predicting ct2-38
2025-05-29 21:41:33.594927: ct2-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.628546: predicting ct2-43
2025-05-29 21:41:33.632801: ct2-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.668382: predicting ct2-45
2025-05-29 21:41:33.672315: ct2-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.708758: predicting ct2-46
2025-05-29 21:41:33.712507: ct2-46, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.750643: predicting ct2-49
2025-05-29 21:41:33.754882: ct2-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.787654: predicting ct2-51
2025-05-29 21:41:33.791588: ct2-51, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.833642: predicting ct2-54
2025-05-29 21:41:33.837822: ct2-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.880408: predicting ct2-55
2025-05-29 21:41:33.883930: ct2-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.919830: predicting ct2-56
2025-05-29 21:41:33.925254: ct2-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.959824: predicting ct2-6
2025-05-29 21:41:33.963370: ct2-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:33.996466: predicting ct2-69
2025-05-29 21:41:34.000743: ct2-69, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.036712: predicting ct2-73
2025-05-29 21:41:34.040465: ct2-73, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.075394: predicting ct2-9
2025-05-29 21:41:34.079435: ct2-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.113917: predicting ct3-10
2025-05-29 21:41:34.117738: ct3-10, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.149119: predicting ct3-16
2025-05-29 21:41:34.152437: ct3-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.188190: predicting ct3-36
2025-05-29 21:41:34.191929: ct3-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.224721: predicting ct3-42
2025-05-29 21:41:34.228378: ct3-42, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.261534: predicting ct4-1
2025-05-29 21:41:34.265197: ct4-1, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.298791: predicting ct4-11
2025-05-29 21:41:34.302589: ct4-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.336352: predicting ct4-13
2025-05-29 21:41:34.340282: ct4-13, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.373263: predicting ct4-14
2025-05-29 21:41:34.376781: ct4-14, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.409696: predicting ct4-21
2025-05-29 21:41:34.413338: ct4-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.445982: predicting ct4-25
2025-05-29 21:41:34.449847: ct4-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.484975: predicting ct4-37
2025-05-29 21:41:34.488693: ct4-37, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.525340: predicting ct4-38
2025-05-29 21:41:34.529109: ct4-38, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.563629: predicting ct4-44
2025-05-29 21:41:34.567438: ct4-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.603357: predicting ct4-45
2025-05-29 21:41:34.609625: ct4-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.645555: predicting ct4-49
2025-05-29 21:41:34.649920: ct4-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.681620: predicting ct4-50
2025-05-29 21:41:34.685508: ct4-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.717157: predicting ct4-52
2025-05-29 21:41:34.720785: ct4-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.765555: predicting ct4-57
2025-05-29 21:41:34.769861: ct4-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.803898: predicting ct4-61
2025-05-29 21:41:34.807254: ct4-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.838516: predicting ct4-7
2025-05-29 21:41:34.841655: ct4-7, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.874705: predicting ct4-83
2025-05-29 21:41:34.877947: ct4-83, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.911572: predicting ct5-13
2025-05-29 21:41:34.915022: ct5-13, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.948669: predicting ct5-16
2025-05-29 21:41:34.952568: ct5-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:34.985934: predicting ct5-17
2025-05-29 21:41:34.989623: ct5-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.022044: predicting ct5-26
2025-05-29 21:41:35.025610: ct5-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.059119: predicting ct5-27
2025-05-29 21:41:35.063175: ct5-27, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.097667: predicting ct5-28
2025-05-29 21:41:35.101311: ct5-28, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.135468: predicting ct5-34
2025-05-29 21:41:35.139565: ct5-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.175039: predicting ct5-48
2025-05-29 21:41:35.178742: ct5-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.211924: predicting ct5-57
2025-05-29 21:41:35.215729: ct5-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.248904: predicting ct5-61
2025-05-29 21:41:35.252711: ct5-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.285820: predicting ct5-74
2025-05-29 21:41:35.289381: ct5-74, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.322371: predicting ct5-77
2025-05-29 21:41:35.325608: ct5-77, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.363802: predicting ct7-15
2025-05-29 21:41:35.367507: ct7-15, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.399814: predicting ct7-19
2025-05-29 21:41:35.403411: ct7-19, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.436901: predicting ct7-26
2025-05-29 21:41:35.440354: ct7-26, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.475363: predicting ct7-34
2025-05-29 21:41:35.479038: ct7-34, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.511158: predicting ct7-35
2025-05-29 21:41:35.514462: ct7-35, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.545714: predicting ct7-4
2025-05-29 21:41:35.548812: ct7-4, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.580319: predicting ct7-43
2025-05-29 21:41:35.583357: ct7-43, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.618105: predicting ct7-44
2025-05-29 21:41:35.621189: ct7-44, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.654806: predicting ct7-45
2025-05-29 21:41:35.657912: ct7-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.689617: predicting ct7-48
2025-05-29 21:41:35.693012: ct7-48, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.726363: predicting ct7-50
2025-05-29 21:41:35.730039: ct7-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.762244: predicting ct7-55
2025-05-29 21:41:35.765828: ct7-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.801651: predicting ct7-57
2025-05-29 21:41:35.805047: ct7-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.837975: predicting ct7-6
2025-05-29 21:41:35.841288: ct7-6, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.877366: predicting ct7-61
2025-05-29 21:41:35.880770: ct7-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.915688: predicting ct8-11
2025-05-29 21:41:35.919281: ct8-11, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.952359: predicting ct8-17
2025-05-29 21:41:35.955827: ct8-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:35.988591: predicting ct8-21
2025-05-29 21:41:35.992391: ct8-21, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.026777: predicting ct8-25
2025-05-29 21:41:36.031063: ct8-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.064787: predicting ct8-3
2025-05-29 21:41:36.068427: ct8-3, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.101300: predicting ct8-36
2025-05-29 21:41:36.105140: ct8-36, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.137550: predicting ct8-47
2025-05-29 21:41:36.140842: ct8-47, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.173762: predicting ct8-5
2025-05-29 21:41:36.177356: ct8-5, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.213129: predicting ct8-54
2025-05-29 21:41:36.218428: ct8-54, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.264425: predicting ct8-55
2025-05-29 21:41:36.268787: ct8-55, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.328923: predicting ct8-58
2025-05-29 21:41:36.334676: ct8-58, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.373822: predicting ct8-59
2025-05-29 21:41:36.377977: ct8-59, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.418657: predicting ct8-61
2025-05-29 21:41:36.423468: ct8-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.457010: predicting ct8-62
2025-05-29 21:41:36.461648: ct8-62, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.500115: predicting ct8-65
2025-05-29 21:41:36.504140: ct8-65, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.540085: predicting ct8-8
2025-05-29 21:41:36.544224: ct8-8, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.577638: predicting ct9-16
2025-05-29 21:41:36.580902: ct9-16, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.621378: predicting ct9-17
2025-05-29 21:41:36.625596: ct9-17, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.661301: predicting ct9-20
2025-05-29 21:41:36.665061: ct9-20, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.701696: predicting ct9-25
2025-05-29 21:41:36.705296: ct9-25, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.738231: predicting ct9-45
2025-05-29 21:41:36.742444: ct9-45, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.780521: predicting ct9-49
2025-05-29 21:41:36.784997: ct9-49, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.819443: predicting ct9-50
2025-05-29 21:41:36.823183: ct9-50, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.856600: predicting ct9-52
2025-05-29 21:41:36.860136: ct9-52, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.894915: predicting ct9-56
2025-05-29 21:41:36.898911: ct9-56, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.932775: predicting ct9-57
2025-05-29 21:41:36.936358: ct9-57, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:36.971847: predicting ct9-61
2025-05-29 21:41:36.976303: ct9-61, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.010262: predicting ct9-64
2025-05-29 21:41:37.013621: ct9-64, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.046691: predicting ct9-67
2025-05-29 21:41:37.050890: ct9-67, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.093076: predicting ct9-70
2025-05-29 21:41:37.097015: ct9-70, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.142918: predicting ct9-71
2025-05-29 21:41:37.146376: ct9-71, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.181135: predicting ct9-74
2025-05-29 21:41:37.184800: ct9-74, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:37.218534: predicting ct9-9
2025-05-29 21:41:37.222352: ct9-9, shape torch.Size([3, 1, 464, 449]), rank 0
2025-05-29 21:41:42.024059: Validation complete
2025-05-29 21:41:42.024181: Mean Validation Dice:  0.45042201828585726
